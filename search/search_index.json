{"config": {"indexing": "full", "lang": ["en"], "min_search_length": 3, "prebuild_index": false, "separator": "[\\s\\-]+"}, "docs": [{"location": "", "text": "Memento \u2691 This is my personal wiki where I share everything I know about this world in form of an online mkdocs book hosted on GitHub . The wiki is meant to be read in the web format . Contributing \u2691 If you find a mistake or want to add new content, please make the changes. You can use the edit button on the top right of any article to add them in a pull request, if you don't know what that means, you cal always open an issue or send me an email . Thank you \u2691 If you liked my book and want to show your support, please contribute to my other projects or just say hi :-)", "title": "Introduction"}, {"location": "#memento", "text": "This is my personal wiki where I share everything I know about this world in form of an online mkdocs book hosted on GitHub . The wiki is meant to be read in the web format .", "title": "Memento"}, {"location": "#contributing", "text": "If you find a mistake or want to add new content, please make the changes. You can use the edit button on the top right of any article to add them in a pull request, if you don't know what that means, you cal always open an issue or send me an email .", "title": "Contributing"}, {"location": "#thank-you", "text": "If you liked my book and want to show your support, please contribute to my other projects or just say hi :-)", "title": "Thank you"}, {"location": "contact/", "text": "I'm available through: Email at m0wer (at) autistici (dot) org XMPP at m0wer (at) creep (dot) im PGP Key: 55ED839D73830D00EBA5409430B4ECB4ECEEF686 -----BEGIN PGP PUBLIC KEY BLOCK----- mQINBFmHbfsBEADEKDDJIhA886JFHahMoeG+qaAEIwrfBiNgx4OvQoqndbJenhwQ frXa+V7fp9582siz3TJbdPexezZpWDCD4ZGqhu1/eNyhuzA/+vDmSrlDqUehDDfT Ef5vIaVyWO+8/GJFrt/TY3zrIDZhHju3F+GR1g4OmSMiHWzRQPUwM8gb0OMJeI1N bLPrl9b09DixJOxEcOBMwUcsUm8VkB6WxiA03twmZDzavLRdoY7XYw6npuNY8gVd AyRxTqtY9156y/GsO1bhYv3VwU2R84GwskVwZ2hPe0j+V84PI/U5hNuhKZH+VOR2 Uw2TtLe/XWXhH1gg3Lg2luy4slOCFPS5aWi0AWVvo0zRYGpUu8fNjtFIQWSiBR+P t0H8vGoZlRzWyU2VFixk16Q/G0V3sA3OE9LSuI9xf0V6GSBKjEnjyg9aegwI56+E dCf3hDdNeTmmyt8EhpB1SkWE6s7g/6jFiL2rCNTdpeZ2pPXsu+GuKvvF3GfiDehy 3aBdwNH23sLI0nt8Ch6GMVYIvGAohFrqK4LroHu3aIqcAGKbe0NQZLNjoH+76unY sAFTgElA5+A4FkY7vuni+uZAbEEZvSG6JvrTq8qevRyFDUKafOjXVox9embk+igY mn5CLyRZ3hlQmAq+cGZz5Ej3HaIthCOduxza3b5c+qjYQqrSdPUyMDR+gwARAQAB tBttMHdlciA8bTB3ZXJAYXV0aXN0aWNpLm9yZz6JAlQEEwEIAD4WIQRV7YOdc4MN AOulQJQwtOy07O72hgUCWYdt+wIbAwUJCWYBgAULCQgHAgYVCAkKCwIEFgIDAQIe AQIXgAAKCRAwtOy07O72ht4lEAC7TyWhoExoLe39eeVcI/n3zTrh+Hcpu+Oq8Hk7 sN/dgUpJvAN7iWalQwM+l9XEqyn/UeyzfksERauPa6RdWvelKEY3riGOYz3GRUVz 9D1vdMNM6mkJ4UfhVnKJanmSaHY/XtI6C6tABDy47tjej4kofJRCfR1mOFd+yW3m WtWuVadSfuKBp1D9PtgT2ptBchWW/e/bT/ZAC+yduvBQ3nfevYMp9xvftvlcdg59 w2tSSadSK4nAozfai9dWp/IlOeubqDLdL92WnzFke3/59+IXkjCO9cwMj2Uwa/pW v6074TmHSd9HyTijMFDpkD/eKrIJL6+eXVSdN00HglSfqKguTRYBTGzIyWO0Ye2p ybBWprHBhNAtJkCHLbSEz43/PX3QHQFnSg9b8HNtHgny1Ae8E23V/UlBm7x3NxUw 2Iqlyv1zwtlDr3cP75YzfeeE08SL+nm/2GBJvErpM7PzX0HIPkQWM1mNRqBLshl7 BzofzBbFhuQ4xhESDDUxv4dEUG6MImJvkzg5BPp+cO/5KXLauRNNzGVTC4FOJuv2 fagdareujaD7s9CxtTambmx3IeUAS65to25B0Pvf9DSDTc7dWP2ZncvFApIUD0G+ stS91qtjpIANLN6iOA0jqj9huMQUlc0qhu5IvzxuRDxdsQ6zlsot7QI16mfbZjdG m/rbNLkCDQRZh237ARAA2uGOkqkmF2rNZppci+NqIeDBGpIExrZI+mlHkhKdDRu6 L45QO/W2q/ixbbpDz1Lpd0u2dXQwcDzfAso0ZPLHLodQUBmwE1vNLtUeB0JGv0Gu pv7I53SjW3Aar9C1K0SfU+sw3KVAEUwxF+rV58923kQD3A9AlNfwZ1thZ3d4ePk5 w2DZS1UT58V9Z461OESMDTyxxWJgegXPNj5sL72/GsJglHKgf7HfsRQ5Qp6FyZbz 0JLKcXaX/X6yFVHFOqZv1fuJGweRG9qMSEeSgku8EwgW2dlZQMGunzVwcm9NKmBl jFGMQ/bcSlkpagG8ODyboqaxA8sYxKyRNt5IzlceVJxpEfgCTpZiN3xGD9Szs1jC RbwZg+2SNYTFO8+ifJ4HbkrqsSFFehe5tizrd4ocSiS9zEVlpEWrAtLDIlO2H4NJ odPkBNfQyjyA1kg5cv0JUB75uUzLSZ4YaL2MBlpU4kw1ao5KUkBcdB2Rmi5tzK89 fN9FCMgesZqIFREuSxnpiQ8ajDqjVNsy1XLEJ7hfzEZPhm2UnLTxSmfW12KHiCMo rdqHio5f18qWoMtFL0Benvmj39LTGr1iW7dIL2C+kPqVcF7S7rz7GlIgoMAlWRag MAv2MgWbb6ic3S7F1w5zAeLiGWifbJ4/WSTGtOrJ0hEwNtaCLyLtJmjv0iENBL0A EQEAAYkCPAQYAQgAJhYhBFXtg51zgw0A66VAlDC07LTs7vaGBQJZh237AhsMBQkJ ZgGAAAoJEDC07LTs7vaG26gP/jppS0s6P/m5PClDk9+pGO+gRcTcAQyVrkfvKzhW la28NA5K29mPYd26QgIKUVF5Do6+SNUHMweWZ3jaDxTF6nxNX3e6RT6T1Zs6kOyG 0pmqFYNZlokPgXc3R18odIIhrEfKv3kRRlDQ83NNZsK2mJ4CHNO0fLX9SfxU6u0s qAmbYA02R8m6mGQjV1q99tpelEfA9UboeY7HfdphI6L5/G7W5NX7PZzA1ECjDx7+ vIKpldbJ5cYJSLqqEF47/nl/JJ25fke20gZ1Jz3/eGSAXyzeFlVCiJE48YWUY079 0Y3kMLCUQh1XS+LnHX+hL4hltdFJuYXD0jGNPz8yMY7xP9tlHHfM3APklhTLwG/x 5uUIqdvRPZkScR+WkxuaM9MMQ0BOMXgtIbnrnpNlG/fzPNxEkkWEOATqNvwB3V3j RDYDrNyiREJIuKTIMz2PGfTw5m5jQMT9SqccIFKyuQlhcht+8IGhJnU/cGPjr1YB TQ56B4bjzt0KEFLSiYkkYTrOF3IYVi4Hxky/bW6sNbJGjPCKqguIJwI1UWPKUQXp ao5RqZSwSmFNwg/RqLDGwPCFCW9geBZyISKKuQOUKjePDsHvzy/AtZO3OxVB2jYu odILE8hf1aCJYZCU3q66/u9RjRp7kpR29zB8ngp8G1YfkA1DL+rb2SPogFU9246l PrA1uQINBF78TVcBEADGh0VWXGgq4dKRF1nmQ5qg9e7LIXU01wyIpTFJEi8qEsMH Uv0jWpktIgnV+s/wwTFpYwcz7pDdFEGeD1ep1faK+zR/yH5QapRE+ce25BcTCWuH TalDSFb0gK9DVNEI04j58pJ4oeBRGBBUzy+ARpsm8LY7WnDkfGXonVXWw3CuwWlM c64V0WtzkeNkbhtwHQPQFYBn3mFqSQ2VUNKz2rT5/Nm0DKd/DvDrie99LJ0k8+XC VZx3PIjCOahuoeyiJ0W6akuGTxRD1NmqTLWvx3HfC6VjMLFI3fvRpM/kCoBTdwNY 4AzUPir3vZWgktUAFNJgWfslB0p0A7h8xlf0L8jFxVON1NpysFWiR/2KuloJG0iC GWgmGgyBdaunOD8bzeAOfS9t5D9MsaXtkq7Pkjc3D7ujK02H47PsvMcrs2dgCot4 NswXgJA0S0RV0zZMZUQzyQhtxskYK904lgO8kV3U0NFwp1e6rZFnKQIIOCKtMD5W mE9pqVHzI0CyuvinSDfdcpodbKpLOrTyvQ6C9hNTPkwaVVTnFFgkRRf3cKJjzN9q 7qPLsHmP3Pr57/1ooKVdUqqsAl+mMpG2iGO95b/AAZjfLXdHIKGJk8gfetxsMGvG /ifYSB7kamFsOtIALK5eADEWwqStloeXg9zNUEXUSrPjbh1v1AOyuEps6PvKtwAR AQABiQI8BBgBCAAmFiEEVe2DnXODDQDrpUCUMLTstOzu9oYFAl78TVcCGwwFCQlm AYAACgkQMLTstOzu9oYFIxAArUUvjUBuEuCDDOCyMsuEPAa8U4DzOyYDDX/foaRH Rmv+kywjjQzsTawsTT77ALXKpASHG2PBGBNAly3o0Kq5VBulqTFIEsVUy+BrpNb6 7xqxtCNU9yJUCNHTxx70PG6kpa0KVBtnbJ9CLboIzEGlhpb8/VcWgljubm3zkSqa bUxBJJGc07uQjxjMLQnmyUpxcMfDwi1KYtO+SwZZ7geJKVshev3lZ82HHLBTMcKH fdQ9TpiHgRP8uxssNxjjnJxGhXve4Gqo4r3I7OHWNsSNgy/8ay32s235y8mwfuvL Jt6S2mo2JMCo+mSsv/rJtn0LsGguOboWq3xJyjUT7wvBTPWLgjdtzf7uvmR56bUr Co1VAMHNqPQAadlGEm2RHkhUrC3EgXGOPeEnYm7eL9fWLyEggIGqQhoE5ti6/qsg kJmH6dhwAhdgXoANsBGp0BiPJy4UZ0JluFNCAek7B/2YF5j+DP1wOqGVq3viXLZ2 sqpLyYrAAgjGNu5zLDHKZdrekfm90Uir5NMxlr4iEuwXHLhmndNMMtYOcRN34fiR e4gAD/12X4PumhekZcuweIVgixKFn7jDIdJhMTlYBfUe7dsUEX0PJyt5mig08gtk EZZdh5usyMH99Oh7yTXEO0gWMrNOngGkjBKTpYCrfwzt+oirzfWRHJ56nGvioeG3 Ono= =Weat -----END PGP PUBLIC KEY BLOCK----- Through Github by opening an issue .", "title": "Contact"}, {"location": "forking_this_wiki/", "text": "Follow the next steps. Fork the repository \u2691 On GitHub click the \"fork\" button on the top right of this repository's main page. This will copy the contents of this repository to your account, so you can start making your own changes. Then, clone the forked repository to your local machine. Adaptations \u2691 Repository URL \u2691 There are several files that contain references to this repository's name and URL, which is different to the new forked repository URL, since the user name and the repository name might have changed. As of now, the files where you should replace the references are: README.md mkdoks.yml theme/main.html Documents and structure \u2691 Now, you can either use the documents of this wiki and extend them, keeping their structure, or modify the structure preserving or not the documents. If you choose the first option, jump to the next section. Otherwise edit the files in docs and the nav section of mkdocs.yml as desired. Dependencies \u2691 In order to be able to build your site, some Python dependencies are needed. You can install them by running pip install -r requirements.txt Checking how it looks \u2691 First, clean the old generated site with make clean Then, you can preview the site on your local machine by running make docs and then opening the link in your web browser. Removing the old commits \u2691 The mkdocs-newsletter plugin uses the commit history to generate the newsletter articles, so if you want to start the newsletter from scratch, a way of doing so is removing the commit history. A way of doing so is removing the .git folder and re-initializing the repository. Within the repository directory do rm -rf .git git init git config user.name { user } git config user.email { email } git remote add origin { your repo url } git add . git commit -m \"Initial commit\" git push --force --set-upstream origin master # Force push Setting up GitHub Pages \u2691 To enable the Github Pages website associated with your repo, follow these steps: Create SSH Deploy Key . Activate the GitHub Pages repository configuration with gh-pages branch. Now, the site will be built whenever you push new commits and periodically, according to the cron configuration from .github/workflows/gh-pages.yml .", "title": "Forking this wiki"}, {"location": "forking_this_wiki/#fork-the-repository", "text": "On GitHub click the \"fork\" button on the top right of this repository's main page. This will copy the contents of this repository to your account, so you can start making your own changes. Then, clone the forked repository to your local machine.", "title": "Fork the repository"}, {"location": "forking_this_wiki/#adaptations", "text": "", "title": "Adaptations"}, {"location": "forking_this_wiki/#repository-url", "text": "There are several files that contain references to this repository's name and URL, which is different to the new forked repository URL, since the user name and the repository name might have changed. As of now, the files where you should replace the references are: README.md mkdoks.yml theme/main.html", "title": "Repository URL"}, {"location": "forking_this_wiki/#documents-and-structure", "text": "Now, you can either use the documents of this wiki and extend them, keeping their structure, or modify the structure preserving or not the documents. If you choose the first option, jump to the next section. Otherwise edit the files in docs and the nav section of mkdocs.yml as desired.", "title": "Documents and structure"}, {"location": "forking_this_wiki/#dependencies", "text": "In order to be able to build your site, some Python dependencies are needed. You can install them by running pip install -r requirements.txt", "title": "Dependencies"}, {"location": "forking_this_wiki/#checking-how-it-looks", "text": "First, clean the old generated site with make clean Then, you can preview the site on your local machine by running make docs and then opening the link in your web browser.", "title": "Checking how it looks"}, {"location": "forking_this_wiki/#removing-the-old-commits", "text": "The mkdocs-newsletter plugin uses the commit history to generate the newsletter articles, so if you want to start the newsletter from scratch, a way of doing so is removing the commit history. A way of doing so is removing the .git folder and re-initializing the repository. Within the repository directory do rm -rf .git git init git config user.name { user } git config user.email { email } git remote add origin { your repo url } git add . git commit -m \"Initial commit\" git push --force --set-upstream origin master # Force push", "title": "Removing the old commits"}, {"location": "forking_this_wiki/#setting-up-github-pages", "text": "To enable the Github Pages website associated with your repo, follow these steps: Create SSH Deploy Key . Activate the GitHub Pages repository configuration with gh-pages branch. Now, the site will be built whenever you push new commits and periodically, according to the cron configuration from .github/workflows/gh-pages.yml .", "title": "Setting up GitHub Pages"}, {"location": "computer_science/android/apps/", "text": "F-droid \u2691 List of nice apps from F-Droid - Free and Open Source Android App Repository : Scrambled Exif : Remove the metadata from your pictures before sharing them.", "title": "Apps"}, {"location": "computer_science/android/apps/#f-droid", "text": "List of nice apps from F-Droid - Free and Open Source Android App Repository : Scrambled Exif : Remove the metadata from your pictures before sharing them.", "title": "F-droid"}, {"location": "computer_science/android/safetynet/", "text": "SafetyNet is a mechanism now included by default in Android that detects device tampering, bad URLs, potentially harmful apps, and fake users and reports it to other apps. In practice this means that if you have root access to your device you won't be able to install apps such as banking apps and apps that show DRM protected content. There are ways of hiding root access to SafetyNet but this solutions don't last for long, because SafetyNet is updated to detect this kind of \u201ccheats\u201d. Fuck googel.", "title": "SafetyNet"}, {"location": "computer_science/android/apps/osmand/", "text": "Export \u2691 Export favorites \u2691 The best way of doing this is going to {storage}/Android/data/net.osmand and copying favorites.gpx .", "title": "OsmAnd"}, {"location": "computer_science/android/apps/osmand/#export", "text": "", "title": "Export"}, {"location": "computer_science/android/apps/osmand/#export-favorites", "text": "The best way of doing this is going to {storage}/Android/data/net.osmand and copying favorites.gpx .", "title": "Export favorites"}, {"location": "computer_science/android/devices/curtana/", "text": "The codename is curtana but its also name of a larger family named miatoll . Recoveries \u2691 For Android 11 use OrangeFox Recovery . ROMs \u2691 I use Pixel Extended-ROM . It's nice and passes SafetyNet if unrooted.", "title": "Xiaomi Redmi Note 9S"}, {"location": "computer_science/android/devices/curtana/#recoveries", "text": "For Android 11 use OrangeFox Recovery .", "title": "Recoveries"}, {"location": "computer_science/android/devices/curtana/#roms", "text": "I use Pixel Extended-ROM . It's nice and passes SafetyNet if unrooted.", "title": "ROMs"}, {"location": "computer_science/cicd/github_actions/", "text": "GitHub Actions let's you automate, customize, and execute your software development workflows right in your repository. Actions \u2691 Checkout V2 \u2691 actions/checkout is an action for checking out a repo. Example usage: jobs : molecule : runs-on : ubuntu-latest strategy : fail-fast : false steps : - name : Checkout uses : actions/checkout@v2 with : submodules : true GitHub Action for GitHub Push \u2691 ad-m/github-push-action is a GitHub action to push back to repository eg. update code. Example usage: jobs : molecule : runs-on : ubuntu-latest strategy : fail-fast : false steps : - name : Push changes uses : ad-m/github-push-action@master with : github_token : ${{ secrets.GITHUB_TOKEN }} branch : ${{ github.ref }} This will push the commited changes to the current branch. Configuration \u2691 Concurrency \u2691 You can use concurrency to cancel any in-progress job or run. Example: concurrency : group : docs-${{ github.head_ref }} cancel-in-progress : true This is useful to cancel previous jobs if new commits are pushed, which saves minutes, energy and avoids conflicts when pushing changes during the action. Secrets \u2691 Store file as secret \u2691 If you want to store a file (multiline, binary...) as a secret, first encode it with base64: base64 -i < {{ file_path }} | tr -d '\\n' | xclip -i -selection clipboard Then paste it to a new secret. To restore the file diring the workflow, add: - name : restore file run : echo ${{ secrets.SECRET }} | base64 -d > {{ file_path }}", "title": "Github Actions"}, {"location": "computer_science/cicd/github_actions/#actions", "text": "", "title": "Actions"}, {"location": "computer_science/cicd/github_actions/#checkout-v2", "text": "actions/checkout is an action for checking out a repo. Example usage: jobs : molecule : runs-on : ubuntu-latest strategy : fail-fast : false steps : - name : Checkout uses : actions/checkout@v2 with : submodules : true", "title": "Checkout V2"}, {"location": "computer_science/cicd/github_actions/#github-action-for-github-push", "text": "ad-m/github-push-action is a GitHub action to push back to repository eg. update code. Example usage: jobs : molecule : runs-on : ubuntu-latest strategy : fail-fast : false steps : - name : Push changes uses : ad-m/github-push-action@master with : github_token : ${{ secrets.GITHUB_TOKEN }} branch : ${{ github.ref }} This will push the commited changes to the current branch.", "title": "GitHub Action for GitHub Push"}, {"location": "computer_science/cicd/github_actions/#configuration", "text": "", "title": "Configuration"}, {"location": "computer_science/cicd/github_actions/#concurrency", "text": "You can use concurrency to cancel any in-progress job or run. Example: concurrency : group : docs-${{ github.head_ref }} cancel-in-progress : true This is useful to cancel previous jobs if new commits are pushed, which saves minutes, energy and avoids conflicts when pushing changes during the action.", "title": "Concurrency"}, {"location": "computer_science/cicd/github_actions/#secrets", "text": "", "title": "Secrets"}, {"location": "computer_science/cicd/github_actions/#store-file-as-secret", "text": "If you want to store a file (multiline, binary...) as a secret, first encode it with base64: base64 -i < {{ file_path }} | tr -d '\\n' | xclip -i -selection clipboard Then paste it to a new secret. To restore the file diring the workflow, add: - name : restore file run : echo ${{ secrets.SECRET }} | base64 -d > {{ file_path }}", "title": "Store file as secret"}, {"location": "computer_science/gnu_linux/X/", "text": "Linux X11 Window System \u2691 Usage \u2691 Reload ~/.Xresources \u2691 xrdb ~/.Xresources stackoverflow Tips \u2691 Hide and disable the cursor \u2691 You can more or less hide it with: unclutter -idle 0 . To disable it, use the Fn button or rmmod psmouse . stackoverflow", "title": "X"}, {"location": "computer_science/gnu_linux/X/#linux-x11-window-system", "text": "", "title": "Linux X11 Window System"}, {"location": "computer_science/gnu_linux/X/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/X/#reload-xresources", "text": "xrdb ~/.Xresources stackoverflow", "title": "Reload ~/.Xresources"}, {"location": "computer_science/gnu_linux/X/#tips", "text": "", "title": "Tips"}, {"location": "computer_science/gnu_linux/X/#hide-and-disable-the-cursor", "text": "You can more or less hide it with: unclutter -idle 0 . To disable it, use the Fn button or rmmod psmouse . stackoverflow", "title": "Hide and disable the cursor"}, {"location": "computer_science/gnu_linux/alacritty/", "text": "alacritty/alacritty is a cross-platform, OpenGL terminal emulator. It excels in performance, you can compare it with your previous terminal emulator by running time tree ~ in both. Install \u2691 To install it in Debian, you can use the pre-built .deb releases from barnumbirr/alacritty-debian . Usage \u2691 Shortcuts \u2691 Ctrl+Shift+Space : Enter vi mode. Common issues \u2691 Terminal functionality unavailable in remote shells \u2691 When connecting to a remote system from an Alacritty terminal, for instance over SSH, it can occur that the system does not have an entry for Alacritty in its terminfo database ( /usr/share/terminfo/a/alacritty ). Therefore, all interactive terminal functionality does not work. This can be fixed by copying the terminfo for Alacritty to the remote server. On the local host, using Alacritty: infocmp > alacritty.terminfo # export Alacritty's Terminfo Now, copy it to the remote host using scp . On the remote host: tic -x alacritty.terminfo # import Terminfo for current user Note : After this, you will need to start a new SSH session to have the remote shell load the new Terminfo.", "title": "Alacritty"}, {"location": "computer_science/gnu_linux/alacritty/#install", "text": "To install it in Debian, you can use the pre-built .deb releases from barnumbirr/alacritty-debian .", "title": "Install"}, {"location": "computer_science/gnu_linux/alacritty/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/alacritty/#shortcuts", "text": "Ctrl+Shift+Space : Enter vi mode.", "title": "Shortcuts"}, {"location": "computer_science/gnu_linux/alacritty/#common-issues", "text": "", "title": "Common issues"}, {"location": "computer_science/gnu_linux/alacritty/#terminal-functionality-unavailable-in-remote-shells", "text": "When connecting to a remote system from an Alacritty terminal, for instance over SSH, it can occur that the system does not have an entry for Alacritty in its terminfo database ( /usr/share/terminfo/a/alacritty ). Therefore, all interactive terminal functionality does not work. This can be fixed by copying the terminfo for Alacritty to the remote server. On the local host, using Alacritty: infocmp > alacritty.terminfo # export Alacritty's Terminfo Now, copy it to the remote host using scp . On the remote host: tic -x alacritty.terminfo # import Terminfo for current user Note : After this, you will need to start a new SSH session to have the remote shell load the new Terminfo.", "title": "Terminal functionality unavailable in remote shells"}, {"location": "computer_science/gnu_linux/android-studio/", "text": "Android Studio \u2691 Debug \u2691 Building gradle stuck/frozen \u2691 It's a weird trouble with internet, follow this instructions: Download a new version of gradle, such as gradle-4.3-all.zip, etc., and put the file in your AS Gradle location (Mac: go to the Application folder and open the package of AS, and put the new gradle in the Gradle folder. PS: If your new gradle version folder is not found, then you can create it on your own.Windows: like the previous two answers); Disconnect your Wifi or LAN; Open Android Studio 3.0 as usual; DO NOT OPEN YOUR PROJECT IMMEDIATELY, TURN TO THE PREFERENCE PART FIRST; GO TO THE GRADLE PART, DO THE SETTINGS AND SWITCH THE OFFLINE MODE ON; Open the project you want to open; Let AS to index the file and modify the gradle.properties when it is still indexing. Turn on you Wifi or LAN, and AS will download the missing file. ATTENTION: DO NOT MODIFY YOUR ANDROID MANIFEST OR OTHER FILES WHEN DOWNLOADING Close AS and reopen the project. And everything will be fine. :-) Note : To switch offline mode on (Configure -> Preferences -> search for gradle -> then check the work offline radio button) Also when everything is done uncheck the offline radio button otherwise errors may occur. stackoverflow", "title": "Android-studio"}, {"location": "computer_science/gnu_linux/android-studio/#android-studio", "text": "", "title": "Android Studio"}, {"location": "computer_science/gnu_linux/android-studio/#debug", "text": "", "title": "Debug"}, {"location": "computer_science/gnu_linux/android-studio/#building-gradle-stuckfrozen", "text": "It's a weird trouble with internet, follow this instructions: Download a new version of gradle, such as gradle-4.3-all.zip, etc., and put the file in your AS Gradle location (Mac: go to the Application folder and open the package of AS, and put the new gradle in the Gradle folder. PS: If your new gradle version folder is not found, then you can create it on your own.Windows: like the previous two answers); Disconnect your Wifi or LAN; Open Android Studio 3.0 as usual; DO NOT OPEN YOUR PROJECT IMMEDIATELY, TURN TO THE PREFERENCE PART FIRST; GO TO THE GRADLE PART, DO THE SETTINGS AND SWITCH THE OFFLINE MODE ON; Open the project you want to open; Let AS to index the file and modify the gradle.properties when it is still indexing. Turn on you Wifi or LAN, and AS will download the missing file. ATTENTION: DO NOT MODIFY YOUR ANDROID MANIFEST OR OTHER FILES WHEN DOWNLOADING Close AS and reopen the project. And everything will be fine. :-) Note : To switch offline mode on (Configure -> Preferences -> search for gradle -> then check the work offline radio button) Also when everything is done uncheck the offline radio button otherwise errors may occur. stackoverflow", "title": "Building gradle stuck/frozen"}, {"location": "computer_science/gnu_linux/android/", "text": "Android \u2691 Reference \u2691 Unix utilities \u2691 Screen control scrcpy", "title": "Android"}, {"location": "computer_science/gnu_linux/android/#android", "text": "", "title": "Android"}, {"location": "computer_science/gnu_linux/android/#reference", "text": "", "title": "Reference"}, {"location": "computer_science/gnu_linux/android/#unix-utilities", "text": "Screen control scrcpy", "title": "Unix utilities"}, {"location": "computer_science/gnu_linux/anki/", "text": "Anki \u2691 Powerful, intelligent flash cards. Remembering things just became much easier. Usage \u2691 Switching card order \u2691 video Debug \u2691 Modifying a card type of a deck affects other decks \u2691 Create a different note type instead. Note types are shared among decks and changes to them will affect all the cards that use it. reddit Reference \u2691 ankiweb Plugins \u2691 SyncRedirector Polar Connect", "title": "Anki"}, {"location": "computer_science/gnu_linux/anki/#anki", "text": "Powerful, intelligent flash cards. Remembering things just became much easier.", "title": "Anki"}, {"location": "computer_science/gnu_linux/anki/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/anki/#switching-card-order", "text": "video", "title": "Switching card order"}, {"location": "computer_science/gnu_linux/anki/#debug", "text": "", "title": "Debug"}, {"location": "computer_science/gnu_linux/anki/#modifying-a-card-type-of-a-deck-affects-other-decks", "text": "Create a different note type instead. Note types are shared among decks and changes to them will affect all the cards that use it. reddit", "title": "Modifying a card type of a deck affects other decks"}, {"location": "computer_science/gnu_linux/anki/#reference", "text": "ankiweb", "title": "Reference"}, {"location": "computer_science/gnu_linux/anki/#plugins", "text": "SyncRedirector Polar Connect", "title": "Plugins"}, {"location": "computer_science/gnu_linux/ansible/", "text": "Ansible \u2691 Usage \u2691 Meta \u2691 Run handlers (before): - meta: flush_handlers ansible handlers Loops \u2691 Looping over Subelements \u2691 Useful when you have a list of dictionaries and you want to pick the same element from all of them. with_subelements : - \"{{ some list }}\" - interesting_list_item - flags : skip_missing : yes ansible-docs Command line \u2691 Variables \u2691 To provide variables directly from the command line: --extra-vars \"version=1.23.45 other_variable=foo\" . stackoverflow Facts \u2691 ansible_user_id Only gather facts when tag matches \u2691 To speed up playbooks, disable gather_facts . In the parts where this is requiered, you can use this approach: - hosts : all sudo : yes gather_facts : False pre_tasks : - setup : filter : ansible_* roles : - your_role_here tags : - tag1 This way ansible will only gather some facts and only if the tag matches (when run with the -t option). stackoverflow Debug \u2691 Include tags ignored \u2691 Example: - import_tasks : db-setup.yml tags=db-setup This tags are ignored if you skip them. Bug: github could not find item['foo'] key in iterated item \u2691 Solution: specify a third element in the with_subelements list called flags that is a dict and contains skip_missing: yes . with_subelements : - \"{{ some list }}\" - interesting_list_item - flags : skip_missing : yes github-issues Reference \u2691 Usage \u2691 ansible-docs Jinja2 filters. Modules \u2691 mysql_db docker_container Utilities \u2691 ansigenome Tool for calculating dependency graphs and more. Vault \u2691 serversforhackers Plugins \u2691 Timing \u2691 Displays tasks timing at the end of the playbook output. To enable, add callback_whitelist = profile_tasks to ansible.cfg . ansible-profile", "title": "Ansible"}, {"location": "computer_science/gnu_linux/ansible/#ansible", "text": "", "title": "Ansible"}, {"location": "computer_science/gnu_linux/ansible/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/ansible/#meta", "text": "Run handlers (before): - meta: flush_handlers ansible handlers", "title": "Meta"}, {"location": "computer_science/gnu_linux/ansible/#loops", "text": "", "title": "Loops"}, {"location": "computer_science/gnu_linux/ansible/#looping-over-subelements", "text": "Useful when you have a list of dictionaries and you want to pick the same element from all of them. with_subelements : - \"{{ some list }}\" - interesting_list_item - flags : skip_missing : yes ansible-docs", "title": "Looping over Subelements"}, {"location": "computer_science/gnu_linux/ansible/#command-line", "text": "", "title": "Command line"}, {"location": "computer_science/gnu_linux/ansible/#variables", "text": "To provide variables directly from the command line: --extra-vars \"version=1.23.45 other_variable=foo\" . stackoverflow", "title": "Variables"}, {"location": "computer_science/gnu_linux/ansible/#facts", "text": "ansible_user_id", "title": "Facts"}, {"location": "computer_science/gnu_linux/ansible/#only-gather-facts-when-tag-matches", "text": "To speed up playbooks, disable gather_facts . In the parts where this is requiered, you can use this approach: - hosts : all sudo : yes gather_facts : False pre_tasks : - setup : filter : ansible_* roles : - your_role_here tags : - tag1 This way ansible will only gather some facts and only if the tag matches (when run with the -t option). stackoverflow", "title": "Only gather facts when tag matches"}, {"location": "computer_science/gnu_linux/ansible/#debug", "text": "", "title": "Debug"}, {"location": "computer_science/gnu_linux/ansible/#include-tags-ignored", "text": "Example: - import_tasks : db-setup.yml tags=db-setup This tags are ignored if you skip them. Bug: github", "title": "Include tags ignored"}, {"location": "computer_science/gnu_linux/ansible/#could-not-find-itemfoo-key-in-iterated-item", "text": "Solution: specify a third element in the with_subelements list called flags that is a dict and contains skip_missing: yes . with_subelements : - \"{{ some list }}\" - interesting_list_item - flags : skip_missing : yes github-issues", "title": "could not find item['foo'] key in iterated item"}, {"location": "computer_science/gnu_linux/ansible/#reference", "text": "", "title": "Reference"}, {"location": "computer_science/gnu_linux/ansible/#usage_1", "text": "ansible-docs Jinja2 filters.", "title": "Usage"}, {"location": "computer_science/gnu_linux/ansible/#modules", "text": "mysql_db docker_container", "title": "Modules"}, {"location": "computer_science/gnu_linux/ansible/#utilities", "text": "ansigenome Tool for calculating dependency graphs and more.", "title": "Utilities"}, {"location": "computer_science/gnu_linux/ansible/#vault", "text": "serversforhackers", "title": "Vault"}, {"location": "computer_science/gnu_linux/ansible/#plugins", "text": "", "title": "Plugins"}, {"location": "computer_science/gnu_linux/ansible/#timing", "text": "Displays tasks timing at the end of the playbook output. To enable, add callback_whitelist = profile_tasks to ansible.cfg . ansible-profile", "title": "Timing"}, {"location": "computer_science/gnu_linux/apt/", "text": "Usage \u2691 Install package from .deb \u2691 Either use apt-get install ./{path to .deb} or dpkg -i {path to .deb} and then apt-get -f install if there are missing dependencies. Debug \u2691 Fix half-installed package \u2691 apt install --reinstall [package] askubuntu Tips \u2691 alias uu = 'apt update && apt upgrade -y && apt-get autoremove -y'", "title": "APT"}, {"location": "computer_science/gnu_linux/apt/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/apt/#install-package-from-deb", "text": "Either use apt-get install ./{path to .deb} or dpkg -i {path to .deb} and then apt-get -f install if there are missing dependencies.", "title": "Install package from .deb"}, {"location": "computer_science/gnu_linux/apt/#debug", "text": "", "title": "Debug"}, {"location": "computer_science/gnu_linux/apt/#fix-half-installed-package", "text": "apt install --reinstall [package] askubuntu", "title": "Fix half-installed package"}, {"location": "computer_science/gnu_linux/apt/#tips", "text": "alias uu = 'apt update && apt upgrade -y && apt-get autoremove -y'", "title": "Tips"}, {"location": "computer_science/gnu_linux/bash/", "text": "Usage \u2691 Run a command N times \u2691 seq [N] | xargs -Iz [command] stackoverflow Output redirection \u2691 To redirect both stderr and stdout to /dev/null use: command > /dev/null 2 > & 1 stackoverflow For loop \u2691 for arg in [ list ] ; do [ command ] $arg ; done Environment variables \u2691 Remove an environment variable \u2691 To remove an exported environment variable use: unset VARIABLE Remove prefix/suffix \u2691 You can remove a fixed prefix and/or suffix from an environment variable with ${var#{prefix}} and ${var%{suffix}} as follows $ string = \"hello-world\" $ $ foo = ${ string #hell } $ foo = ${ foo %ld } $ $ echo \" ${ foo } \" o-wor Configuration \u2691 Prompt \u2691 Add timestamp \u2691 Add \\D{%T} to PS1 to display the current time (HH:MM:SS). For example for debian edit /etc/bash.bashrc and add: PS1 = '\\D{%T} ${debian_chroot:+($debian_chroot)}\\u@\\h:\\w\\$' bneijt.nl Reference \u2691 Shortcuts \u2691 lifehacker Keyboard syntax \u2691 ss64", "title": "Bash"}, {"location": "computer_science/gnu_linux/bash/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/bash/#run-a-command-n-times", "text": "seq [N] | xargs -Iz [command] stackoverflow", "title": "Run a command N times"}, {"location": "computer_science/gnu_linux/bash/#output-redirection", "text": "To redirect both stderr and stdout to /dev/null use: command > /dev/null 2 > & 1 stackoverflow", "title": "Output redirection"}, {"location": "computer_science/gnu_linux/bash/#for-loop", "text": "for arg in [ list ] ; do [ command ] $arg ; done", "title": "For loop"}, {"location": "computer_science/gnu_linux/bash/#environment-variables", "text": "", "title": "Environment variables"}, {"location": "computer_science/gnu_linux/bash/#remove-an-environment-variable", "text": "To remove an exported environment variable use: unset VARIABLE", "title": "Remove an environment variable"}, {"location": "computer_science/gnu_linux/bash/#remove-prefixsuffix", "text": "You can remove a fixed prefix and/or suffix from an environment variable with ${var#{prefix}} and ${var%{suffix}} as follows $ string = \"hello-world\" $ $ foo = ${ string #hell } $ foo = ${ foo %ld } $ $ echo \" ${ foo } \" o-wor", "title": "Remove prefix/suffix"}, {"location": "computer_science/gnu_linux/bash/#configuration", "text": "", "title": "Configuration"}, {"location": "computer_science/gnu_linux/bash/#prompt", "text": "", "title": "Prompt"}, {"location": "computer_science/gnu_linux/bash/#add-timestamp", "text": "Add \\D{%T} to PS1 to display the current time (HH:MM:SS). For example for debian edit /etc/bash.bashrc and add: PS1 = '\\D{%T} ${debian_chroot:+($debian_chroot)}\\u@\\h:\\w\\$' bneijt.nl", "title": "Add timestamp"}, {"location": "computer_science/gnu_linux/bash/#reference", "text": "", "title": "Reference"}, {"location": "computer_science/gnu_linux/bash/#shortcuts", "text": "lifehacker", "title": "Shortcuts"}, {"location": "computer_science/gnu_linux/bash/#keyboard-syntax", "text": "ss64", "title": "Keyboard syntax"}, {"location": "computer_science/gnu_linux/basics/", "text": "Useful commands \u2691 Find duplicated lines and count how many times they appear in a file \u2691 sort <file> | uniq -c", "title": "Basics"}, {"location": "computer_science/gnu_linux/basics/#useful-commands", "text": "", "title": "Useful commands"}, {"location": "computer_science/gnu_linux/basics/#find-duplicated-lines-and-count-how-many-times-they-appear-in-a-file", "text": "sort <file> | uniq -c", "title": "Find duplicated lines and count how many times they appear in a file"}, {"location": "computer_science/gnu_linux/blkid/", "text": "blkid \u2691 Usage \u2691 Get device UUID \u2691 blkid [ device ] liquidat", "title": "blkid"}, {"location": "computer_science/gnu_linux/blkid/#blkid", "text": "", "title": "blkid"}, {"location": "computer_science/gnu_linux/blkid/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/blkid/#get-device-uuid", "text": "blkid [ device ] liquidat", "title": "Get device UUID"}, {"location": "computer_science/gnu_linux/c/", "text": "C programming language \u2691 Usage \u2691 Pointers \u2691 The basic formula is: a = * ( & a ) The & operator returns the direction of the operand's position in memory. The * operator accesess the operand's memory address. Reference \u2691 Harvard", "title": "C"}, {"location": "computer_science/gnu_linux/c/#c-programming-language", "text": "", "title": "C programming language"}, {"location": "computer_science/gnu_linux/c/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/c/#pointers", "text": "The basic formula is: a = * ( & a ) The & operator returns the direction of the operand's position in memory. The * operator accesess the operand's memory address.", "title": "Pointers"}, {"location": "computer_science/gnu_linux/c/#reference", "text": "Harvard", "title": "Reference"}, {"location": "computer_science/gnu_linux/commitizen/", "text": "Commitizen is a tool that defines a standard way of committing. It can bump the version of your project automatically based on commits and generate a changelog file. Installation \u2691 pip install commitizen Configuration \u2691 If your project version is not detected automatically or it isn't specified you can add the files where the version appears or the version respectively to .cz.toml as shown in the following examples: [tool.commitizen] version_files = [ \"src/__version__.py\" , \"setup.py\" , ] [tool.commitizen] version = \"0.2.2\" Usage \u2691 To commit: cz commit To retry a failed commit: cz commit --retry To bump the version and update the changelog: cz bump --changelog --no-verify", "title": "Commitizen"}, {"location": "computer_science/gnu_linux/commitizen/#installation", "text": "pip install commitizen", "title": "Installation"}, {"location": "computer_science/gnu_linux/commitizen/#configuration", "text": "If your project version is not detected automatically or it isn't specified you can add the files where the version appears or the version respectively to .cz.toml as shown in the following examples: [tool.commitizen] version_files = [ \"src/__version__.py\" , \"setup.py\" , ] [tool.commitizen] version = \"0.2.2\"", "title": "Configuration"}, {"location": "computer_science/gnu_linux/commitizen/#usage", "text": "To commit: cz commit To retry a failed commit: cz commit --retry To bump the version and update the changelog: cz bump --changelog --no-verify", "title": "Usage"}, {"location": "computer_science/gnu_linux/cpupower/", "text": "cpupower usage guide \u2691 Change the governor \u2691 cpupower frequency-set -g [governor] archlinux-wiki", "title": "cpupower"}, {"location": "computer_science/gnu_linux/cpupower/#cpupower-usage-guide", "text": "", "title": "cpupower usage guide"}, {"location": "computer_science/gnu_linux/cpupower/#change-the-governor", "text": "cpupower frequency-set -g [governor] archlinux-wiki", "title": "Change the governor"}, {"location": "computer_science/gnu_linux/curl/", "text": "curl is used in command lines or scripts to transfer data. Usage \u2691 HTTP AUTH \u2691 To fetch a website that requires authentication, use curl -u username:password [ url ]", "title": "cURL"}, {"location": "computer_science/gnu_linux/curl/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/curl/#http-auth", "text": "To fetch a website that requires authentication, use curl -u username:password [ url ]", "title": "HTTP AUTH"}, {"location": "computer_science/gnu_linux/debian/", "text": "Install \u2691 Setup raid1+LVM \u2691 debian-wiki Select fastest mirror \u2691 Install and run netselect-apt to choose the best Debian mirror by downloading the full mirror list and using netselect to find the fastest/closest one.", "title": "Debian"}, {"location": "computer_science/gnu_linux/debian/#install", "text": "", "title": "Install"}, {"location": "computer_science/gnu_linux/debian/#setup-raid1lvm", "text": "debian-wiki", "title": "Setup raid1+LVM"}, {"location": "computer_science/gnu_linux/debian/#select-fastest-mirror", "text": "Install and run netselect-apt to choose the best Debian mirror by downloading the full mirror list and using netselect to find the fastest/closest one.", "title": "Select fastest mirror"}, {"location": "computer_science/gnu_linux/dig/", "text": "dig usage guide \u2691 Get primary DNS server for a given domain \u2691 dig [domain] soa +short stackoverflow Get CAA register for a given domain \u2691 dig caa [domain] stackoverflow", "title": "dig"}, {"location": "computer_science/gnu_linux/dig/#dig-usage-guide", "text": "", "title": "dig usage guide"}, {"location": "computer_science/gnu_linux/dig/#get-primary-dns-server-for-a-given-domain", "text": "dig [domain] soa +short stackoverflow", "title": "Get primary DNS server for a given domain"}, {"location": "computer_science/gnu_linux/dig/#get-caa-register-for-a-given-domain", "text": "dig caa [domain] stackoverflow", "title": "Get CAA register for a given domain"}, {"location": "computer_science/gnu_linux/docker/", "text": "Usage \u2691 Build an image \u2691 The general command is docker build [ OPTIONS ] PATH | URL | - Most commonly you'll use docker build -t tag . if there is a Dockerfile in the directory. Build image from a git repository \u2691 docker build -t tag https://github.com/docker/rootfs.git# [ tag_or_branch ] There are more possible configurations available, check the Docker documentation . Registry as a cache \u2691 docker run -d -p 5000:5000 --restart always --name registry -e \"REGISTRY_DELETE_ENABLED=true\" -e \"REGISTRY_PROXY_REMOTEURL=https://registry-1.docker.io\" registry:2 And the in the clients run dockerd with --registry-mirror http://host:5000 . docker-doc GUI \u2691 X server \u2691 You should mount your local ~/Xauthority to the docker. If it doesn't work, try from your machine: xhost +local:root # this enables local non-network connections So it enables access control. ros.org Configuration \u2691 Change docker data root path \u2691 In the systemd unit file: ExecStart=/usr/bin/dockerd --data-root [docker_data_root_path] Tips \u2691 Manage dockers with systemd \u2691 [Unit] Description=Foo Service After=docker.service Requires=docker.service After=docker.redis.service Requires=docker.redis.service [Service] TimeoutStartSec=0 Restart=always ExecStartPre=-/usr/bin/docker stop foo ExecStartPre=-/usr/bin/docker rm foo ExecStartPre=/usr/bin/docker pull foo ExecStart=/usr/bin/docker run --name foo --link docker.redi.service:redis --rm foo [Install] WantedBy=multi-user.target Note: The \u201c-\u201d at the start means systemd won\u2019t abort if the command fails. container-solutions Delete dangling volumes \u2691 Delete orphan volumes (created when not running docker run with the --rm option): docker volume rm \\ docker volume ls -q -f dangling=true`` coderwall Remove unused data \u2691 Use docker system prune . Automated clean up \u2691 Add the following line to crontab -e : 0 3 * * * /usr/bin/docker system prune -f 2>&1 > /dev/null -f prevents manual confirmation from being asked. Print names in stead of IDs with docker stats \u2691 docker stats $(docker ps --format '{{.Names}}') stackoverflow Get the run command of a docker \u2691 Sometimes you have a running docker of which you want to get the command line options it was originally launched with. You can get it with: docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \\ assaflavie/runlike [ container ] stackoverflow Upgrade all your currently downloaded docker images \u2691 docker images | grep -vE \"(REPOSITORY|local|<none>)\" | awk '{print $1\":\"$2}' | xargs -L1 docker pull Sort docker images by size desc \u2691 docker images --format '{{.Size}}\\t{{.Repository}}\\t{{.Tag}}\\t{{.ID}}' | sed 's/ //' | sort -h -r | column -t gist Don't send unnecessary files/directory to build context \u2691 When building an image from a Dockerfile, Docker copies the files and directories in the local path, which can take a long time if the files are large. You can add unnecesary files and directories to .dockerignore so that they are't copied when building. Reference \u2691 Healthcheck \u2691 couchbase", "title": "Docker"}, {"location": "computer_science/gnu_linux/docker/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/docker/#build-an-image", "text": "The general command is docker build [ OPTIONS ] PATH | URL | - Most commonly you'll use docker build -t tag . if there is a Dockerfile in the directory.", "title": "Build an image"}, {"location": "computer_science/gnu_linux/docker/#build-image-from-a-git-repository", "text": "docker build -t tag https://github.com/docker/rootfs.git# [ tag_or_branch ] There are more possible configurations available, check the Docker documentation .", "title": "Build image from a git repository"}, {"location": "computer_science/gnu_linux/docker/#registry-as-a-cache", "text": "docker run -d -p 5000:5000 --restart always --name registry -e \"REGISTRY_DELETE_ENABLED=true\" -e \"REGISTRY_PROXY_REMOTEURL=https://registry-1.docker.io\" registry:2 And the in the clients run dockerd with --registry-mirror http://host:5000 . docker-doc", "title": "Registry as a cache"}, {"location": "computer_science/gnu_linux/docker/#gui", "text": "", "title": "GUI"}, {"location": "computer_science/gnu_linux/docker/#x-server", "text": "You should mount your local ~/Xauthority to the docker. If it doesn't work, try from your machine: xhost +local:root # this enables local non-network connections So it enables access control. ros.org", "title": "X server"}, {"location": "computer_science/gnu_linux/docker/#configuration", "text": "", "title": "Configuration"}, {"location": "computer_science/gnu_linux/docker/#change-docker-data-root-path", "text": "In the systemd unit file: ExecStart=/usr/bin/dockerd --data-root [docker_data_root_path]", "title": "Change docker data root path"}, {"location": "computer_science/gnu_linux/docker/#tips", "text": "", "title": "Tips"}, {"location": "computer_science/gnu_linux/docker/#manage-dockers-with-systemd", "text": "[Unit] Description=Foo Service After=docker.service Requires=docker.service After=docker.redis.service Requires=docker.redis.service [Service] TimeoutStartSec=0 Restart=always ExecStartPre=-/usr/bin/docker stop foo ExecStartPre=-/usr/bin/docker rm foo ExecStartPre=/usr/bin/docker pull foo ExecStart=/usr/bin/docker run --name foo --link docker.redi.service:redis --rm foo [Install] WantedBy=multi-user.target Note: The \u201c-\u201d at the start means systemd won\u2019t abort if the command fails. container-solutions", "title": "Manage dockers with systemd"}, {"location": "computer_science/gnu_linux/docker/#delete-dangling-volumes", "text": "Delete orphan volumes (created when not running docker run with the --rm option): docker volume rm \\ docker volume ls -q -f dangling=true`` coderwall", "title": "Delete dangling volumes"}, {"location": "computer_science/gnu_linux/docker/#remove-unused-data", "text": "Use docker system prune .", "title": "Remove unused data"}, {"location": "computer_science/gnu_linux/docker/#automated-clean-up", "text": "Add the following line to crontab -e : 0 3 * * * /usr/bin/docker system prune -f 2>&1 > /dev/null -f prevents manual confirmation from being asked.", "title": "Automated clean up"}, {"location": "computer_science/gnu_linux/docker/#print-names-in-stead-of-ids-with-docker-stats", "text": "docker stats $(docker ps --format '{{.Names}}') stackoverflow", "title": "Print names in stead of IDs with docker stats"}, {"location": "computer_science/gnu_linux/docker/#get-the-run-command-of-a-docker", "text": "Sometimes you have a running docker of which you want to get the command line options it was originally launched with. You can get it with: docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \\ assaflavie/runlike [ container ] stackoverflow", "title": "Get the run command of a docker"}, {"location": "computer_science/gnu_linux/docker/#upgrade-all-your-currently-downloaded-docker-images", "text": "docker images | grep -vE \"(REPOSITORY|local|<none>)\" | awk '{print $1\":\"$2}' | xargs -L1 docker pull", "title": "Upgrade all your currently downloaded docker images"}, {"location": "computer_science/gnu_linux/docker/#sort-docker-images-by-size-desc", "text": "docker images --format '{{.Size}}\\t{{.Repository}}\\t{{.Tag}}\\t{{.ID}}' | sed 's/ //' | sort -h -r | column -t gist", "title": "Sort docker images by size desc"}, {"location": "computer_science/gnu_linux/docker/#dont-send-unnecessary-filesdirectory-to-build-context", "text": "When building an image from a Dockerfile, Docker copies the files and directories in the local path, which can take a long time if the files are large. You can add unnecesary files and directories to .dockerignore so that they are't copied when building.", "title": "Don't send unnecessary files/directory to build context"}, {"location": "computer_science/gnu_linux/docker/#reference", "text": "", "title": "Reference"}, {"location": "computer_science/gnu_linux/docker/#healthcheck", "text": "couchbase", "title": "Healthcheck"}, {"location": "computer_science/gnu_linux/eclipse/", "text": "Eclipse \u2691 Reference \u2691 Plugins \u2691 vrapper Vim-like input scheme for moving around and editing text.", "title": "Eclipse"}, {"location": "computer_science/gnu_linux/eclipse/#eclipse", "text": "", "title": "Eclipse"}, {"location": "computer_science/gnu_linux/eclipse/#reference", "text": "", "title": "Reference"}, {"location": "computer_science/gnu_linux/eclipse/#plugins", "text": "vrapper Vim-like input scheme for moving around and editing text.", "title": "Plugins"}, {"location": "computer_science/gnu_linux/elogind/", "text": "elogind \u2691 Configuration \u2691 Lock screen and suspend \u2691 #!/bin/sh # # /lib/elogind/system-sleep/lock.sh # Lock before suspend integration with elogind username = lerax userhome = /home/ $username export XAUTHORITY = \" $userhome /.Xauthority\" export DISPLAY = \":0.0\" case \" ${ 1 } \" in pre ) su $username -c \"/usr/bin/slock\" & sleep 1s ; ;; esac How lock your system before suspend with openrc init via elogind using slock", "title": "elogind"}, {"location": "computer_science/gnu_linux/elogind/#elogind", "text": "", "title": "elogind"}, {"location": "computer_science/gnu_linux/elogind/#configuration", "text": "", "title": "Configuration"}, {"location": "computer_science/gnu_linux/elogind/#lock-screen-and-suspend", "text": "#!/bin/sh # # /lib/elogind/system-sleep/lock.sh # Lock before suspend integration with elogind username = lerax userhome = /home/ $username export XAUTHORITY = \" $userhome /.Xauthority\" export DISPLAY = \":0.0\" case \" ${ 1 } \" in pre ) su $username -c \"/usr/bin/slock\" & sleep 1s ; ;; esac How lock your system before suspend with openrc init via elogind using slock", "title": "Lock screen and suspend"}, {"location": "computer_science/gnu_linux/emerge/", "text": "Portage emerge (gentoo package manager) \u2691 Upgrade with depth \u2691 emerge --ask --alert=y --update --newuse --deep 200 --with-bdeps=y --verbose @world Continue failed emerge \u2691 emerge --resume --skipfirst", "title": "emerge"}, {"location": "computer_science/gnu_linux/emerge/#portage-emerge-gentoo-package-manager", "text": "", "title": "Portage emerge (gentoo package manager)"}, {"location": "computer_science/gnu_linux/emerge/#upgrade-with-depth", "text": "emerge --ask --alert=y --update --newuse --deep 200 --with-bdeps=y --verbose @world", "title": "Upgrade with depth"}, {"location": "computer_science/gnu_linux/emerge/#continue-failed-emerge", "text": "emerge --resume --skipfirst", "title": "Continue failed emerge"}, {"location": "computer_science/gnu_linux/equery/", "text": "equery \u2691 Usage \u2691 Finding the package that a file came from with belongs (b) \u2691 equery belongs -e [file] Finding which packages depend on a given one \u2691 equery depends [package] Reference \u2691 gentoo-wiki", "title": "equery"}, {"location": "computer_science/gnu_linux/equery/#equery", "text": "", "title": "equery"}, {"location": "computer_science/gnu_linux/equery/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/equery/#finding-the-package-that-a-file-came-from-with-belongs-b", "text": "equery belongs -e [file]", "title": "Finding the package that a file came from with belongs (b)"}, {"location": "computer_science/gnu_linux/equery/#finding-which-packages-depend-on-a-given-one", "text": "equery depends [package]", "title": "Finding which packages depend on a given one"}, {"location": "computer_science/gnu_linux/equery/#reference", "text": "gentoo-wiki", "title": "Reference"}, {"location": "computer_science/gnu_linux/esp8266/", "text": "ESP8266 \u2691 Reference \u2691 Code \u2691 check flash config", "title": "ESP8266"}, {"location": "computer_science/gnu_linux/esp8266/#esp8266", "text": "", "title": "ESP8266"}, {"location": "computer_science/gnu_linux/esp8266/#reference", "text": "", "title": "Reference"}, {"location": "computer_science/gnu_linux/esp8266/#code", "text": "check flash config", "title": "Code"}, {"location": "computer_science/gnu_linux/exiftool/", "text": "exiftool \u2691 Delete metadata from a file \u2691 exiftool -all:all= [file] PDF \u2691 If it is a PDF is convnient to run this afterwards: qpdf --linearize [file.pdf] And maybe exiftool again. github", "title": "ExifTool"}, {"location": "computer_science/gnu_linux/exiftool/#exiftool", "text": "", "title": "exiftool"}, {"location": "computer_science/gnu_linux/exiftool/#delete-metadata-from-a-file", "text": "exiftool -all:all= [file]", "title": "Delete metadata from a file"}, {"location": "computer_science/gnu_linux/exiftool/#pdf", "text": "If it is a PDF is convnient to run this afterwards: qpdf --linearize [file.pdf] And maybe exiftool again. github", "title": "PDF"}, {"location": "computer_science/gnu_linux/fdisk/", "text": "fdisk \u2691 Create new partition: \u2691 fdisk [ disk ] n # answer the questions w # write changes Delete partitions \u2691 fdisk [ device ] p # to list current partitions d w # write changes", "title": "fdisk"}, {"location": "computer_science/gnu_linux/fdisk/#fdisk", "text": "", "title": "fdisk"}, {"location": "computer_science/gnu_linux/fdisk/#create-new-partition", "text": "fdisk [ disk ] n # answer the questions w # write changes", "title": "Create new partition:"}, {"location": "computer_science/gnu_linux/fdisk/#delete-partitions", "text": "fdisk [ device ] p # to list current partitions d w # write changes", "title": "Delete partitions"}, {"location": "computer_science/gnu_linux/ffmpeg/", "text": "Usage \u2691 Recording \u2691 Record video from screen and audio from microphone \u2691 ffmpeg -video_size 1920x1080 -framerate 30 -f x11grab -i :0.0+0,0 -f alsa -ac 2 -i pulse -pix_fmt yuv420p { out } With -i :0.0+0,0 you can specify the X11 session ( 0.0 ) and the position of the top left corner ( 0,0 ). Misc \u2691 List available formats \u2691 ffmpeg -formats Convert a file to the default settings \u2691 ffmpeg -i [input file] [output file] Compress a video to a given size \u2691 ffmpeg -i [ input ] -fs [ size in MB ] M [ output ] stackexchange Tips \u2691 Video compatibility \u2691 For compatibility with common media players, use -pix_fmt yuv420p and MP4 format.", "title": "FFmpeg"}, {"location": "computer_science/gnu_linux/ffmpeg/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/ffmpeg/#recording", "text": "", "title": "Recording"}, {"location": "computer_science/gnu_linux/ffmpeg/#record-video-from-screen-and-audio-from-microphone", "text": "ffmpeg -video_size 1920x1080 -framerate 30 -f x11grab -i :0.0+0,0 -f alsa -ac 2 -i pulse -pix_fmt yuv420p { out } With -i :0.0+0,0 you can specify the X11 session ( 0.0 ) and the position of the top left corner ( 0,0 ).", "title": "Record video from screen and audio from microphone"}, {"location": "computer_science/gnu_linux/ffmpeg/#misc", "text": "", "title": "Misc"}, {"location": "computer_science/gnu_linux/ffmpeg/#list-available-formats", "text": "ffmpeg -formats", "title": "List available formats"}, {"location": "computer_science/gnu_linux/ffmpeg/#convert-a-file-to-the-default-settings", "text": "ffmpeg -i [input file] [output file]", "title": "Convert a file to the default settings"}, {"location": "computer_science/gnu_linux/ffmpeg/#compress-a-video-to-a-given-size", "text": "ffmpeg -i [ input ] -fs [ size in MB ] M [ output ] stackexchange", "title": "Compress a video to a given size"}, {"location": "computer_science/gnu_linux/ffmpeg/#tips", "text": "", "title": "Tips"}, {"location": "computer_science/gnu_linux/ffmpeg/#video-compatibility", "text": "For compatibility with common media players, use -pix_fmt yuv420p and MP4 format.", "title": "Video compatibility"}, {"location": "computer_science/gnu_linux/find/", "text": "Cheatsheet \u2691 List files larger than \u2691 find . -type f -size +100M Options \u2691 Types \u2691 Find only directories: -type d stackexchange-unix", "title": "find"}, {"location": "computer_science/gnu_linux/find/#cheatsheet", "text": "", "title": "Cheatsheet"}, {"location": "computer_science/gnu_linux/find/#list-files-larger-than", "text": "find . -type f -size +100M", "title": "List files larger than"}, {"location": "computer_science/gnu_linux/find/#options", "text": "", "title": "Options"}, {"location": "computer_science/gnu_linux/find/#types", "text": "Find only directories: -type d stackexchange-unix", "title": "Types"}, {"location": "computer_science/gnu_linux/firefox/", "text": "Firefox \u2691 Debug \u2691 Input black background \u2691 Firefox messes up every input if the GTK theme is dark. There are a lot of workarounds. Text Contrast Plugin Use a light theme for firefox archlinux-wiki Some file types won't display and directly open the download popup instead \u2691 This happened to me when trying to use the markdown-viewer plugin. To fix this, add a new MIME type in ~/.local/share/mime/packages/text-markdown.xml : <?xml version=\"1.0\"?> <mime-info xmlns= 'http://www.freedesktop.org/standards/shared-mime-info' > <mime-type type= \"text/plain\" > <glob pattern= \"*.md\" /> <glob pattern= \"*.mkd\" /> <glob pattern= \"*.markdown\" /> </mime-type> </mime-info> And then run update-mime-database ~/.local/share/mime . Encoding error for local files \u2691 Set UTF-8 as fallback in about:config : intl.charset.fallback.utf8_for_file = true . markdown-viewer Reference \u2691 Plugins \u2691 markdown-viewer", "title": "Firefox"}, {"location": "computer_science/gnu_linux/firefox/#firefox", "text": "", "title": "Firefox"}, {"location": "computer_science/gnu_linux/firefox/#debug", "text": "", "title": "Debug"}, {"location": "computer_science/gnu_linux/firefox/#input-black-background", "text": "Firefox messes up every input if the GTK theme is dark. There are a lot of workarounds. Text Contrast Plugin Use a light theme for firefox archlinux-wiki", "title": "Input black background"}, {"location": "computer_science/gnu_linux/firefox/#some-file-types-wont-display-and-directly-open-the-download-popup-instead", "text": "This happened to me when trying to use the markdown-viewer plugin. To fix this, add a new MIME type in ~/.local/share/mime/packages/text-markdown.xml : <?xml version=\"1.0\"?> <mime-info xmlns= 'http://www.freedesktop.org/standards/shared-mime-info' > <mime-type type= \"text/plain\" > <glob pattern= \"*.md\" /> <glob pattern= \"*.mkd\" /> <glob pattern= \"*.markdown\" /> </mime-type> </mime-info> And then run update-mime-database ~/.local/share/mime .", "title": "Some file types won't display and directly open the download popup instead"}, {"location": "computer_science/gnu_linux/firefox/#encoding-error-for-local-files", "text": "Set UTF-8 as fallback in about:config : intl.charset.fallback.utf8_for_file = true . markdown-viewer", "title": "Encoding error for local files"}, {"location": "computer_science/gnu_linux/firefox/#reference", "text": "", "title": "Reference"}, {"location": "computer_science/gnu_linux/firefox/#plugins", "text": "markdown-viewer", "title": "Plugins"}, {"location": "computer_science/gnu_linux/ftp/", "text": "FTP \u2691 Connection \u2691 ftp [host] And then enter the login details. Mirror everything \u2691 wget -m ftp://username:password@ip.of.old.host stackoverflow Reference \u2691 howtoforge", "title": "FTP"}, {"location": "computer_science/gnu_linux/ftp/#ftp", "text": "", "title": "FTP"}, {"location": "computer_science/gnu_linux/ftp/#connection", "text": "ftp [host] And then enter the login details.", "title": "Connection"}, {"location": "computer_science/gnu_linux/ftp/#mirror-everything", "text": "wget -m ftp://username:password@ip.of.old.host stackoverflow", "title": "Mirror everything"}, {"location": "computer_science/gnu_linux/ftp/#reference", "text": "howtoforge", "title": "Reference"}, {"location": "computer_science/gnu_linux/genkernel/", "text": "Genkernel \u2691 Usage \u2691 Generate a new kernel \u2691 Set the desired kernel as default with eselect . Run genkernel all . With the kernel alias \u2691 alias kernel='genkernel --kernel-config=/root/kernel_config all && mkkernelsig && emerge -Av @module-rebuild' Note: Steps 4 and 5 should have be done the last time, if that isn't the case, do them first. Download the new gentoo-sources by enabling them in package.license. Select the new sources with eselect kernel . Compile the new kernel and select new configurations with kernel . After rebooting and checking that everything works as expected: Save the kernel configuration with cp /usr/src/linux/.config ~/kernel-config- uname -r``. Copy this configurations as the default: cp ~/kernel-config- uname -r ~/kernel_config This will create a new clean kernel from the default configuration. Preserve old configuration \u2691 Manually this will be done with make oldconfig . If we save a kernel configuration, we can use it with newer versions (it will be automatically merged with the new kernel settings). To do so, we need to specify the old configuration to genkernel. genkernel --kernel-config=/root/kernel_config all gentoo-forums", "title": "genkernel"}, {"location": "computer_science/gnu_linux/genkernel/#genkernel", "text": "", "title": "Genkernel"}, {"location": "computer_science/gnu_linux/genkernel/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/genkernel/#generate-a-new-kernel", "text": "Set the desired kernel as default with eselect . Run genkernel all .", "title": "Generate a new kernel"}, {"location": "computer_science/gnu_linux/genkernel/#with-the-kernel-alias", "text": "alias kernel='genkernel --kernel-config=/root/kernel_config all && mkkernelsig && emerge -Av @module-rebuild' Note: Steps 4 and 5 should have be done the last time, if that isn't the case, do them first. Download the new gentoo-sources by enabling them in package.license. Select the new sources with eselect kernel . Compile the new kernel and select new configurations with kernel . After rebooting and checking that everything works as expected: Save the kernel configuration with cp /usr/src/linux/.config ~/kernel-config- uname -r``. Copy this configurations as the default: cp ~/kernel-config- uname -r ~/kernel_config This will create a new clean kernel from the default configuration.", "title": "With the kernel alias"}, {"location": "computer_science/gnu_linux/genkernel/#preserve-old-configuration", "text": "Manually this will be done with make oldconfig . If we save a kernel configuration, we can use it with newer versions (it will be automatically merged with the new kernel settings). To do so, we need to specify the old configuration to genkernel. genkernel --kernel-config=/root/kernel_config all gentoo-forums", "title": "Preserve old configuration"}, {"location": "computer_science/gnu_linux/genlop/", "text": "genlop (portage) \u2691 Usage \u2691 Estimate time of current ebuild \u2691 emerge -ciq -c : Display the currently compiling packages. -i : Extra infos for the selected package. -q : Query gentoo.linuxhowtos.org database if no local emerge was found. Estimate time of current emerge queue \u2691 emerge --resume -p | genlop -p Reference \u2691 gentoo-wiki", "title": "genlop"}, {"location": "computer_science/gnu_linux/genlop/#genlop-portage", "text": "", "title": "genlop (portage)"}, {"location": "computer_science/gnu_linux/genlop/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/genlop/#estimate-time-of-current-ebuild", "text": "emerge -ciq -c : Display the currently compiling packages. -i : Extra infos for the selected package. -q : Query gentoo.linuxhowtos.org database if no local emerge was found.", "title": "Estimate time of current ebuild"}, {"location": "computer_science/gnu_linux/genlop/#estimate-time-of-current-emerge-queue", "text": "emerge --resume -p | genlop -p", "title": "Estimate time of current emerge queue"}, {"location": "computer_science/gnu_linux/genlop/#reference", "text": "gentoo-wiki", "title": "Reference"}, {"location": "computer_science/gnu_linux/gentoo/", "text": "Gentoo \u2691 Install \u2691 /etc/portage/make.conf \u2691 Useful utillities: app-portage/cpuid2cpuflags", "title": "Gentoo"}, {"location": "computer_science/gnu_linux/gentoo/#gentoo", "text": "", "title": "Gentoo"}, {"location": "computer_science/gnu_linux/gentoo/#install", "text": "", "title": "Install"}, {"location": "computer_science/gnu_linux/gentoo/#etcportagemakeconf", "text": "Useful utillities: app-portage/cpuid2cpuflags", "title": "/etc/portage/make.conf"}, {"location": "computer_science/gnu_linux/ghostscript/", "text": "ghostscript \u2691 Compress PDF document \u2691 gs -sDEVICE=pdfwrite -dCompatibilityLevel=1.4 -dPDFSETTINGS=/screen -dNOPAUSE -dQUIET -dBATCH -sOutputFile=output.pdf input.pdf \"/screen\" is a very poor quality. For scanned documents \"/ebook\" works great. askubuntu", "title": "Ghostscript"}, {"location": "computer_science/gnu_linux/ghostscript/#ghostscript", "text": "", "title": "ghostscript"}, {"location": "computer_science/gnu_linux/ghostscript/#compress-pdf-document", "text": "gs -sDEVICE=pdfwrite -dCompatibilityLevel=1.4 -dPDFSETTINGS=/screen -dNOPAUSE -dQUIET -dBATCH -sOutputFile=output.pdf input.pdf \"/screen\" is a very poor quality. For scanned documents \"/ebook\" works great. askubuntu", "title": "Compress PDF document"}, {"location": "computer_science/gnu_linux/git/", "text": "Configuration \u2691 New repo \u2691 After running git init : git config user.name \"[username]\" git config user.email \"[email]\" git config user.signingkey \"[key ID]\" git remote add origin [remote origin] git push -u origin [branch] Autosign commits \u2691 Add the following lines to .git/config : [commit] gpgsign = true Global .gitignore file \u2691 git config --global core.excludesfile ~/.gitignore_global github-help Hooks \u2691 pre-commit \u2691 pre-commit/pre-commit is a framework for managing and maintaining multi-language pre-commit hooks. Usage \u2691 Skip specific hooks \u2691 SKIP = no-commit-to-branch pre-commit run --all-files Which is useful if a CI runs for the main branch so that it doesn't complain about running in it. Usage \u2691 Cloning \u2691 Clone a repo and its submodules \u2691 git clone --recurse-submodules -j8 [ repo ] The -jN option to fetch N submodules at parallel. For pulling the command is similar: git pull --recurse-submodules stackoverflow stackoverflow Branches \u2691 Create new branch and switch to it \u2691 git checkout -b [branch name] Delete branchs \u2691 To delete a local branch: git branch -d [branch] . To delete a remote branch: git push origin --delete [branch] makandracards Rename branch \u2691 git branch -m [ old_branch_name ] [ new_branch_name ] Fetch and track remote branches \u2691 You need to create a local branch that tracks a remote branch. git checkout --track origin/ [ branch_name ] Git fetch remote branch - Stack Overflow Commits \u2691 Revert last public commit \u2691 git revert HEAD stackoverflow Revert public merge commit \u2691 Reset to the last good commit: git reset [commit] Set everything as it was then: git reset --hard Force push: git push -f origin [branch] stackoverflow Delete last commit \u2691 git reset HEAD^ Note : this won't delete the changes made, just the commit. Also it will unstage the modified files. stackoverflow Revert to a particular commit \u2691 git reset --hard [commit-id] This will remove local changes. stackoverflow Reset file to specific revision \u2691 To reset a file to its state in a specific commit: git checkout [commit-id] -- [files...] To revert changes made to a file in a commit (reset file to its version in the immediately previous commit: git checkout [commit-id]~1 -- [files...] stackoverflow Removing sensitive data from a repository \u2691 If you commit sensitive data, such as a password or SSH key into a git repository, you can remove it from the history. To entirely remove unwanted files from a repository's history you can use git filter-branch . To force git to process the entire history of every branch and tag and remove the specified file as well as any empty commits generated as a result run: git filter-branch --force --index-filter \\ \"git rm --cached --ignore-unmatch {{path_to_file}}\" \\ --prune-empty --tag-name-filter cat -- --all Note : If the file with sensitive data used to exist at any other paths (because it was moved or renamed), you must run this command on those paths, as well. GPG signed commits \u2691 Sign last commit \u2691 git commit -S --amend Rewrite old commits \u2691 Change last commit message \u2691 To edit the message: git commit --amend Then to push it to the upstream: git push --force github-help Change author username and email \u2691 Create an alias in .gitconfig : change-commits = \"!f() { VAR=$1; OLD=$2; NEW=$3; shift 3; git filter-branch --env-filter \\\"if [[ \\\\\\\"$ echo $VAR \\\\\\\" = '$OLD' ]]; then export $VAR='$NEW'; fi\\\" $@; }; f \" Then from the repo: git change-commits GIT_AUTHOR_NAME \"old name\" \"new name\" git change-commits GIT_AUTHOR_EMAIL \"old email\" \"new email\" stackoverflow Files \u2691 Untrack file/folder but keep locally \u2691 It is a good idea to add the file/folder's path to .gitignore . Then, to remove the file/folder and its contents from git tracking: git rm [-r] --cached {path} . stackoverflow Tags \u2691 Tag current HEAD with a message and GPG sign it \u2691 git tag -a [tag] -m \"[tag message]\" -s Then, push it with: git push origin [tag] . git-doc Delete a tag local and remote \u2691 git push --delete origin [ tagname ] git tag --delete [ tagname ] stackoverflow Syncing a fork \u2691 Sync a fork of a repository to keep it up-to-date with the upstream repository. git fetch upstream git checkout master git merge upstream/master GitHub Help stash \u2691 If you have uncommitted changes and you want to switch to another branch, you can temporarily save those changes with: git stash Then, to reapply them, do: git stash pop Tips \u2691 Unstage files \u2691 git reset [file] stackoverflow Debug \u2691 Failed to delete remote branch (deletion of the current branch prohibited) \u2691 The default branch must be changed from the web repo configuration. stackoverflow Reference \u2691 Merging \u2691 mergetool \u2691 rosipov Workflow \u2691 git-scm Commits \u2691 Style \u2691 semantic commit messages Subtrees \u2691 atlassian Tips \u2691 Usuful .gitignore \u2691 github", "title": "Git"}, {"location": "computer_science/gnu_linux/git/#configuration", "text": "", "title": "Configuration"}, {"location": "computer_science/gnu_linux/git/#new-repo", "text": "After running git init : git config user.name \"[username]\" git config user.email \"[email]\" git config user.signingkey \"[key ID]\" git remote add origin [remote origin] git push -u origin [branch]", "title": "New repo"}, {"location": "computer_science/gnu_linux/git/#autosign-commits", "text": "Add the following lines to .git/config : [commit] gpgsign = true", "title": "Autosign commits"}, {"location": "computer_science/gnu_linux/git/#global-gitignore-file", "text": "git config --global core.excludesfile ~/.gitignore_global github-help", "title": "Global .gitignore file"}, {"location": "computer_science/gnu_linux/git/#hooks", "text": "", "title": "Hooks"}, {"location": "computer_science/gnu_linux/git/#pre-commit", "text": "pre-commit/pre-commit is a framework for managing and maintaining multi-language pre-commit hooks.", "title": "pre-commit"}, {"location": "computer_science/gnu_linux/git/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/git/#skip-specific-hooks", "text": "SKIP = no-commit-to-branch pre-commit run --all-files Which is useful if a CI runs for the main branch so that it doesn't complain about running in it.", "title": "Skip specific hooks"}, {"location": "computer_science/gnu_linux/git/#usage_1", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/git/#cloning", "text": "", "title": "Cloning"}, {"location": "computer_science/gnu_linux/git/#clone-a-repo-and-its-submodules", "text": "git clone --recurse-submodules -j8 [ repo ] The -jN option to fetch N submodules at parallel. For pulling the command is similar: git pull --recurse-submodules stackoverflow stackoverflow", "title": "Clone a repo and its submodules"}, {"location": "computer_science/gnu_linux/git/#branches", "text": "", "title": "Branches"}, {"location": "computer_science/gnu_linux/git/#create-new-branch-and-switch-to-it", "text": "git checkout -b [branch name]", "title": "Create new branch and switch to it"}, {"location": "computer_science/gnu_linux/git/#delete-branchs", "text": "To delete a local branch: git branch -d [branch] . To delete a remote branch: git push origin --delete [branch] makandracards", "title": "Delete branchs"}, {"location": "computer_science/gnu_linux/git/#rename-branch", "text": "git branch -m [ old_branch_name ] [ new_branch_name ]", "title": "Rename branch"}, {"location": "computer_science/gnu_linux/git/#fetch-and-track-remote-branches", "text": "You need to create a local branch that tracks a remote branch. git checkout --track origin/ [ branch_name ] Git fetch remote branch - Stack Overflow", "title": "Fetch and track remote branches"}, {"location": "computer_science/gnu_linux/git/#commits", "text": "", "title": "Commits"}, {"location": "computer_science/gnu_linux/git/#revert-last-public-commit", "text": "git revert HEAD stackoverflow", "title": "Revert last public commit"}, {"location": "computer_science/gnu_linux/git/#revert-public-merge-commit", "text": "Reset to the last good commit: git reset [commit] Set everything as it was then: git reset --hard Force push: git push -f origin [branch] stackoverflow", "title": "Revert public merge commit"}, {"location": "computer_science/gnu_linux/git/#delete-last-commit", "text": "git reset HEAD^ Note : this won't delete the changes made, just the commit. Also it will unstage the modified files. stackoverflow", "title": "Delete last commit"}, {"location": "computer_science/gnu_linux/git/#revert-to-a-particular-commit", "text": "git reset --hard [commit-id] This will remove local changes. stackoverflow", "title": "Revert to a particular commit"}, {"location": "computer_science/gnu_linux/git/#reset-file-to-specific-revision", "text": "To reset a file to its state in a specific commit: git checkout [commit-id] -- [files...] To revert changes made to a file in a commit (reset file to its version in the immediately previous commit: git checkout [commit-id]~1 -- [files...] stackoverflow", "title": "Reset file to specific revision"}, {"location": "computer_science/gnu_linux/git/#removing-sensitive-data-from-a-repository", "text": "If you commit sensitive data, such as a password or SSH key into a git repository, you can remove it from the history. To entirely remove unwanted files from a repository's history you can use git filter-branch . To force git to process the entire history of every branch and tag and remove the specified file as well as any empty commits generated as a result run: git filter-branch --force --index-filter \\ \"git rm --cached --ignore-unmatch {{path_to_file}}\" \\ --prune-empty --tag-name-filter cat -- --all Note : If the file with sensitive data used to exist at any other paths (because it was moved or renamed), you must run this command on those paths, as well.", "title": "Removing sensitive data from a repository"}, {"location": "computer_science/gnu_linux/git/#gpg-signed-commits", "text": "", "title": "GPG signed commits"}, {"location": "computer_science/gnu_linux/git/#sign-last-commit", "text": "git commit -S --amend", "title": "Sign last commit"}, {"location": "computer_science/gnu_linux/git/#rewrite-old-commits", "text": "", "title": "Rewrite old commits"}, {"location": "computer_science/gnu_linux/git/#change-last-commit-message", "text": "To edit the message: git commit --amend Then to push it to the upstream: git push --force github-help", "title": "Change last commit message"}, {"location": "computer_science/gnu_linux/git/#change-author-username-and-email", "text": "Create an alias in .gitconfig : change-commits = \"!f() { VAR=$1; OLD=$2; NEW=$3; shift 3; git filter-branch --env-filter \\\"if [[ \\\\\\\"$ echo $VAR \\\\\\\" = '$OLD' ]]; then export $VAR='$NEW'; fi\\\" $@; }; f \" Then from the repo: git change-commits GIT_AUTHOR_NAME \"old name\" \"new name\" git change-commits GIT_AUTHOR_EMAIL \"old email\" \"new email\" stackoverflow", "title": "Change author username and email"}, {"location": "computer_science/gnu_linux/git/#files", "text": "", "title": "Files"}, {"location": "computer_science/gnu_linux/git/#untrack-filefolder-but-keep-locally", "text": "It is a good idea to add the file/folder's path to .gitignore . Then, to remove the file/folder and its contents from git tracking: git rm [-r] --cached {path} . stackoverflow", "title": "Untrack file/folder but keep locally"}, {"location": "computer_science/gnu_linux/git/#tags", "text": "", "title": "Tags"}, {"location": "computer_science/gnu_linux/git/#tag-current-head-with-a-message-and-gpg-sign-it", "text": "git tag -a [tag] -m \"[tag message]\" -s Then, push it with: git push origin [tag] . git-doc", "title": "Tag current HEAD with a message and GPG sign it"}, {"location": "computer_science/gnu_linux/git/#delete-a-tag-local-and-remote", "text": "git push --delete origin [ tagname ] git tag --delete [ tagname ] stackoverflow", "title": "Delete a tag local and remote"}, {"location": "computer_science/gnu_linux/git/#syncing-a-fork", "text": "Sync a fork of a repository to keep it up-to-date with the upstream repository. git fetch upstream git checkout master git merge upstream/master GitHub Help", "title": "Syncing a fork"}, {"location": "computer_science/gnu_linux/git/#stash", "text": "If you have uncommitted changes and you want to switch to another branch, you can temporarily save those changes with: git stash Then, to reapply them, do: git stash pop", "title": "stash"}, {"location": "computer_science/gnu_linux/git/#tips", "text": "", "title": "Tips"}, {"location": "computer_science/gnu_linux/git/#unstage-files", "text": "git reset [file] stackoverflow", "title": "Unstage files"}, {"location": "computer_science/gnu_linux/git/#debug", "text": "", "title": "Debug"}, {"location": "computer_science/gnu_linux/git/#failed-to-delete-remote-branch-deletion-of-the-current-branch-prohibited", "text": "The default branch must be changed from the web repo configuration. stackoverflow", "title": "Failed to delete remote branch (deletion of the current branch prohibited)"}, {"location": "computer_science/gnu_linux/git/#reference", "text": "", "title": "Reference"}, {"location": "computer_science/gnu_linux/git/#merging", "text": "", "title": "Merging"}, {"location": "computer_science/gnu_linux/git/#mergetool", "text": "rosipov", "title": "mergetool"}, {"location": "computer_science/gnu_linux/git/#workflow", "text": "git-scm", "title": "Workflow"}, {"location": "computer_science/gnu_linux/git/#commits_1", "text": "", "title": "Commits"}, {"location": "computer_science/gnu_linux/git/#style", "text": "semantic commit messages", "title": "Style"}, {"location": "computer_science/gnu_linux/git/#subtrees", "text": "atlassian", "title": "Subtrees"}, {"location": "computer_science/gnu_linux/git/#tips_1", "text": "", "title": "Tips"}, {"location": "computer_science/gnu_linux/git/#usuful-gitignore", "text": "github", "title": "Usuful .gitignore"}, {"location": "computer_science/gnu_linux/gpg/", "text": "GPG \u2691 Reference \u2691 Usage \u2691 easyengine.io General commands. Keyservers \u2691 sks-keyservers List of SKS servers in the pool. SKS keyservers \u2691 urown.net with .onion and IPv6.", "title": "GPG"}, {"location": "computer_science/gnu_linux/gpg/#gpg", "text": "", "title": "GPG"}, {"location": "computer_science/gnu_linux/gpg/#reference", "text": "", "title": "Reference"}, {"location": "computer_science/gnu_linux/gpg/#usage", "text": "easyengine.io General commands.", "title": "Usage"}, {"location": "computer_science/gnu_linux/gpg/#keyservers", "text": "sks-keyservers List of SKS servers in the pool.", "title": "Keyservers"}, {"location": "computer_science/gnu_linux/gpg/#sks-keyservers", "text": "urown.net with .onion and IPv6.", "title": "SKS keyservers"}, {"location": "computer_science/gnu_linux/hushboard/", "text": "Hushboard is an utility that mutes your microphone while you\u2019re typing. Installation \u2691 They recommend using the Snap Store package but you can also install it manually as follows: sudo apt install libgirepository1.0-dev libcairo2-dev mkvirtualenv hushboard git clone https://github.com/stuartlangridge/hushboard cd hushboard pip install pycairo PyGObject six xlib pip install . deactivate Running the application \u2691 You can run it manually as follows workon hushboard python -m hushboard deactivate Or if you use i3wm , create the following script #!/usr/bin/env bash source { WORKON_PATH } /hushboard/bin/activate python -m hushboard deactivate You should replace {WORKON_PATH} with your virtual environments path. Then add this line to your i3wm configuration file to start it automatically. exec --no-startup-id ~/scripts/hushboard.sh Notes \u2691 mkvirtualenv , deactivate and workon are part of virtualenvwrapper .", "title": "Hushboard"}, {"location": "computer_science/gnu_linux/hushboard/#installation", "text": "They recommend using the Snap Store package but you can also install it manually as follows: sudo apt install libgirepository1.0-dev libcairo2-dev mkvirtualenv hushboard git clone https://github.com/stuartlangridge/hushboard cd hushboard pip install pycairo PyGObject six xlib pip install . deactivate", "title": "Installation"}, {"location": "computer_science/gnu_linux/hushboard/#running-the-application", "text": "You can run it manually as follows workon hushboard python -m hushboard deactivate Or if you use i3wm , create the following script #!/usr/bin/env bash source { WORKON_PATH } /hushboard/bin/activate python -m hushboard deactivate You should replace {WORKON_PATH} with your virtual environments path. Then add this line to your i3wm configuration file to start it automatically. exec --no-startup-id ~/scripts/hushboard.sh", "title": "Running the application"}, {"location": "computer_science/gnu_linux/hushboard/#notes", "text": "mkvirtualenv , deactivate and workon are part of virtualenvwrapper .", "title": "Notes"}, {"location": "computer_science/gnu_linux/i3wm/", "text": "Tips \u2691 Floating applications \u2691 for_window [class=\"Nautilus\" instance=\"file_progress\"] floating enable i3wm-faq Move workspaces between monitors \u2691 # move focused workspace between monitors bindsym $mod+Ctrl+greater move workspace to output right bindsym $mod+Ctrl+less move workspace to output left stackoverflow How to get rid of the spinning wheel \u2691 Run exec and exec_always with --no-startup-id if the command won't generate a window, otherwise the spinning wheel will get stuck and appear instead of the normal mouse icon.", "title": "i3 window manager"}, {"location": "computer_science/gnu_linux/i3wm/#tips", "text": "", "title": "Tips"}, {"location": "computer_science/gnu_linux/i3wm/#floating-applications", "text": "for_window [class=\"Nautilus\" instance=\"file_progress\"] floating enable i3wm-faq", "title": "Floating applications"}, {"location": "computer_science/gnu_linux/i3wm/#move-workspaces-between-monitors", "text": "# move focused workspace between monitors bindsym $mod+Ctrl+greater move workspace to output right bindsym $mod+Ctrl+less move workspace to output left stackoverflow", "title": "Move workspaces between monitors"}, {"location": "computer_science/gnu_linux/i3wm/#how-to-get-rid-of-the-spinning-wheel", "text": "Run exec and exec_always with --no-startup-id if the command won't generate a window, otherwise the spinning wheel will get stuck and appear instead of the normal mouse icon.", "title": "How to get rid of the spinning wheel"}, {"location": "computer_science/gnu_linux/ibus/", "text": "IBus \u2691 Config \u2691 Initial Setup \u2691 Run ibus-setup . If ibus-daemon doesn't start automatically, add the following command to your ~/.xinitrc : # Start IBus daemon ibus-daemon -drx Reference \u2691 ArchWiki", "title": "ibus"}, {"location": "computer_science/gnu_linux/ibus/#ibus", "text": "", "title": "IBus"}, {"location": "computer_science/gnu_linux/ibus/#config", "text": "", "title": "Config"}, {"location": "computer_science/gnu_linux/ibus/#initial-setup", "text": "Run ibus-setup . If ibus-daemon doesn't start automatically, add the following command to your ~/.xinitrc : # Start IBus daemon ibus-daemon -drx", "title": "Initial Setup"}, {"location": "computer_science/gnu_linux/ibus/#reference", "text": "ArchWiki", "title": "Reference"}, {"location": "computer_science/gnu_linux/imagemagick/", "text": "Screenshots \u2691 Make a screenshot of a selection \u2691 import [output.png] stackexchange-unix Conversions \u2691 Image to PDF \u2691 convert [image] [output].pdf stackoverflow Resize and compress \u2691 Resize an image to width 1000 px and compress it with a JPG quality level of 80% in place: mogrify -quality 1000 -resize 80 file.jpg", "title": "ImageMagick"}, {"location": "computer_science/gnu_linux/imagemagick/#screenshots", "text": "", "title": "Screenshots"}, {"location": "computer_science/gnu_linux/imagemagick/#make-a-screenshot-of-a-selection", "text": "import [output.png] stackexchange-unix", "title": "Make a screenshot of a selection"}, {"location": "computer_science/gnu_linux/imagemagick/#conversions", "text": "", "title": "Conversions"}, {"location": "computer_science/gnu_linux/imagemagick/#image-to-pdf", "text": "convert [image] [output].pdf stackoverflow", "title": "Image to PDF"}, {"location": "computer_science/gnu_linux/imagemagick/#resize-and-compress", "text": "Resize an image to width 1000 px and compress it with a JPG quality level of 80% in place: mogrify -quality 1000 -resize 80 file.jpg", "title": "Resize and compress"}, {"location": "computer_science/gnu_linux/iostat/", "text": "iostat \u2691 Usage \u2691 Monitor all disks with extended statistics \u2691 iostat -d -x 3 3 -d : Display the device utilization report. -x : Display extended statistics. 3 : Interval. 3 : Count. serverfault", "title": "iostat"}, {"location": "computer_science/gnu_linux/iostat/#iostat", "text": "", "title": "iostat"}, {"location": "computer_science/gnu_linux/iostat/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/iostat/#monitor-all-disks-with-extended-statistics", "text": "iostat -d -x 3 3 -d : Display the device utilization report. -x : Display extended statistics. 3 : Interval. 3 : Count. serverfault", "title": "Monitor all disks with extended statistics"}, {"location": "computer_science/gnu_linux/iptables/", "text": "iptables \u2691 Usage \u2691 Allow from range from an interface to an specific port \u2691 iptables -A INPUT -p tcp -i [interface] -s [range] --dport [port] -j ACCEPT serverfault Install \u2691 iptables-persistent \u2691 When installed, it will save the current rules. If you want to save more afterwards, you have to manually save them: iptables-save >/etc/iptables/rules.v4 stackexchange-unix Tips \u2691 Clear all rules and allow all traffic \u2691 iptables -F iptables -X iptables -t nat -F iptables -t nat -X iptables -t mangle -F iptables -t mangle -X iptables -P INPUT ACCEPT iptables -P FORWARD ACCEPT iptables -P OUTPUT ACCEPT adminsehow", "title": "iptables"}, {"location": "computer_science/gnu_linux/iptables/#iptables", "text": "", "title": "iptables"}, {"location": "computer_science/gnu_linux/iptables/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/iptables/#allow-from-range-from-an-interface-to-an-specific-port", "text": "iptables -A INPUT -p tcp -i [interface] -s [range] --dport [port] -j ACCEPT serverfault", "title": "Allow from range from an interface to an specific port"}, {"location": "computer_science/gnu_linux/iptables/#install", "text": "", "title": "Install"}, {"location": "computer_science/gnu_linux/iptables/#iptables-persistent", "text": "When installed, it will save the current rules. If you want to save more afterwards, you have to manually save them: iptables-save >/etc/iptables/rules.v4 stackexchange-unix", "title": "iptables-persistent"}, {"location": "computer_science/gnu_linux/iptables/#tips", "text": "", "title": "Tips"}, {"location": "computer_science/gnu_linux/iptables/#clear-all-rules-and-allow-all-traffic", "text": "iptables -F iptables -X iptables -t nat -F iptables -t nat -X iptables -t mangle -F iptables -t mangle -X iptables -P INPUT ACCEPT iptables -P FORWARD ACCEPT iptables -P OUTPUT ACCEPT adminsehow", "title": "Clear all rules and allow all traffic"}, {"location": "computer_science/gnu_linux/isync/", "text": "isync \u2691 Reference \u2691 arch-wiki", "title": "isync"}, {"location": "computer_science/gnu_linux/isync/#isync", "text": "", "title": "isync"}, {"location": "computer_science/gnu_linux/isync/#reference", "text": "arch-wiki", "title": "Reference"}, {"location": "computer_science/gnu_linux/jabber/", "text": "Jabber \u2691 Reference \u2691 Utilities \u2691 simpleupload Script to upload files to jabber servers with HTTP Upload (XEP-0363) enabled. Testing \u2691 messaging.one Test XMPP server capabilities and configurations. ssl test", "title": "Jabber"}, {"location": "computer_science/gnu_linux/jabber/#jabber", "text": "", "title": "Jabber"}, {"location": "computer_science/gnu_linux/jabber/#reference", "text": "", "title": "Reference"}, {"location": "computer_science/gnu_linux/jabber/#utilities", "text": "simpleupload Script to upload files to jabber servers with HTTP Upload (XEP-0363) enabled.", "title": "Utilities"}, {"location": "computer_science/gnu_linux/jabber/#testing", "text": "messaging.one Test XMPP server capabilities and configurations. ssl test", "title": "Testing"}, {"location": "computer_science/gnu_linux/java/", "text": "Java \u2691 Debug \u2691 org.junit cannot be resolved \u2691 Right click on the eclipse project and navigate: Properties -> Java Build Path -> Libraries -> Add Library -> JUnit -> Junit 3/ stackoverflow", "title": "Java"}, {"location": "computer_science/gnu_linux/java/#java", "text": "", "title": "Java"}, {"location": "computer_science/gnu_linux/java/#debug", "text": "", "title": "Debug"}, {"location": "computer_science/gnu_linux/java/#orgjunit-cannot-be-resolved", "text": "Right click on the eclipse project and navigate: Properties -> Java Build Path -> Libraries -> Add Library -> JUnit -> Junit 3/ stackoverflow", "title": "org.junit cannot be resolved"}, {"location": "computer_science/gnu_linux/jmtpfs/", "text": "jmtpfs is a FUSE and libmtp based filesystem for accessing MTP (Media Transfer Protocol) devices. Install \u2691 apt install jmtpfs Usage \u2691 Plug your Android device and enable file transfer, then from the computer: jmtpfs { mountdir }", "title": "jmtpfs"}, {"location": "computer_science/gnu_linux/jmtpfs/#install", "text": "apt install jmtpfs", "title": "Install"}, {"location": "computer_science/gnu_linux/jmtpfs/#usage", "text": "Plug your Android device and enable file transfer, then from the computer: jmtpfs { mountdir }", "title": "Usage"}, {"location": "computer_science/gnu_linux/jpegoptim/", "text": "jpegoptim: JPEG image optimizer and compressor \u2691 Usage \u2691 Compress to a certain size \u2691 jpegoptim --size = 250k [ image ] tecmint", "title": "jpegoptim"}, {"location": "computer_science/gnu_linux/jpegoptim/#jpegoptim-jpeg-image-optimizer-and-compressor", "text": "", "title": "jpegoptim: JPEG image optimizer and compressor"}, {"location": "computer_science/gnu_linux/jpegoptim/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/jpegoptim/#compress-to-a-certain-size", "text": "jpegoptim --size = 250k [ image ] tecmint", "title": "Compress to a certain size"}, {"location": "computer_science/gnu_linux/kali/", "text": "Kali Linux \u2691 Install \u2691 Live USB with encrypted persistence \u2691 Download an flash latest version from kali-downloads . Then: usb = /dev/sdc3 echo $usb # just in case... parted /dev/sdb mkpart primary 3000 100 % cryptsetup --verbose --verify-passphrase luksFormat $usb cryptsetup luksOpen $usb my_usb mkfs.ext3 -L persistence $usb e2label $usb persistence mkdir -p /mnt/my_usb mount /dev/mapper/my_usb /mnt/my_usb echo \"/ union\" > /mnt/my_usb/persistence.conf umount /dev/mapper/my_usb cryptsetup luksClose /dev/mapper/my_usb kali-docs", "title": "Kali"}, {"location": "computer_science/gnu_linux/kali/#kali-linux", "text": "", "title": "Kali Linux"}, {"location": "computer_science/gnu_linux/kali/#install", "text": "", "title": "Install"}, {"location": "computer_science/gnu_linux/kali/#live-usb-with-encrypted-persistence", "text": "Download an flash latest version from kali-downloads . Then: usb = /dev/sdc3 echo $usb # just in case... parted /dev/sdb mkpart primary 3000 100 % cryptsetup --verbose --verify-passphrase luksFormat $usb cryptsetup luksOpen $usb my_usb mkfs.ext3 -L persistence $usb e2label $usb persistence mkdir -p /mnt/my_usb mount /dev/mapper/my_usb /mnt/my_usb echo \"/ union\" > /mnt/my_usb/persistence.conf umount /dev/mapper/my_usb cryptsetup luksClose /dev/mapper/my_usb kali-docs", "title": "Live USB with encrypted persistence"}, {"location": "computer_science/gnu_linux/kernel/", "text": "Linux kernel \u2691 Usage \u2691 Load modules at boot \u2691 Add the desired modules in /etc/conf.d/modules : modules=\"[...]\" supreuser Tips \u2691 Remove old kernels in gentoo \u2691 Remove the source directory: rm -r /usr/src/linux-4.X.Y . Remove the modules: rm -r /lib/modules/4.X.Y . Remove the files in /boot coresponding to the old kernel. E.g: vmlinuz , initramfs , kernel , config , initramfs ... gentoo-wiki", "title": "Kernel"}, {"location": "computer_science/gnu_linux/kernel/#linux-kernel", "text": "", "title": "Linux kernel"}, {"location": "computer_science/gnu_linux/kernel/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/kernel/#load-modules-at-boot", "text": "Add the desired modules in /etc/conf.d/modules : modules=\"[...]\" supreuser", "title": "Load modules at boot"}, {"location": "computer_science/gnu_linux/kernel/#tips", "text": "", "title": "Tips"}, {"location": "computer_science/gnu_linux/kernel/#remove-old-kernels-in-gentoo", "text": "Remove the source directory: rm -r /usr/src/linux-4.X.Y . Remove the modules: rm -r /lib/modules/4.X.Y . Remove the files in /boot coresponding to the old kernel. E.g: vmlinuz , initramfs , kernel , config , initramfs ... gentoo-wiki", "title": "Remove old kernels in gentoo"}, {"location": "computer_science/gnu_linux/keyboard/", "text": "Configuration \u2691 My favorite layout is altgr-intl because it is based on the standard US layout, which is comfortable for programming and allows me to write accents on letters (required for Spanish and French). And by adding some modifications it can be used for Turkish too. To enable this layout, edit /etc/default/keyboard and add the following content # KEYBOARD CONFIGURATION FILE # Consult the keyboard(5) manual page. XKBMODEL = \"pc105\" XKBLAYOUT = \"us\" XKBVARIANT = \"intl\" XKBOPTIONS = \"caps:ctrl_modifier, shift:both_shiftlock\" BACKSPACE = \"guess\" With this you'll get the mentioned layout with some extra options, that make the Caps Lock key behave as Ctrl and both Shift keys pressed at the same time as Caps Lock . Additionaly, the Caps Lock key (which is now mapped as Ctrl ) can act as Esc if pressed alone. To do so, install xcape and execute the following command xcape -e 'Caps_Lock=Escape' You can execute this command after login by adding it to your ~/.config/i3/config or in ~/.profile . Turkish support \u2691 Turkish has a few letters that are not included by default in this layout, but they can be added easily. We'll add the following mappings: \u015f: AltGr + s (and caps available with Shift) \u011f: AltGr + g (and caps available with Shift) \u0131: AltGr + j \u0130: AltGr + Shift + j \u00e7: AltGr + c (and caps available with Shift) To add this mapping, create ~/.xmodmaprc and add keycode 39 = s S s S scedilla Scedilla scedilla Scedilla keycode 42 = g G g G gbreve Gbreve gbreve Gbreve keycode 44 = j J j J idotless Iabovedot idotless Iabovedot keycode 54 = c C c C ccedilla Ccedilla ccedilla Ccedilla You can get the current mappings with xmodmap -pke Execute xmodmap ~/.xmodmaprc before the xcode command.", "title": "Keyboard"}, {"location": "computer_science/gnu_linux/keyboard/#configuration", "text": "My favorite layout is altgr-intl because it is based on the standard US layout, which is comfortable for programming and allows me to write accents on letters (required for Spanish and French). And by adding some modifications it can be used for Turkish too. To enable this layout, edit /etc/default/keyboard and add the following content # KEYBOARD CONFIGURATION FILE # Consult the keyboard(5) manual page. XKBMODEL = \"pc105\" XKBLAYOUT = \"us\" XKBVARIANT = \"intl\" XKBOPTIONS = \"caps:ctrl_modifier, shift:both_shiftlock\" BACKSPACE = \"guess\" With this you'll get the mentioned layout with some extra options, that make the Caps Lock key behave as Ctrl and both Shift keys pressed at the same time as Caps Lock . Additionaly, the Caps Lock key (which is now mapped as Ctrl ) can act as Esc if pressed alone. To do so, install xcape and execute the following command xcape -e 'Caps_Lock=Escape' You can execute this command after login by adding it to your ~/.config/i3/config or in ~/.profile .", "title": "Configuration"}, {"location": "computer_science/gnu_linux/keyboard/#turkish-support", "text": "Turkish has a few letters that are not included by default in this layout, but they can be added easily. We'll add the following mappings: \u015f: AltGr + s (and caps available with Shift) \u011f: AltGr + g (and caps available with Shift) \u0131: AltGr + j \u0130: AltGr + Shift + j \u00e7: AltGr + c (and caps available with Shift) To add this mapping, create ~/.xmodmaprc and add keycode 39 = s S s S scedilla Scedilla scedilla Scedilla keycode 42 = g G g G gbreve Gbreve gbreve Gbreve keycode 44 = j J j J idotless Iabovedot idotless Iabovedot keycode 54 = c C c C ccedilla Ccedilla ccedilla Ccedilla You can get the current mappings with xmodmap -pke Execute xmodmap ~/.xmodmaprc before the xcode command.", "title": "Turkish support"}, {"location": "computer_science/gnu_linux/khal/", "text": "Khal \u2691 Reference \u2691 eric-scheibler", "title": "Khal"}, {"location": "computer_science/gnu_linux/khal/#khal", "text": "", "title": "Khal"}, {"location": "computer_science/gnu_linux/khal/#reference", "text": "eric-scheibler", "title": "Reference"}, {"location": "computer_science/gnu_linux/khard/", "text": "Khard: Console carddav client \u2691 Reference \u2691 github", "title": "Khard"}, {"location": "computer_science/gnu_linux/khard/#khard-console-carddav-client", "text": "", "title": "Khard: Console carddav client"}, {"location": "computer_science/gnu_linux/khard/#reference", "text": "github", "title": "Reference"}, {"location": "computer_science/gnu_linux/kodi/", "text": "Kodi \u2691 Configuration \u2691 Autostart \u2691 So you were able to install Kodi via \"sudo apt-get install kodi\" but have no idea how to force it to autostart on boot? You have tried all those googled solutions such as adding kodi-standalone to .bashrc, creating init.d script but nothing worked? Try with this gist .", "title": "Kodi"}, {"location": "computer_science/gnu_linux/kodi/#kodi", "text": "", "title": "Kodi"}, {"location": "computer_science/gnu_linux/kodi/#configuration", "text": "", "title": "Configuration"}, {"location": "computer_science/gnu_linux/kodi/#autostart", "text": "So you were able to install Kodi via \"sudo apt-get install kodi\" but have no idea how to force it to autostart on boot? You have tried all those googled solutions such as adding kodi-standalone to .bashrc, creating init.d script but nothing worked? Try with this gist .", "title": "Autostart"}, {"location": "computer_science/gnu_linux/latex/", "text": "Cheatsheet \u2691 Style \u2691 Use point as the decimal separator: \\decimalpoint . stackexchange Greek letters \u2691 epsilon: \\varepsilon $ \\varepsilon $ rho: \\rho $ \\rho $ phi: \\phi $ \\phi $ Not greek, but related: Nabla: \\nabla $ \\nabla $ uib wikipedia Math \u2691 Vectors \u2691 Unit vectors: \\hat{v} $ \\hat{v} $ Integrals \u2691 Triple integrals: \\iiint xyz dxdydz $ \\iiint xyz dxdydz $ Closed integrals \u2691 Using packages asmath and esint . \\oiint $ \\oiint $ stackexchange-tex Quotation \u2691 To quote some text you can't directly use \"\", you should wrap it around `` and '' instead. stackexchange Rename tables names in Spanish \u2691 By default, the caption of a table will start with \u201cCuadro: \u201d when using \\usepackage[spanish]{babel} . if you want to change it to something else, for example \u201cTabla: \u201d add the following lines after \\begin{document} : % Cambiar Cuadros por Tablas y lista de... \\renewcommand { \\listtablename }{ \u00cdndice de tablas } \\renewcommand { \\tablename }{ Tabla } Usage \u2691 Plugins \u2691 Minted \u2691 Import code from file \u2691 \\inputminted { <lang> }{ <file> } stackexchange Figures \u2691 Tips \u2691 To ensure figures appear before certain point, use placeins . For example: \\usepackage [section] { placeins } % ... some floats here ... \\FloatBarrier Reference \u2691 Packages \u2691 ConTeXt To include .svg diagrams directly. minted To enable syntax highlighting, supports VHDL. TikZ A Portable Graphic Format for TeX", "title": "Latex"}, {"location": "computer_science/gnu_linux/latex/#cheatsheet", "text": "", "title": "Cheatsheet"}, {"location": "computer_science/gnu_linux/latex/#style", "text": "Use point as the decimal separator: \\decimalpoint . stackexchange", "title": "Style"}, {"location": "computer_science/gnu_linux/latex/#greek-letters", "text": "epsilon: \\varepsilon $ \\varepsilon $ rho: \\rho $ \\rho $ phi: \\phi $ \\phi $ Not greek, but related: Nabla: \\nabla $ \\nabla $ uib wikipedia", "title": "Greek letters"}, {"location": "computer_science/gnu_linux/latex/#math", "text": "", "title": "Math"}, {"location": "computer_science/gnu_linux/latex/#vectors", "text": "Unit vectors: \\hat{v} $ \\hat{v} $", "title": "Vectors"}, {"location": "computer_science/gnu_linux/latex/#integrals", "text": "Triple integrals: \\iiint xyz dxdydz $ \\iiint xyz dxdydz $", "title": "Integrals"}, {"location": "computer_science/gnu_linux/latex/#closed-integrals", "text": "Using packages asmath and esint . \\oiint $ \\oiint $ stackexchange-tex", "title": "Closed integrals"}, {"location": "computer_science/gnu_linux/latex/#quotation", "text": "To quote some text you can't directly use \"\", you should wrap it around `` and '' instead. stackexchange", "title": "Quotation"}, {"location": "computer_science/gnu_linux/latex/#rename-tables-names-in-spanish", "text": "By default, the caption of a table will start with \u201cCuadro: \u201d when using \\usepackage[spanish]{babel} . if you want to change it to something else, for example \u201cTabla: \u201d add the following lines after \\begin{document} : % Cambiar Cuadros por Tablas y lista de... \\renewcommand { \\listtablename }{ \u00cdndice de tablas } \\renewcommand { \\tablename }{ Tabla }", "title": "Rename tables names in Spanish"}, {"location": "computer_science/gnu_linux/latex/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/latex/#plugins", "text": "", "title": "Plugins"}, {"location": "computer_science/gnu_linux/latex/#minted", "text": "", "title": "Minted"}, {"location": "computer_science/gnu_linux/latex/#import-code-from-file", "text": "\\inputminted { <lang> }{ <file> } stackexchange", "title": "Import code from file"}, {"location": "computer_science/gnu_linux/latex/#figures", "text": "", "title": "Figures"}, {"location": "computer_science/gnu_linux/latex/#tips", "text": "To ensure figures appear before certain point, use placeins . For example: \\usepackage [section] { placeins } % ... some floats here ... \\FloatBarrier", "title": "Tips"}, {"location": "computer_science/gnu_linux/latex/#reference", "text": "", "title": "Reference"}, {"location": "computer_science/gnu_linux/latex/#packages", "text": "ConTeXt To include .svg diagrams directly. minted To enable syntax highlighting, supports VHDL. TikZ A Portable Graphic Format for TeX", "title": "Packages"}, {"location": "computer_science/gnu_linux/layman/", "text": "Gentoo \u2691 Referenc \u2691 General usage \u2691 gentoo-wiki", "title": "Layman"}, {"location": "computer_science/gnu_linux/layman/#gentoo", "text": "", "title": "Gentoo"}, {"location": "computer_science/gnu_linux/layman/#referenc", "text": "", "title": "Referenc"}, {"location": "computer_science/gnu_linux/layman/#general-usage", "text": "gentoo-wiki", "title": "General usage"}, {"location": "computer_science/gnu_linux/letsencrypt/", "text": "Usage \u2691 Request a new certificate \u2691 If there is no HTTP sever running: certbot certonly --standalone --preferred-challenges http-01 -d {{ domain }} --register-unsafely-without-email --agree-tos -n If there is an HTTP running: certonly --webroot -w {{ web_path_letsencrypt }} --preferred-challenges http-01 -d {{ domain }} --register-unsafely-without-email --agree-tos -n", "title": "Let\\'s Encrypt"}, {"location": "computer_science/gnu_linux/letsencrypt/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/letsencrypt/#request-a-new-certificate", "text": "If there is no HTTP sever running: certbot certonly --standalone --preferred-challenges http-01 -d {{ domain }} --register-unsafely-without-email --agree-tos -n If there is an HTTP running: certonly --webroot -w {{ web_path_letsencrypt }} --preferred-challenges http-01 -d {{ domain }} --register-unsafely-without-email --agree-tos -n", "title": "Request a new certificate"}, {"location": "computer_science/gnu_linux/libreoffice/", "text": "Libre Office \u2691 Writer \u2691 Toggle Track Changes mode \u2691 Useful to see the changes made or the final document. Open the document to be edited and choose Edit - Track Changes and then choose Show . libreoffice-doc", "title": "LibreOffice"}, {"location": "computer_science/gnu_linux/libreoffice/#libre-office", "text": "", "title": "Libre Office"}, {"location": "computer_science/gnu_linux/libreoffice/#writer", "text": "", "title": "Writer"}, {"location": "computer_science/gnu_linux/libreoffice/#toggle-track-changes-mode", "text": "Useful to see the changes made or the final document. Open the document to be edited and choose Edit - Track Changes and then choose Show . libreoffice-doc", "title": "Toggle Track Changes mode"}, {"location": "computer_science/gnu_linux/lightdm/", "text": "lightDM \u2691 Debug \u2691 Fix boot fail \u2691 When booting, no X session and error in the boot log: /etc/X11/startDM.sh: line 22: get_options: command not found . Solution : add /lib/rc/bin/ to ROOTPATH : echo \"ROOTPATH=\\\"/lib/rc/bin\\\"\" >/etc/env.d/99local gentoo-forum", "title": "LightDM"}, {"location": "computer_science/gnu_linux/lightdm/#lightdm", "text": "", "title": "lightDM"}, {"location": "computer_science/gnu_linux/lightdm/#debug", "text": "", "title": "Debug"}, {"location": "computer_science/gnu_linux/lightdm/#fix-boot-fail", "text": "When booting, no X session and error in the boot log: /etc/X11/startDM.sh: line 22: get_options: command not found . Solution : add /lib/rc/bin/ to ROOTPATH : echo \"ROOTPATH=\\\"/lib/rc/bin\\\"\" >/etc/env.d/99local gentoo-forum", "title": "Fix boot fail"}, {"location": "computer_science/gnu_linux/linux/", "text": "linux \u2691 CPU \u2691 Change scaling governor \u2691 for c in $(ls -d /sys/devices/system/cpu/cpu[0-9]*); do echo ondemand >$c/cpufreq/scaling_governor; done gentoo-wiki Change CPU maximum frequency \u2691 for c in $(ls -d /sys/devices/system/cpu/cpu[0-9]*); do echo [freq (Hz)] >$c/cpufreq/scaling_max_freq; done Users and Groups \u2691 Groups \u2691 You can check the groups and their members in /etc/groups . There's also an utility called members . cyberciti", "title": "Linux"}, {"location": "computer_science/gnu_linux/linux/#linux", "text": "", "title": "linux"}, {"location": "computer_science/gnu_linux/linux/#cpu", "text": "", "title": "CPU"}, {"location": "computer_science/gnu_linux/linux/#change-scaling-governor", "text": "for c in $(ls -d /sys/devices/system/cpu/cpu[0-9]*); do echo ondemand >$c/cpufreq/scaling_governor; done gentoo-wiki", "title": "Change scaling governor"}, {"location": "computer_science/gnu_linux/linux/#change-cpu-maximum-frequency", "text": "for c in $(ls -d /sys/devices/system/cpu/cpu[0-9]*); do echo [freq (Hz)] >$c/cpufreq/scaling_max_freq; done", "title": "Change CPU maximum frequency"}, {"location": "computer_science/gnu_linux/linux/#users-and-groups", "text": "", "title": "Users and Groups"}, {"location": "computer_science/gnu_linux/linux/#groups", "text": "You can check the groups and their members in /etc/groups . There's also an utility called members . cyberciti", "title": "Groups"}, {"location": "computer_science/gnu_linux/luks/", "text": "Usage \u2691 Setup ciphered disk with partitions \u2691 cryptsetup -v --cipher aes-xts-plain64 --key-size 512 --hash sha512 --iter-time 5000 --use-random --verify-passphrase luksFormat [device] cryptsetup luksOpen [device] [mountpoint_name] Create partitions and format. archlinux-wiki Add a keyfile \u2691 First, create the keyfile with dd bs = 512 count = 4 if = /dev/random of = /etc/mykeyfile iflag = fullblock This will generate a keyfile of 2048 random bytes in the specified location. Then, set the proper permissions with chmod 600 /etc/mykeyfile Then, add the keyfile to the LUKS header with cryptsetup luksAddKey { luks_partitition } /etc/mykeyfile Change the passphrase \u2691 To change a passphrase of a LUKS device to another: cryptsetup luksChangeKey { device } You will be prompted for the old passphrase and the new one twice. The device can be unlocked and in-use while changing the password. Reference \u2691 howtoforge Automatically unlock LUKS drives. How to Change Your LUKS Encryption Passphrase - Make Tech Easier", "title": "LUKS"}, {"location": "computer_science/gnu_linux/luks/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/luks/#setup-ciphered-disk-with-partitions", "text": "cryptsetup -v --cipher aes-xts-plain64 --key-size 512 --hash sha512 --iter-time 5000 --use-random --verify-passphrase luksFormat [device] cryptsetup luksOpen [device] [mountpoint_name] Create partitions and format. archlinux-wiki", "title": "Setup ciphered disk with partitions"}, {"location": "computer_science/gnu_linux/luks/#add-a-keyfile", "text": "First, create the keyfile with dd bs = 512 count = 4 if = /dev/random of = /etc/mykeyfile iflag = fullblock This will generate a keyfile of 2048 random bytes in the specified location. Then, set the proper permissions with chmod 600 /etc/mykeyfile Then, add the keyfile to the LUKS header with cryptsetup luksAddKey { luks_partitition } /etc/mykeyfile", "title": "Add a keyfile"}, {"location": "computer_science/gnu_linux/luks/#change-the-passphrase", "text": "To change a passphrase of a LUKS device to another: cryptsetup luksChangeKey { device } You will be prompted for the old passphrase and the new one twice. The device can be unlocked and in-use while changing the password.", "title": "Change the passphrase"}, {"location": "computer_science/gnu_linux/luks/#reference", "text": "howtoforge Automatically unlock LUKS drives. How to Change Your LUKS Encryption Passphrase - Make Tech Easier", "title": "Reference"}, {"location": "computer_science/gnu_linux/lvm/", "text": "LVM \u2691 Usage \u2691 Display the physical volumes and the logical volumes they conatain \u2691 pvdisplay -m serverfault Create new physical volume \u2691 The device must have an empty partition table or if it's a partition, it should have the 0x8e identifier (for LVM). You can achieve this things with fdisk . Once ready: pvcreate [ device ] centos Move physical extents between physical volumes \u2691 This is useful if you want an already existing LV to be on a specific PV. pvmove /dev/sda1:1000-1999 /dev/sdb1:0-999 superuser Create a logical volume \u2691 lvcreate -n [ lv name ] -L [ size in gigabytes ] g [ vg name ] Then format it and mount it if requiered. debian wiki Extend LV and filesystem \u2691 To extend the logical volume and the filesystem in it use: lvresize --resizefs --size +931GB /dev/vg/lv_home When extending, the filesystem can be mounted, but not when shrinking. systutorials Reference \u2691 redhat", "title": "LVM"}, {"location": "computer_science/gnu_linux/lvm/#lvm", "text": "", "title": "LVM"}, {"location": "computer_science/gnu_linux/lvm/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/lvm/#display-the-physical-volumes-and-the-logical-volumes-they-conatain", "text": "pvdisplay -m serverfault", "title": "Display the physical volumes and the logical volumes they conatain"}, {"location": "computer_science/gnu_linux/lvm/#create-new-physical-volume", "text": "The device must have an empty partition table or if it's a partition, it should have the 0x8e identifier (for LVM). You can achieve this things with fdisk . Once ready: pvcreate [ device ] centos", "title": "Create new physical volume"}, {"location": "computer_science/gnu_linux/lvm/#move-physical-extents-between-physical-volumes", "text": "This is useful if you want an already existing LV to be on a specific PV. pvmove /dev/sda1:1000-1999 /dev/sdb1:0-999 superuser", "title": "Move physical extents between physical volumes"}, {"location": "computer_science/gnu_linux/lvm/#create-a-logical-volume", "text": "lvcreate -n [ lv name ] -L [ size in gigabytes ] g [ vg name ] Then format it and mount it if requiered. debian wiki", "title": "Create a logical volume"}, {"location": "computer_science/gnu_linux/lvm/#extend-lv-and-filesystem", "text": "To extend the logical volume and the filesystem in it use: lvresize --resizefs --size +931GB /dev/vg/lv_home When extending, the filesystem can be mounted, but not when shrinking. systutorials", "title": "Extend LV and filesystem"}, {"location": "computer_science/gnu_linux/lvm/#reference", "text": "redhat", "title": "Reference"}, {"location": "computer_science/gnu_linux/mail/", "text": "Tips \u2691 Mark all messages as read \u2691 Execute mail and then: t * and as many q s as needed.", "title": "mail"}, {"location": "computer_science/gnu_linux/mail/#tips", "text": "", "title": "Tips"}, {"location": "computer_science/gnu_linux/mail/#mark-all-messages-as-read", "text": "Execute mail and then: t * and as many q s as needed.", "title": "Mark all messages as read"}, {"location": "computer_science/gnu_linux/makefile/", "text": "Configuration \u2691 Paralelize steps \u2691 Add the following lines to the beginning of the Makefile : NPROCS = $( shell grep -c 'processor' /proc/cpuinfo ) MAKEFLAGS += -j $( NPROCS )", "title": "Makefile"}, {"location": "computer_science/gnu_linux/makefile/#configuration", "text": "", "title": "Configuration"}, {"location": "computer_science/gnu_linux/makefile/#paralelize-steps", "text": "Add the following lines to the beginning of the Makefile : NPROCS = $( shell grep -c 'processor' /proc/cpuinfo ) MAKEFLAGS += -j $( NPROCS )", "title": "Paralelize steps"}, {"location": "computer_science/gnu_linux/mariadb/", "text": "Tips \u2691 Gain root access without the password \u2691 This can be useful for resetting the password or just for performing privileged actions without entering the root password. Start the database in the background without loading the grant tables or enabling networking: mysqld_safe --skip-grant-tables --skip-networking & Then access it with: mysql -u root", "title": "MariaDB"}, {"location": "computer_science/gnu_linux/mariadb/#tips", "text": "", "title": "Tips"}, {"location": "computer_science/gnu_linux/mariadb/#gain-root-access-without-the-password", "text": "This can be useful for resetting the password or just for performing privileged actions without entering the root password. Start the database in the background without loading the grant tables or enabling networking: mysqld_safe --skip-grant-tables --skip-networking & Then access it with: mysql -u root", "title": "Gain root access without the password"}, {"location": "computer_science/gnu_linux/markdown/", "text": "markdown \u2691 Reference \u2691 reveal-md Create slides from MarkDown. Cheatsheets \u2691 adam-p Lint \u2691 github", "title": "MarkDown"}, {"location": "computer_science/gnu_linux/markdown/#markdown", "text": "", "title": "markdown"}, {"location": "computer_science/gnu_linux/markdown/#reference", "text": "reveal-md Create slides from MarkDown.", "title": "Reference"}, {"location": "computer_science/gnu_linux/markdown/#cheatsheets", "text": "adam-p", "title": "Cheatsheets"}, {"location": "computer_science/gnu_linux/markdown/#lint", "text": "github", "title": "Lint"}, {"location": "computer_science/gnu_linux/mathjax/", "text": "MathJax \u2691 Reference \u2691 Supported symbols : mathjax-doc", "title": "MathJax"}, {"location": "computer_science/gnu_linux/mathjax/#mathjax", "text": "", "title": "MathJax"}, {"location": "computer_science/gnu_linux/mathjax/#reference", "text": "Supported symbols : mathjax-doc", "title": "Reference"}, {"location": "computer_science/gnu_linux/mdadm/", "text": "Usage \u2691 Add RAID device to initramfs \u2691 Add the currently active RAID devices to mdadm.conf : mdadm --detail --scan > /etc/mdadm/mdadm.conf Update the initramfs : update-initramfs -u serverfault Check the RAID devices status \u2691 cat /proc/mdstat RAID0 \u2691 Create RAID0 from one disk \u2691 If you have a regular disk without RAID, and you want to convert it to a RAID0 device so you can add more disks later, you can't do it directly. Instead you'll have to: Install the new disk to the machine and create a RAID0 array with only that drive. Setup the partitions on it and copy the data from the original drive. Change /etc/crypttab and /etc/fstab if needed to use the partition(s) of the RAID0 array. Extend the RAID0 adding the original disk as instructed in the next section. Extend RAID0 \u2691 Format the disk to be added generating a new partition table and a new partition. You can use fdisk . Extend the existing RAID0 array with mdadm --grow /dev/mdX --raid-devices = 2 --add /dev/sdXN This will convert the array to RAID4 temporarily since RAID0 can't be extended directly. You can check the reshape status with cat /proc/mdadm . 1. Resize the partitions, and everything needed. Reference \u2691 Usage \u2691 ducea RAID1 \u2691 Setup \u2691 tecmint", "title": "mdadm"}, {"location": "computer_science/gnu_linux/mdadm/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/mdadm/#add-raid-device-to-initramfs", "text": "Add the currently active RAID devices to mdadm.conf : mdadm --detail --scan > /etc/mdadm/mdadm.conf Update the initramfs : update-initramfs -u serverfault", "title": "Add RAID device to initramfs"}, {"location": "computer_science/gnu_linux/mdadm/#check-the-raid-devices-status", "text": "cat /proc/mdstat", "title": "Check the RAID devices status"}, {"location": "computer_science/gnu_linux/mdadm/#raid0", "text": "", "title": "RAID0"}, {"location": "computer_science/gnu_linux/mdadm/#create-raid0-from-one-disk", "text": "If you have a regular disk without RAID, and you want to convert it to a RAID0 device so you can add more disks later, you can't do it directly. Instead you'll have to: Install the new disk to the machine and create a RAID0 array with only that drive. Setup the partitions on it and copy the data from the original drive. Change /etc/crypttab and /etc/fstab if needed to use the partition(s) of the RAID0 array. Extend the RAID0 adding the original disk as instructed in the next section.", "title": "Create RAID0 from one disk"}, {"location": "computer_science/gnu_linux/mdadm/#extend-raid0", "text": "Format the disk to be added generating a new partition table and a new partition. You can use fdisk . Extend the existing RAID0 array with mdadm --grow /dev/mdX --raid-devices = 2 --add /dev/sdXN This will convert the array to RAID4 temporarily since RAID0 can't be extended directly. You can check the reshape status with cat /proc/mdadm . 1. Resize the partitions, and everything needed.", "title": "Extend RAID0"}, {"location": "computer_science/gnu_linux/mdadm/#reference", "text": "", "title": "Reference"}, {"location": "computer_science/gnu_linux/mdadm/#usage_1", "text": "ducea", "title": "Usage"}, {"location": "computer_science/gnu_linux/mdadm/#raid1", "text": "", "title": "RAID1"}, {"location": "computer_science/gnu_linux/mdadm/#setup", "text": "tecmint", "title": "Setup"}, {"location": "computer_science/gnu_linux/mimeopen/", "text": "mimeopen default applications \u2691 Usage \u2691 Check the current default application \u2691 mimeopen [file] or mimeopen .[extenesion] . Change the default application \u2691 mimeopen -d [file] or mimeopen -d .[extenesion] . mimeopen will change or add the entries to ~/.config/mimeapps.list . If a .desktop entry is requiered for some app, it will be automatically created in .local/share/applications/ . askubuntu", "title": "mimeopen"}, {"location": "computer_science/gnu_linux/mimeopen/#mimeopen-default-applications", "text": "", "title": "mimeopen default applications"}, {"location": "computer_science/gnu_linux/mimeopen/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/mimeopen/#check-the-current-default-application", "text": "mimeopen [file] or mimeopen .[extenesion] .", "title": "Check the current default application"}, {"location": "computer_science/gnu_linux/mimeopen/#change-the-default-application", "text": "mimeopen -d [file] or mimeopen -d .[extenesion] . mimeopen will change or add the entries to ~/.config/mimeapps.list . If a .desktop entry is requiered for some app, it will be automatically created in .local/share/applications/ . askubuntu", "title": "Change the default application"}, {"location": "computer_science/gnu_linux/mkdocs/", "text": "MkDocs is a fast, simple and downright gorgeous static site generator that's geared towards building project documentation. Documentation source files are written in Markdown, and configured with a single YAML configuration file. MathJax \u2691 MathJax is a beautiful and accessible way to display mathematical content in the browser, allows for writing formulas in different notations, including LaTeX, MathML and AsciiMath, and can be easily integrated with Material for MkDocs. Arithmatex \u2691 Arithmatex is an extension that preserves LaTeX math equations during the Markdown conversion process so that they can be used with libraries like MathJax. We need this extension for enabling MathJax in our site. The installation process is as follows: Edit mkdocs.yml and add: markdown_extensions : - pymdownx.arithmatex : generic : true and extra_javascript : - javascripts/config.js - https://polyfill.io/v3/polyfill.min.js?features=es6 - https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js Create docs/javascripts/config.js and add: window . MathJax = { tex : { inlineMath : [[ \"\\\\(\" , \"\\\\)\" ]], displayMath : [[ \"\\\\[\" , \"\\\\]\" ]], processEscapes : true , processEnvironments : true }, options : { ignoreHtmlClass : \".*|\" , processHtmlClass : \"arithmatex\" } }; document $ . subscribe (() => { MathJax . typesetPromise () }) Usage \u2691 Blocks must be enclosed in $$\u2026$$ or \\[\u2026\\] on separate lines. Inline blocks must be enclosed in $\u2026$ or \\(\u2026\\) . Reference \u2691 MathJax - Material for MkDocs Plugins \u2691 mkdocs-bibtex \u2691 shyamd/mkdocs-bibtex is a plugin for citation management using bibtex. Installation \u2691 Install the plugin using pip: pip install mkdocs-bibtex Next, add the following lines to your mkdocs.yml : plugins: - bibtex: bib_file: \"refs.bib\" cite_style: \"pandoc\" Usage \u2691 Keep your bibtex references in refs.bib . Then, if you want to add a reference in an entry, cite it with [@{cite_name}] and add `` wherever you want the full references to appear. mkdocs-exclude-search \u2691 chrieke/mkdocs-exclude-search is a mkdocs plugin that lets you exclude selected chapters from the search index. I use it to exclude the newsletter files generated from lyz-code/mkdocs-newsletter from the search. Installation \u2691 Install the plugin with pip install mkdocs-exclude-search and activate it in mkdocs.yml as shown in the configuration section. Configuration \u2691 Add the following configuration to your mkdocs.yml plugins : - search - exclude-search : exclude : - first.md - dir/second.md - third.md#some-heading - dir2/* - /*/fifth.md ignore : - dir/second.md#some-heading Note that dir/* excludes all markdown files within a directory and its children. mkdocs-newsletter \u2691 lyz-code/mkdocs-newsletter is a plugin that automatically creates newsletters from the changes in a MkDocs git repository. Installation \u2691 You'll need to: pip install mkdocs-newsletter And enable this plugin, by changing your mkdocs.yml plugins : - git-revision-date-localized : type : timeago - autolinks - section-index - mkdocs-newsletter mkdocstrings \u2691 mkdocstrings/mkdocstrings generates automatic documentation from sources. Configuration \u2691 plugins : - mkdocstrings : handlers : python : setup_commands : - \"import sys\" - \"sys.path.append('../')\" If we don't add ../ to the python path, the package for which we are generating the documentation would need to be installed. Automatically generate the reference files for each source file \u2691 Instead of creating manually a markdown file for every source file with package.module.file , we can automate this with a script that will be run automatically on every site build: plugins : - gen-files : scripts : - generate_reference.py from pathlib import Path import mkdocs_gen_files src_root = Path ( \"../my_module\" ) for path in src_root . glob ( \"**/*.py\" ): doc_path = Path ( \"reference\" , path . relative_to ( src_root )) . with_suffix ( \".md\" ) with mkdocs_gen_files . open ( doc_path , \"w\" ) as f : ident = \".\" . join ( path . with_suffix ( \"\" ) . parts [ 1 :]) print ( \"::: \" + ident , file = f )", "title": "MkDocs"}, {"location": "computer_science/gnu_linux/mkdocs/#mathjax", "text": "MathJax is a beautiful and accessible way to display mathematical content in the browser, allows for writing formulas in different notations, including LaTeX, MathML and AsciiMath, and can be easily integrated with Material for MkDocs.", "title": "MathJax"}, {"location": "computer_science/gnu_linux/mkdocs/#arithmatex", "text": "Arithmatex is an extension that preserves LaTeX math equations during the Markdown conversion process so that they can be used with libraries like MathJax. We need this extension for enabling MathJax in our site. The installation process is as follows: Edit mkdocs.yml and add: markdown_extensions : - pymdownx.arithmatex : generic : true and extra_javascript : - javascripts/config.js - https://polyfill.io/v3/polyfill.min.js?features=es6 - https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js Create docs/javascripts/config.js and add: window . MathJax = { tex : { inlineMath : [[ \"\\\\(\" , \"\\\\)\" ]], displayMath : [[ \"\\\\[\" , \"\\\\]\" ]], processEscapes : true , processEnvironments : true }, options : { ignoreHtmlClass : \".*|\" , processHtmlClass : \"arithmatex\" } }; document $ . subscribe (() => { MathJax . typesetPromise () })", "title": "Arithmatex"}, {"location": "computer_science/gnu_linux/mkdocs/#usage", "text": "Blocks must be enclosed in $$\u2026$$ or \\[\u2026\\] on separate lines. Inline blocks must be enclosed in $\u2026$ or \\(\u2026\\) .", "title": "Usage"}, {"location": "computer_science/gnu_linux/mkdocs/#reference", "text": "MathJax - Material for MkDocs", "title": "Reference"}, {"location": "computer_science/gnu_linux/mkdocs/#plugins", "text": "", "title": "Plugins"}, {"location": "computer_science/gnu_linux/mkdocs/#mkdocs-bibtex", "text": "shyamd/mkdocs-bibtex is a plugin for citation management using bibtex.", "title": "mkdocs-bibtex"}, {"location": "computer_science/gnu_linux/mkdocs/#installation", "text": "Install the plugin using pip: pip install mkdocs-bibtex Next, add the following lines to your mkdocs.yml : plugins: - bibtex: bib_file: \"refs.bib\" cite_style: \"pandoc\"", "title": "Installation"}, {"location": "computer_science/gnu_linux/mkdocs/#usage_1", "text": "Keep your bibtex references in refs.bib . Then, if you want to add a reference in an entry, cite it with [@{cite_name}] and add `` wherever you want the full references to appear.", "title": "Usage"}, {"location": "computer_science/gnu_linux/mkdocs/#mkdocs-exclude-search", "text": "chrieke/mkdocs-exclude-search is a mkdocs plugin that lets you exclude selected chapters from the search index. I use it to exclude the newsletter files generated from lyz-code/mkdocs-newsletter from the search.", "title": "mkdocs-exclude-search"}, {"location": "computer_science/gnu_linux/mkdocs/#installation_1", "text": "Install the plugin with pip install mkdocs-exclude-search and activate it in mkdocs.yml as shown in the configuration section.", "title": "Installation"}, {"location": "computer_science/gnu_linux/mkdocs/#configuration", "text": "Add the following configuration to your mkdocs.yml plugins : - search - exclude-search : exclude : - first.md - dir/second.md - third.md#some-heading - dir2/* - /*/fifth.md ignore : - dir/second.md#some-heading Note that dir/* excludes all markdown files within a directory and its children.", "title": "Configuration"}, {"location": "computer_science/gnu_linux/mkdocs/#mkdocs-newsletter", "text": "lyz-code/mkdocs-newsletter is a plugin that automatically creates newsletters from the changes in a MkDocs git repository.", "title": "mkdocs-newsletter"}, {"location": "computer_science/gnu_linux/mkdocs/#installation_2", "text": "You'll need to: pip install mkdocs-newsletter And enable this plugin, by changing your mkdocs.yml plugins : - git-revision-date-localized : type : timeago - autolinks - section-index - mkdocs-newsletter", "title": "Installation"}, {"location": "computer_science/gnu_linux/mkdocs/#mkdocstrings", "text": "mkdocstrings/mkdocstrings generates automatic documentation from sources.", "title": "mkdocstrings"}, {"location": "computer_science/gnu_linux/mkdocs/#configuration_1", "text": "plugins : - mkdocstrings : handlers : python : setup_commands : - \"import sys\" - \"sys.path.append('../')\" If we don't add ../ to the python path, the package for which we are generating the documentation would need to be installed.", "title": "Configuration"}, {"location": "computer_science/gnu_linux/mkdocs/#automatically-generate-the-reference-files-for-each-source-file", "text": "Instead of creating manually a markdown file for every source file with package.module.file , we can automate this with a script that will be run automatically on every site build: plugins : - gen-files : scripts : - generate_reference.py from pathlib import Path import mkdocs_gen_files src_root = Path ( \"../my_module\" ) for path in src_root . glob ( \"**/*.py\" ): doc_path = Path ( \"reference\" , path . relative_to ( src_root )) . with_suffix ( \".md\" ) with mkdocs_gen_files . open ( doc_path , \"w\" ) as f : ident = \".\" . join ( path . with_suffix ( \"\" ) . parts [ 1 :]) print ( \"::: \" + ident , file = f )", "title": "Automatically generate the reference files for each source file"}, {"location": "computer_science/gnu_linux/mmv/", "text": "mmv is a command line utility to move/copy/append/link multiple files by wildcard patterns. Usage \u2691 The general usage scheme is: mmv { from } { to } where {from} is a RegEx pattern, with * for any substring and ? for any character, and {to} is a pattern that can include characters and substitutions from the matching wildcards from {from} (using #1 for the first wildcard and so on). For example (from the man page) to rename music files from <track no.> - <interpreter> - <song title>.ogg to <interpreter> - <track no.> - <song title>.ogg in the current directory: mmv '* - * - *.ogg' '#2 - #1 - #3.ogg'", "title": "mmv"}, {"location": "computer_science/gnu_linux/mmv/#usage", "text": "The general usage scheme is: mmv { from } { to } where {from} is a RegEx pattern, with * for any substring and ? for any character, and {to} is a pattern that can include characters and substitutions from the matching wildcards from {from} (using #1 for the first wildcard and so on). For example (from the man page) to rename music files from <track no.> - <interpreter> - <song title>.ogg to <interpreter> - <track no.> - <song title>.ogg in the current directory: mmv '* - * - *.ogg' '#2 - #1 - #3.ogg'", "title": "Usage"}, {"location": "computer_science/gnu_linux/molecule/", "text": "Molecule \u2691 Reference \u2691 provisioner", "title": "Molecule"}, {"location": "computer_science/gnu_linux/molecule/#molecule", "text": "", "title": "Molecule"}, {"location": "computer_science/gnu_linux/molecule/#reference", "text": "provisioner", "title": "Reference"}, {"location": "computer_science/gnu_linux/msmtp/", "text": "msmtp \u2691 Reference \u2691 arch-wiki html-docs", "title": "Msmtp"}, {"location": "computer_science/gnu_linux/msmtp/#msmtp", "text": "", "title": "msmtp"}, {"location": "computer_science/gnu_linux/msmtp/#reference", "text": "arch-wiki html-docs", "title": "Reference"}, {"location": "computer_science/gnu_linux/music/", "text": "FLAC \u2691 FLAC is a open lossless audio codec. ReplayGain \u2691 To calculate and add the replaygain tag to FLAC files, do: metaflac --add-replay-gain *.flac Spot fake FLACs \u2691 To spot fake FLACs, which are FLAC files generated from a lossy audio file, you can analyze the spectrum with spek or sonic-visualiser . Look for a cutoff in the signal power around 16-18 kHz. If it's a real FLAC, there shouldn't such a cut. Reference \u2691 Utilities \u2691 easytag for tags. pulseeffects equalizer. spek spectrum analyzer.", "title": "Music"}, {"location": "computer_science/gnu_linux/music/#flac", "text": "FLAC is a open lossless audio codec.", "title": "FLAC"}, {"location": "computer_science/gnu_linux/music/#replaygain", "text": "To calculate and add the replaygain tag to FLAC files, do: metaflac --add-replay-gain *.flac", "title": "ReplayGain"}, {"location": "computer_science/gnu_linux/music/#spot-fake-flacs", "text": "To spot fake FLACs, which are FLAC files generated from a lossy audio file, you can analyze the spectrum with spek or sonic-visualiser . Look for a cutoff in the signal power around 16-18 kHz. If it's a real FLAC, there shouldn't such a cut.", "title": "Spot fake FLACs"}, {"location": "computer_science/gnu_linux/music/#reference", "text": "", "title": "Reference"}, {"location": "computer_science/gnu_linux/music/#utilities", "text": "easytag for tags. pulseeffects equalizer. spek spectrum analyzer.", "title": "Utilities"}, {"location": "computer_science/gnu_linux/neomutt/", "text": "Usage \u2691 GPG \u2691 Attach GPG public key \u2691 When sending an email you might want to attach your GPG public key. Press Alt+k in order to do so. myridia.com Configuration \u2691 index_format \u2691 This variable allows you to customize the message index display to your personal taste. Local timezone \u2691 Use %{fmt} for the sender's timezone and %[fmt] for your local one. Reference \u2691 arch-wiki Vim bindings \u2691 ryanlue", "title": "NeoMutt"}, {"location": "computer_science/gnu_linux/neomutt/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/neomutt/#gpg", "text": "", "title": "GPG"}, {"location": "computer_science/gnu_linux/neomutt/#attach-gpg-public-key", "text": "When sending an email you might want to attach your GPG public key. Press Alt+k in order to do so. myridia.com", "title": "Attach GPG public key"}, {"location": "computer_science/gnu_linux/neomutt/#configuration", "text": "", "title": "Configuration"}, {"location": "computer_science/gnu_linux/neomutt/#index_format", "text": "This variable allows you to customize the message index display to your personal taste.", "title": "index_format"}, {"location": "computer_science/gnu_linux/neomutt/#local-timezone", "text": "Use %{fmt} for the sender's timezone and %[fmt] for your local one.", "title": "Local timezone"}, {"location": "computer_science/gnu_linux/neomutt/#reference", "text": "arch-wiki", "title": "Reference"}, {"location": "computer_science/gnu_linux/neomutt/#vim-bindings", "text": "ryanlue", "title": "Vim bindings"}, {"location": "computer_science/gnu_linux/neovim/", "text": "Install \u2691 To install the latest stable release, do: curl -sSL \"https://github.com/neovim/neovim/releases/download/stable/nvim-linux64.tar.gz\" | \\ tar -C \" ${ HOME } /.local\" -xz --strip-components = 1 -f -", "title": "neovim"}, {"location": "computer_science/gnu_linux/neovim/#install", "text": "To install the latest stable release, do: curl -sSL \"https://github.com/neovim/neovim/releases/download/stable/nvim-linux64.tar.gz\" | \\ tar -C \" ${ HOME } /.local\" -xz --strip-components = 1 -f -", "title": "Install"}, {"location": "computer_science/gnu_linux/netcat/", "text": "Usage \u2691 Test TCP connections \u2691 nc -v -z -w 3 [ host ] [ port ] Options: * -v : verbose * -z : just check if the port is open and exit (without sending any data) * -w 3 : 3 seconds timeout If it exists with return code 0, it means that the connection succeeded. Listen to a port \u2691 netcat -l [port] Scan port range \u2691 nc -zvnw 1 [ip] 1-1000 -z Port scanning mode. -v Verbose. -n Do not resolve the host name. -w 1 1s timeout. cybercity Connect through TOR \u2691 nc -v -X5 -x localhost:9050 [ server ] [ port ] vicendominguez Reference \u2691 Basic usage \u2691 digitalocean", "title": "netcat"}, {"location": "computer_science/gnu_linux/netcat/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/netcat/#test-tcp-connections", "text": "nc -v -z -w 3 [ host ] [ port ] Options: * -v : verbose * -z : just check if the port is open and exit (without sending any data) * -w 3 : 3 seconds timeout If it exists with return code 0, it means that the connection succeeded.", "title": "Test TCP connections"}, {"location": "computer_science/gnu_linux/netcat/#listen-to-a-port", "text": "netcat -l [port]", "title": "Listen to a port"}, {"location": "computer_science/gnu_linux/netcat/#scan-port-range", "text": "nc -zvnw 1 [ip] 1-1000 -z Port scanning mode. -v Verbose. -n Do not resolve the host name. -w 1 1s timeout. cybercity", "title": "Scan port range"}, {"location": "computer_science/gnu_linux/netcat/#connect-through-tor", "text": "nc -v -X5 -x localhost:9050 [ server ] [ port ] vicendominguez", "title": "Connect through TOR"}, {"location": "computer_science/gnu_linux/netcat/#reference", "text": "", "title": "Reference"}, {"location": "computer_science/gnu_linux/netcat/#basic-usage", "text": "digitalocean", "title": "Basic usage"}, {"location": "computer_science/gnu_linux/nextcloud/", "text": "Nextcloud \u2691 Debug \u2691 Extremely slow \u2691 Website takes a long time to load, desktop and mobile apps stop working \u2691 This might be happening because the host of a shared folder can't be reached. You can try to delete those folders via the web interface. If it doesn't work, try login to the database and removing the external shared folders table with: delete from oc_share_external ; nextcloud help github issue Can't login from apps \u2691 If the Nextcloud instance is behind a reverse proxy, maybe you should add the overwriteportocol directive to the server config. bayton", "title": "Nextcloud"}, {"location": "computer_science/gnu_linux/nextcloud/#nextcloud", "text": "", "title": "Nextcloud"}, {"location": "computer_science/gnu_linux/nextcloud/#debug", "text": "", "title": "Debug"}, {"location": "computer_science/gnu_linux/nextcloud/#extremely-slow", "text": "", "title": "Extremely slow"}, {"location": "computer_science/gnu_linux/nextcloud/#website-takes-a-long-time-to-load-desktop-and-mobile-apps-stop-working", "text": "This might be happening because the host of a shared folder can't be reached. You can try to delete those folders via the web interface. If it doesn't work, try login to the database and removing the external shared folders table with: delete from oc_share_external ; nextcloud help github issue", "title": "Website takes a long time to load, desktop and mobile apps stop working"}, {"location": "computer_science/gnu_linux/nextcloud/#cant-login-from-apps", "text": "If the Nextcloud instance is behind a reverse proxy, maybe you should add the overwriteportocol directive to the server config. bayton", "title": "Can't login from apps"}, {"location": "computer_science/gnu_linux/nfs/", "text": "NFS \u2691 Usage \u2691 NFSv4 \u2691 Server \u2691 In /etc/exports : /export 192.168.1.0/24(rw,fsid=0,no_subtree_check) And then you can add other directories that are inside /export in the server. NFSv4 NFSv4 dictates that the additional shared directories are subdirectories of the root share (the one with fsid=0 ). Client \u2691 mount -t nfs4 -o proto = tcp,port = 2049 [ nfs-server ] :/ /mnt Note : Yo should specify the path relative to the root share folder. /etc/fstab \u2691 Server:/path/to/export /local_mountpoint nfs hard,intr 0 0 Linux NFS Mount Entry in fstab ( /etc/fstab ) with Example Debug \u2691 From the client try: mount -v -o nfsvers = 4 [ nfs-server ] :/ /mnt Reference \u2691 NFSv4 \u2691 ubunut-help", "title": "NFS"}, {"location": "computer_science/gnu_linux/nfs/#nfs", "text": "", "title": "NFS"}, {"location": "computer_science/gnu_linux/nfs/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/nfs/#nfsv4", "text": "", "title": "NFSv4"}, {"location": "computer_science/gnu_linux/nfs/#server", "text": "In /etc/exports : /export 192.168.1.0/24(rw,fsid=0,no_subtree_check) And then you can add other directories that are inside /export in the server. NFSv4 NFSv4 dictates that the additional shared directories are subdirectories of the root share (the one with fsid=0 ).", "title": "Server"}, {"location": "computer_science/gnu_linux/nfs/#client", "text": "mount -t nfs4 -o proto = tcp,port = 2049 [ nfs-server ] :/ /mnt Note : Yo should specify the path relative to the root share folder.", "title": "Client"}, {"location": "computer_science/gnu_linux/nfs/#etcfstab", "text": "Server:/path/to/export /local_mountpoint nfs hard,intr 0 0 Linux NFS Mount Entry in fstab ( /etc/fstab ) with Example", "title": "/etc/fstab"}, {"location": "computer_science/gnu_linux/nfs/#debug", "text": "From the client try: mount -v -o nfsvers = 4 [ nfs-server ] :/ /mnt", "title": "Debug"}, {"location": "computer_science/gnu_linux/nfs/#reference", "text": "", "title": "Reference"}, {"location": "computer_science/gnu_linux/nfs/#nfsv4_1", "text": "ubunut-help", "title": "NFSv4"}, {"location": "computer_science/gnu_linux/nginx/", "text": "Configuration \u2691 Serve static files \u2691 Either location /static/ { root /var/www/app/; } or location /static/ { alias /var/www/app/static/; } The difference is that with alias the location part gets dropped from the original URL so http://host/static/somefile would access /var/www/app/static/somefile instead of /var/www/app/static/somefile/somefile . Reverse proxy \u2691 In the vhost file, add location /something/ { proxy_pass http://127.0.0.1:8000/; # note the trailing slash here, it matters! } Disable showing nginx's version in the error pages \u2691 server_tokens off; scalescale", "title": "NGINX"}, {"location": "computer_science/gnu_linux/nginx/#configuration", "text": "", "title": "Configuration"}, {"location": "computer_science/gnu_linux/nginx/#serve-static-files", "text": "Either location /static/ { root /var/www/app/; } or location /static/ { alias /var/www/app/static/; } The difference is that with alias the location part gets dropped from the original URL so http://host/static/somefile would access /var/www/app/static/somefile instead of /var/www/app/static/somefile/somefile .", "title": "Serve static files"}, {"location": "computer_science/gnu_linux/nginx/#reverse-proxy", "text": "In the vhost file, add location /something/ { proxy_pass http://127.0.0.1:8000/; # note the trailing slash here, it matters! }", "title": "Reverse proxy"}, {"location": "computer_science/gnu_linux/nginx/#disable-showing-nginxs-version-in-the-error-pages", "text": "server_tokens off; scalescale", "title": "Disable showing nginx's version in the error pages"}, {"location": "computer_science/gnu_linux/nice/", "text": "UNIX/Linux nice \u2691 Usage \u2691 Run a process with an specific priority \u2691 nice -n [ nice value ] [ command ] Setting Priority of currently running process \u2691 renice [ nice value ] -p [ process id ] Reference \u2691 General usage \u2691 thegeekdiary", "title": "nice"}, {"location": "computer_science/gnu_linux/nice/#unixlinux-nice", "text": "", "title": "UNIX/Linux nice"}, {"location": "computer_science/gnu_linux/nice/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/nice/#run-a-process-with-an-specific-priority", "text": "nice -n [ nice value ] [ command ]", "title": "Run a process with an specific priority"}, {"location": "computer_science/gnu_linux/nice/#setting-priority-of-currently-running-process", "text": "renice [ nice value ] -p [ process id ]", "title": "Setting Priority of currently running process"}, {"location": "computer_science/gnu_linux/nice/#reference", "text": "", "title": "Reference"}, {"location": "computer_science/gnu_linux/nice/#general-usage", "text": "thegeekdiary", "title": "General usage"}, {"location": "computer_science/gnu_linux/nikola/", "text": "Nikola: static site generator \u2691 Install \u2691 Installing in an virtualenv is almost mandatory. Be careful doing it otherwise. mkvirtualenv -p ` which python3 ` nikola-py3 pip install --upgrade setuptools pip pip install --upgrade \"Nikola[extras]\" Done! nikola", "title": "Nikola"}, {"location": "computer_science/gnu_linux/nikola/#nikola-static-site-generator", "text": "", "title": "Nikola: static site generator"}, {"location": "computer_science/gnu_linux/nikola/#install", "text": "Installing in an virtualenv is almost mandatory. Be careful doing it otherwise. mkvirtualenv -p ` which python3 ` nikola-py3 pip install --upgrade setuptools pip pip install --upgrade \"Nikola[extras]\" Done! nikola", "title": "Install"}, {"location": "computer_science/gnu_linux/octave/", "text": "GNU/Ocatve \u2691 Vectors \u2691 Generate vectors \u2691 From $ x_0 = 0 $ to $ x_n = 5 $ with step $ s = 1 $: ref = [0:1:5] Concatenate \u2691 Horizontally concatenate row vectors: new = [ A , B ] kk = [ ones ( 1 , 4 ), zeros ( 1 , 4 ) ] kk = 1 1 1 1 0 0 0 0", "title": "Octave"}, {"location": "computer_science/gnu_linux/octave/#gnuocatve", "text": "", "title": "GNU/Ocatve"}, {"location": "computer_science/gnu_linux/octave/#vectors", "text": "", "title": "Vectors"}, {"location": "computer_science/gnu_linux/octave/#generate-vectors", "text": "From $ x_0 = 0 $ to $ x_n = 5 $ with step $ s = 1 $: ref = [0:1:5]", "title": "Generate vectors"}, {"location": "computer_science/gnu_linux/octave/#concatenate", "text": "Horizontally concatenate row vectors: new = [ A , B ] kk = [ ones ( 1 , 4 ), zeros ( 1 , 4 ) ] kk = 1 1 1 1 0 0 0 0", "title": "Concatenate"}, {"location": "computer_science/gnu_linux/openldap/", "text": "Usage \u2691 Don't check certs \u2691 LDAPTLS_REQCERT = never [ command ] Or add TLS_REQCERT never to /etc/openldap/ldap.conf . Tips \u2691 Get highest uidNUmber on LDAP \u2691 ldapsearch -H ldaps://your-ldap-domain -D \"cn=Manager,dc=domain,dc=com\" -W | awk '/uidNumber: / {print $2}' | sort | tail -n 1", "title": "OpenLDAP"}, {"location": "computer_science/gnu_linux/openldap/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/openldap/#dont-check-certs", "text": "LDAPTLS_REQCERT = never [ command ] Or add TLS_REQCERT never to /etc/openldap/ldap.conf .", "title": "Don't check certs"}, {"location": "computer_science/gnu_linux/openldap/#tips", "text": "", "title": "Tips"}, {"location": "computer_science/gnu_linux/openldap/#get-highest-uidnumber-on-ldap", "text": "ldapsearch -H ldaps://your-ldap-domain -D \"cn=Manager,dc=domain,dc=com\" -W | awk '/uidNumber: / {print $2}' | sort | tail -n 1", "title": "Get highest uidNUmber on LDAP"}, {"location": "computer_science/gnu_linux/openrc/", "text": "openRC \u2691 Configuration \u2691 Enable loggin \u2691 Set rc_logger=\"YES\" in /etc/rc.conf . arch-wiki", "title": "OpenRC"}, {"location": "computer_science/gnu_linux/openrc/#openrc", "text": "", "title": "openRC"}, {"location": "computer_science/gnu_linux/openrc/#configuration", "text": "", "title": "Configuration"}, {"location": "computer_science/gnu_linux/openrc/#enable-loggin", "text": "Set rc_logger=\"YES\" in /etc/rc.conf . arch-wiki", "title": "Enable loggin"}, {"location": "computer_science/gnu_linux/openssl/", "text": "Usage \u2691 Key \u2691 Generate a RSA key \u2691 openssl genrsa -out [key file] [bit size] [bit size] : 2048, 4096... CSR \u2691 Get information from a CSR file \u2691 openssl req -in [csr file] -text -noout shellhacks Generate a CSR \u2691 Generate a key file. Create a csr.conf file (recommended) with the following contents: [ req ] default_bits = [key bit size] default_md = sha512 default_keyfile = [domain] prompt = no encrypt_key = no distinguished_name = req_distinguished_name # distinguished_name [ req_distinguished_name ] countryName = \"[C]\" # C= localityName = \"[L]\" # L= organizationName = \"[O]\" # O= organizationalUnitName = \"[OU]\" # OU= commonName = \"[CN]\" # CN= emailAddress = \"[CN/emailAddress]\" # CN/emailAddress= 3. Generate de CSR file for the key: openssl req -config csr.conf -new -key [key file] -out [CSR file] -verbose medium Get information about a SSL/TLS certificate \u2691 openssl s_client -connect [ host ] : [ port ] | openssl x509 -noout -dates", "title": "OpenSSL"}, {"location": "computer_science/gnu_linux/openssl/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/openssl/#key", "text": "", "title": "Key"}, {"location": "computer_science/gnu_linux/openssl/#generate-a-rsa-key", "text": "openssl genrsa -out [key file] [bit size] [bit size] : 2048, 4096...", "title": "Generate a RSA key"}, {"location": "computer_science/gnu_linux/openssl/#csr", "text": "", "title": "CSR"}, {"location": "computer_science/gnu_linux/openssl/#get-information-from-a-csr-file", "text": "openssl req -in [csr file] -text -noout shellhacks", "title": "Get information from a CSR file"}, {"location": "computer_science/gnu_linux/openssl/#generate-a-csr", "text": "Generate a key file. Create a csr.conf file (recommended) with the following contents: [ req ] default_bits = [key bit size] default_md = sha512 default_keyfile = [domain] prompt = no encrypt_key = no distinguished_name = req_distinguished_name # distinguished_name [ req_distinguished_name ] countryName = \"[C]\" # C= localityName = \"[L]\" # L= organizationName = \"[O]\" # O= organizationalUnitName = \"[OU]\" # OU= commonName = \"[CN]\" # CN= emailAddress = \"[CN/emailAddress]\" # CN/emailAddress= 3. Generate de CSR file for the key: openssl req -config csr.conf -new -key [key file] -out [CSR file] -verbose medium", "title": "Generate a CSR"}, {"location": "computer_science/gnu_linux/openssl/#get-information-about-a-ssltls-certificate", "text": "openssl s_client -connect [ host ] : [ port ] | openssl x509 -noout -dates", "title": "Get information about a SSL/TLS certificate"}, {"location": "computer_science/gnu_linux/pandoc/", "text": "Pandoc \u2691 Usage \u2691 Download website to LaTeX PDF \u2691 pandoc --pdf-engine = xelatex -s -r html [ url ] -o out.pdf", "title": "Pandoc"}, {"location": "computer_science/gnu_linux/pandoc/#pandoc", "text": "", "title": "Pandoc"}, {"location": "computer_science/gnu_linux/pandoc/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/pandoc/#download-website-to-latex-pdf", "text": "pandoc --pdf-engine = xelatex -s -r html [ url ] -o out.pdf", "title": "Download website to LaTeX PDF"}, {"location": "computer_science/gnu_linux/parallel/", "text": "GNU parallel is a shell tool for executing jobs in parallel using one or more computers. A job can be a single command or a small script that has to be run for each of the lines in the input. The typical input is a list of files, a list of hosts, a list of users, a list of URLs, or a list of tables. A job can also be a command that reads from a pipe. GNU parallel can then split the input and pipe it into commands in parallel. For example parallel grep \"string\" ::: ` ls `", "title": "Parallel"}, {"location": "computer_science/gnu_linux/pass/", "text": "Pass: the standard unix password manager \u2691 Usage \u2691 Re-encrypt .password-store using new gpg key \u2691 pass init -p <path> <gpg-id ( s ) > Specify the <path> relative to ~/.password-store . askubuntu Reference \u2691 https://www.passwordstore.org/ medium.com", "title": "Pass"}, {"location": "computer_science/gnu_linux/pass/#pass-the-standard-unix-password-manager", "text": "", "title": "Pass: the standard unix password manager"}, {"location": "computer_science/gnu_linux/pass/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/pass/#re-encrypt-password-store-using-new-gpg-key", "text": "pass init -p <path> <gpg-id ( s ) > Specify the <path> relative to ~/.password-store . askubuntu", "title": "Re-encrypt .password-store using new gpg key"}, {"location": "computer_science/gnu_linux/pass/#reference", "text": "https://www.passwordstore.org/ medium.com", "title": "Reference"}, {"location": "computer_science/gnu_linux/pdfimages/", "text": "PDFimages \u2691 Extract all images from PDF \u2691 pdfimages -j [pdf] /tmp/out Will save images from PDF file [pdf] in files /tmp/out-000.jpg , /tmp/out-001.jpg , etc. askubuntu", "title": "pdfimages"}, {"location": "computer_science/gnu_linux/pdfimages/#pdfimages", "text": "", "title": "PDFimages"}, {"location": "computer_science/gnu_linux/pdfimages/#extract-all-images-from-pdf", "text": "pdfimages -j [pdf] /tmp/out Will save images from PDF file [pdf] in files /tmp/out-000.jpg , /tmp/out-001.jpg , etc. askubuntu", "title": "Extract all images from PDF"}, {"location": "computer_science/gnu_linux/pdftk/", "text": "Usage \u2691 Rotate all of the pages clockwise \u2691 pdftk [ input ] cat 1 -endeast output [ output ] Extract a page range of a PDF \u2691 To extract a page range of a PDF you could print to file using evince selecting a page range. The drawback of this method is that the text might be converted to images an thus no longer be searchable. A faster alternative that also keeps the text intact is using pdftk as follows: pdftk { original.pdf } cat { range_start } - { range_end } output { output.pdf } where {range_start} is the first page number of {original.pdf} to be included in {output.pdf} and {range_end} the last one. Reference \u2691 Docker images \u2691 jottr/alpine-pdftk", "title": "PDFtk"}, {"location": "computer_science/gnu_linux/pdftk/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/pdftk/#rotate-all-of-the-pages-clockwise", "text": "pdftk [ input ] cat 1 -endeast output [ output ]", "title": "Rotate all of the pages clockwise"}, {"location": "computer_science/gnu_linux/pdftk/#extract-a-page-range-of-a-pdf", "text": "To extract a page range of a PDF you could print to file using evince selecting a page range. The drawback of this method is that the text might be converted to images an thus no longer be searchable. A faster alternative that also keeps the text intact is using pdftk as follows: pdftk { original.pdf } cat { range_start } - { range_end } output { output.pdf } where {range_start} is the first page number of {original.pdf} to be included in {output.pdf} and {range_end} the last one.", "title": "Extract a page range of a PDF"}, {"location": "computer_science/gnu_linux/pdftk/#reference", "text": "", "title": "Reference"}, {"location": "computer_science/gnu_linux/pdftk/#docker-images", "text": "jottr/alpine-pdftk", "title": "Docker images"}, {"location": "computer_science/gnu_linux/pdfunite/", "text": "pdfunite \u2691 Usage \u2691 pdfunite part1.pdf part2.pdf ... partn.pdf out.pdf stackoverflow", "title": "pdfunite"}, {"location": "computer_science/gnu_linux/pdfunite/#pdfunite", "text": "", "title": "pdfunite"}, {"location": "computer_science/gnu_linux/pdfunite/#usage", "text": "pdfunite part1.pdf part2.pdf ... partn.pdf out.pdf stackoverflow", "title": "Usage"}, {"location": "computer_science/gnu_linux/portage/", "text": "Portage: Gentoo package manager \u2691 Usage \u2691 Options \u2691 Ignore errors and continue \u2691 Use the option --keep-going . Add custom ebuild \u2691 Copy the ebuild file to the corresponding directory, creating it in its category, in /usr/portage . Then: chown -R portage:portage /usr/local/portage pushd [ new-directory ] repoman manifest popd gentoo-wiki Tips \u2691 Upgrading live ebuilds \u2691 If you use the version 9999 of an ebuild, it probably means you are compiling the master branch of the source repo each time. Portage doesn't check for the updates and won't update this packages automatically (because the version will always be 9999 ). The best way to update them is by using a script. To find the installed packages you can use: find /var/db/pkg/ -mindepth 2 -maxdepth 2 -name \\* -9999 To upgrade all of them, use: emerge -1aAv ` find /var/db/pkg/ -mindepth 2 -maxdepth 2 -name \\* -9999 | awk -F \\/ '{printf \"=%s/%s \", $5, $6}' ` gentoo forums", "title": "Portage"}, {"location": "computer_science/gnu_linux/portage/#portage-gentoo-package-manager", "text": "", "title": "Portage: Gentoo package manager"}, {"location": "computer_science/gnu_linux/portage/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/portage/#options", "text": "", "title": "Options"}, {"location": "computer_science/gnu_linux/portage/#ignore-errors-and-continue", "text": "Use the option --keep-going .", "title": "Ignore errors and continue"}, {"location": "computer_science/gnu_linux/portage/#add-custom-ebuild", "text": "Copy the ebuild file to the corresponding directory, creating it in its category, in /usr/portage . Then: chown -R portage:portage /usr/local/portage pushd [ new-directory ] repoman manifest popd gentoo-wiki", "title": "Add custom ebuild"}, {"location": "computer_science/gnu_linux/portage/#tips", "text": "", "title": "Tips"}, {"location": "computer_science/gnu_linux/portage/#upgrading-live-ebuilds", "text": "If you use the version 9999 of an ebuild, it probably means you are compiling the master branch of the source repo each time. Portage doesn't check for the updates and won't update this packages automatically (because the version will always be 9999 ). The best way to update them is by using a script. To find the installed packages you can use: find /var/db/pkg/ -mindepth 2 -maxdepth 2 -name \\* -9999 To upgrade all of them, use: emerge -1aAv ` find /var/db/pkg/ -mindepth 2 -maxdepth 2 -name \\* -9999 | awk -F \\/ '{printf \"=%s/%s \", $5, $6}' ` gentoo forums", "title": "Upgrading live ebuilds"}, {"location": "computer_science/gnu_linux/postgresql/", "text": "Usage \u2691 Use psql . Queries ignore case, so if any column name has capital letters in it, escape it with double quotes (\"). To scape a string use single quotes ('). To select the database to work in do \\connect {database_name} or \\c {database_name} in short. Basic operations \u2691 Delete a table \u2691 DROP TABLE \"{table_name}\" ; Add a new column \u2691 To add a new column, use ALTER TABLE . For example: ALTER TABLE { table_name } ADD IF NOT EXISTS { column_name } { data_type } GROUP BY \u2691 Reference: PostgreSQL GROUP BY UPDATE \u2691 To update the values of some columns, use UPDATE . The general basic syntax is as follows: UPDATE table_name SET column1 = value1 , column2 = value2 , ... WHERE condition ; From subquery \u2691 The most efficient way appears to be the following. UPDATE { table } SET { column1 } = subquery . { column1 }, { column2 } = subquery . { column2 } FROM ({ subquery }) AS subquery WHERE { table } . { id } = subquery . { id }; Other options are to perform a JOIN but the syntax is less clear and the performance seems to be worse. Window functions \u2691 Window functions allow to perform the calculation across a set of rows related to the current row. The simplified syntax is: window_function ( arg1 , arg2 , .. ) OVER ( [ PARTITION BY partition_expression ] [ ORDER BY sort_expression [ ASC | DESC ] [ NULLS { FIRST | LAST }]) So for example a moving average of the last 28 days could be obtained with: SELECT AVG ({ column }) OVER ( ORDER BY { date_column } RANGE BETWEEN '28 day' PRECEDING AND current row ) AS rolling_average FROM { table } Query operators \u2691 NULLIF \u2691 The NULLIF(value1, value2) function returns a null value if value1 equals value2 ; otherwise it returns value1 . It can be useful for avoiding divisions by 0 (e.g. set value2 to 0). String functions and operators \u2691 Reference: PostgreSQL Documentation concat_ws \u2691 To concatenate strings with a separator, use concat_ws({separator}, {val1}, {...}) . For example: concat_ws(',', 'abcde', 2, NULL, 22) \u2192 abcde,2,22 . Time stamp operations \u2691 Get only part of the time stamp \u2691 To get only a part of the time stamp (e.g., day, hour...) or to get it in another format (e.g., epoch), use date_part() . For example, to get the hour of a timestamp do: date_part ( 'hour' , timestamp '2001-02-16 20:38:40' ) which will return 20 . The second argument of the function can be the name of a column. If instead you want to truncate a timestamp to a specified level of precission, use date_trunc('datepart', field) . Meta \u2691 Get column names of a table \u2691 SELECT column_name FROM INFORMATION_SCHEMA . COLUMNS WHERE TABLE_NAME = '{table_name}' ; Or, to get the column names along with their type use: \\d+ {table_name} Enable command timing \u2691 \\timing [on|off] stackoverflow Stop/kill process \u2691 First locate the process pid with SELECT pid , query FROM pg_stat_activity WHERE state = 'active' ; Then, stop or kill the process with SELECT pg_cancel_backend({pid}) or pg_termiante_backend({pid}) respectively. Configuration \u2691 You can use PGTune to calculate configuration for PostgreSQL based on the maximum performance for a given hardware configuration. Parallelization \u2691 To tune the number of workers edit postgresql.conf and in the - Asynchronous Behavior - section edit max_worker_processes , max_parallel_workers_per_gather and max_parallel_workers . Administration \u2691 Change user password \u2691 ALTER USER user_name WITH PASSWORD 'new_password' ; Reference \u2691 Data types \u2691 Numeric Types", "title": "PostgreSQL"}, {"location": "computer_science/gnu_linux/postgresql/#usage", "text": "Use psql . Queries ignore case, so if any column name has capital letters in it, escape it with double quotes (\"). To scape a string use single quotes ('). To select the database to work in do \\connect {database_name} or \\c {database_name} in short.", "title": "Usage"}, {"location": "computer_science/gnu_linux/postgresql/#basic-operations", "text": "", "title": "Basic operations"}, {"location": "computer_science/gnu_linux/postgresql/#delete-a-table", "text": "DROP TABLE \"{table_name}\" ;", "title": "Delete a table"}, {"location": "computer_science/gnu_linux/postgresql/#add-a-new-column", "text": "To add a new column, use ALTER TABLE . For example: ALTER TABLE { table_name } ADD IF NOT EXISTS { column_name } { data_type }", "title": "Add a new column"}, {"location": "computer_science/gnu_linux/postgresql/#group-by", "text": "Reference: PostgreSQL GROUP BY", "title": "GROUP BY"}, {"location": "computer_science/gnu_linux/postgresql/#update", "text": "To update the values of some columns, use UPDATE . The general basic syntax is as follows: UPDATE table_name SET column1 = value1 , column2 = value2 , ... WHERE condition ;", "title": "UPDATE"}, {"location": "computer_science/gnu_linux/postgresql/#from-subquery", "text": "The most efficient way appears to be the following. UPDATE { table } SET { column1 } = subquery . { column1 }, { column2 } = subquery . { column2 } FROM ({ subquery }) AS subquery WHERE { table } . { id } = subquery . { id }; Other options are to perform a JOIN but the syntax is less clear and the performance seems to be worse.", "title": "From subquery"}, {"location": "computer_science/gnu_linux/postgresql/#window-functions", "text": "Window functions allow to perform the calculation across a set of rows related to the current row. The simplified syntax is: window_function ( arg1 , arg2 , .. ) OVER ( [ PARTITION BY partition_expression ] [ ORDER BY sort_expression [ ASC | DESC ] [ NULLS { FIRST | LAST }]) So for example a moving average of the last 28 days could be obtained with: SELECT AVG ({ column }) OVER ( ORDER BY { date_column } RANGE BETWEEN '28 day' PRECEDING AND current row ) AS rolling_average FROM { table }", "title": "Window functions"}, {"location": "computer_science/gnu_linux/postgresql/#query-operators", "text": "", "title": "Query operators"}, {"location": "computer_science/gnu_linux/postgresql/#nullif", "text": "The NULLIF(value1, value2) function returns a null value if value1 equals value2 ; otherwise it returns value1 . It can be useful for avoiding divisions by 0 (e.g. set value2 to 0).", "title": "NULLIF"}, {"location": "computer_science/gnu_linux/postgresql/#string-functions-and-operators", "text": "Reference: PostgreSQL Documentation", "title": "String functions and operators"}, {"location": "computer_science/gnu_linux/postgresql/#concat_ws", "text": "To concatenate strings with a separator, use concat_ws({separator}, {val1}, {...}) . For example: concat_ws(',', 'abcde', 2, NULL, 22) \u2192 abcde,2,22 .", "title": "concat_ws"}, {"location": "computer_science/gnu_linux/postgresql/#time-stamp-operations", "text": "", "title": "Time stamp operations"}, {"location": "computer_science/gnu_linux/postgresql/#get-only-part-of-the-time-stamp", "text": "To get only a part of the time stamp (e.g., day, hour...) or to get it in another format (e.g., epoch), use date_part() . For example, to get the hour of a timestamp do: date_part ( 'hour' , timestamp '2001-02-16 20:38:40' ) which will return 20 . The second argument of the function can be the name of a column. If instead you want to truncate a timestamp to a specified level of precission, use date_trunc('datepart', field) .", "title": "Get only part of the time stamp"}, {"location": "computer_science/gnu_linux/postgresql/#meta", "text": "", "title": "Meta"}, {"location": "computer_science/gnu_linux/postgresql/#get-column-names-of-a-table", "text": "SELECT column_name FROM INFORMATION_SCHEMA . COLUMNS WHERE TABLE_NAME = '{table_name}' ; Or, to get the column names along with their type use: \\d+ {table_name}", "title": "Get column names of a table"}, {"location": "computer_science/gnu_linux/postgresql/#enable-command-timing", "text": "\\timing [on|off] stackoverflow", "title": "Enable command timing"}, {"location": "computer_science/gnu_linux/postgresql/#stopkill-process", "text": "First locate the process pid with SELECT pid , query FROM pg_stat_activity WHERE state = 'active' ; Then, stop or kill the process with SELECT pg_cancel_backend({pid}) or pg_termiante_backend({pid}) respectively.", "title": "Stop/kill process"}, {"location": "computer_science/gnu_linux/postgresql/#configuration", "text": "You can use PGTune to calculate configuration for PostgreSQL based on the maximum performance for a given hardware configuration.", "title": "Configuration"}, {"location": "computer_science/gnu_linux/postgresql/#parallelization", "text": "To tune the number of workers edit postgresql.conf and in the - Asynchronous Behavior - section edit max_worker_processes , max_parallel_workers_per_gather and max_parallel_workers .", "title": "Parallelization"}, {"location": "computer_science/gnu_linux/postgresql/#administration", "text": "", "title": "Administration"}, {"location": "computer_science/gnu_linux/postgresql/#change-user-password", "text": "ALTER USER user_name WITH PASSWORD 'new_password' ;", "title": "Change user password"}, {"location": "computer_science/gnu_linux/postgresql/#reference", "text": "", "title": "Reference"}, {"location": "computer_science/gnu_linux/postgresql/#data-types", "text": "Numeric Types", "title": "Data types"}, {"location": "computer_science/gnu_linux/profanity/", "text": "Usage \u2691 Most common commands \u2691 General \u2691 \\msg {user@server.tld} : Start a conversation. \\roster add {user@server.tld} : Add user to contacts. \\sub request {user@server.tld} : Request presence updates from user. OMEMO \u2691 In a chat with another user: \\omemo start : Start an OMEMO session.", "title": "Profanity"}, {"location": "computer_science/gnu_linux/profanity/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/profanity/#most-common-commands", "text": "", "title": "Most common commands"}, {"location": "computer_science/gnu_linux/profanity/#general", "text": "\\msg {user@server.tld} : Start a conversation. \\roster add {user@server.tld} : Add user to contacts. \\sub request {user@server.tld} : Request presence updates from user.", "title": "General"}, {"location": "computer_science/gnu_linux/profanity/#omemo", "text": "In a chat with another user: \\omemo start : Start an OMEMO session.", "title": "OMEMO"}, {"location": "computer_science/gnu_linux/pulseaudio/", "text": "PulseAudio \u2691 Reference \u2691 ArchLinux Examples [Usage with Docker]( https://github.com/mviereck/x11docker/wiki/Container-sound:-ALSA-or-Pulseaudio )", "title": "PulseAudio"}, {"location": "computer_science/gnu_linux/pulseaudio/#pulseaudio", "text": "", "title": "PulseAudio"}, {"location": "computer_science/gnu_linux/pulseaudio/#reference", "text": "ArchLinux Examples [Usage with Docker]( https://github.com/mviereck/x11docker/wiki/Container-sound:-ALSA-or-Pulseaudio )", "title": "Reference"}, {"location": "computer_science/gnu_linux/qutebrowser/", "text": "Plugins \u2691 Greasemonkey \u2691 To install a greasemonkey plugin, download the script to ~/.local/share/qutebrowser/greasemonkey and then from qutebrowser run greasemonkey-reload . Auto Close YouTube Ads \u2691 Get it with: curl -o ~/.local/share/qutebrowser/greasemonkey/yt-autoclose.js https://greasyfork.org/scripts/9165-auto-close-youtube-ads/code/Auto%20Close%20YouTube%20Ads.user.js Reference \u2691 Nord theme", "title": "qutebrowser"}, {"location": "computer_science/gnu_linux/qutebrowser/#plugins", "text": "", "title": "Plugins"}, {"location": "computer_science/gnu_linux/qutebrowser/#greasemonkey", "text": "To install a greasemonkey plugin, download the script to ~/.local/share/qutebrowser/greasemonkey and then from qutebrowser run greasemonkey-reload .", "title": "Greasemonkey"}, {"location": "computer_science/gnu_linux/qutebrowser/#auto-close-youtube-ads", "text": "Get it with: curl -o ~/.local/share/qutebrowser/greasemonkey/yt-autoclose.js https://greasyfork.org/scripts/9165-auto-close-youtube-ads/code/Auto%20Close%20YouTube%20Ads.user.js", "title": "Auto Close YouTube Ads"}, {"location": "computer_science/gnu_linux/qutebrowser/#reference", "text": "Nord theme", "title": "Reference"}, {"location": "computer_science/gnu_linux/radare2/", "text": "radare2 \u2691 Install \u2691 From the sources folder (cloned from git): sudo ./sys/install.sh It will update, compile and install. ~2min", "title": "Radare2"}, {"location": "computer_science/gnu_linux/radare2/#radare2", "text": "", "title": "radare2"}, {"location": "computer_science/gnu_linux/radare2/#install", "text": "From the sources folder (cloned from git): sudo ./sys/install.sh It will update, compile and install. ~2min", "title": "Install"}, {"location": "computer_science/gnu_linux/ranger/", "text": "Ranger \u2691 Usage \u2691 Move files \u2691 Select them by pressing the space bar and then, dd to cut and pp to paste in another directory. stackexchange", "title": "Ranger"}, {"location": "computer_science/gnu_linux/ranger/#ranger", "text": "", "title": "Ranger"}, {"location": "computer_science/gnu_linux/ranger/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/ranger/#move-files", "text": "Select them by pressing the space bar and then, dd to cut and pp to paste in another directory. stackexchange", "title": "Move files"}, {"location": "computer_science/gnu_linux/rpi/", "text": "Raspberry Pi \u2691 Guide \u2691 Resize boot partition \u2691 The default boot partition size is sometimes not enough. In order to resize it, we need to extract the SD/microSD card and plug it in on another device. Then with gparted : Move the ext4 main data partition to the right, shrinking it if necessary. Mount the boot fat32 partition and copy its contents to your disk. E.g. cp -r /media/sdc1/ /tmp/sdc1 . Resize the boot partition and format it, because the gparted file system resize will fail due to the bug 649324 . Copy the contents back again to the newly formatted partition. E.g. cp -r /tmp/sdc1/* /media/sdc1 . Unmount the boot partition. Everything should be ready now. Raspberry Pi Forums Disable swap \u2691 To make your SD card live longer, you can reduce the number of reads and writes by completely disabling swap. sudo dphys-swapfile swapoff sudo dphys-swapfile uninstall sudo update-rc.d dphys-swapfile remove Stopping SD Card Corruption on Raspberry Pi\u2019s Raspbian \u2013 IdeaHeap", "title": "Raspberry Pi"}, {"location": "computer_science/gnu_linux/rpi/#raspberry-pi", "text": "", "title": "Raspberry Pi"}, {"location": "computer_science/gnu_linux/rpi/#guide", "text": "", "title": "Guide"}, {"location": "computer_science/gnu_linux/rpi/#resize-boot-partition", "text": "The default boot partition size is sometimes not enough. In order to resize it, we need to extract the SD/microSD card and plug it in on another device. Then with gparted : Move the ext4 main data partition to the right, shrinking it if necessary. Mount the boot fat32 partition and copy its contents to your disk. E.g. cp -r /media/sdc1/ /tmp/sdc1 . Resize the boot partition and format it, because the gparted file system resize will fail due to the bug 649324 . Copy the contents back again to the newly formatted partition. E.g. cp -r /tmp/sdc1/* /media/sdc1 . Unmount the boot partition. Everything should be ready now. Raspberry Pi Forums", "title": "Resize boot partition"}, {"location": "computer_science/gnu_linux/rpi/#disable-swap", "text": "To make your SD card live longer, you can reduce the number of reads and writes by completely disabling swap. sudo dphys-swapfile swapoff sudo dphys-swapfile uninstall sudo update-rc.d dphys-swapfile remove Stopping SD Card Corruption on Raspberry Pi\u2019s Raspbian \u2013 IdeaHeap", "title": "Disable swap"}, {"location": "computer_science/gnu_linux/rsnapshot/", "text": "Rsnapshot \u2691 Reference \u2691 howto", "title": "rsnapshot"}, {"location": "computer_science/gnu_linux/rsnapshot/#rsnapshot", "text": "", "title": "Rsnapshot"}, {"location": "computer_science/gnu_linux/rsnapshot/#reference", "text": "howto", "title": "Reference"}, {"location": "computer_science/gnu_linux/rsync/", "text": "rsync \u2691 Copy folder contents and delete anything else \u2691 rsync -avz --delete [folder] [host]:[path] Exclude a path or regex \u2691 rsync --exclude \"[path/regex]\" Where the path is relative to the path we want to sync. thegeekstuff", "title": "rsync"}, {"location": "computer_science/gnu_linux/rsync/#rsync", "text": "", "title": "rsync"}, {"location": "computer_science/gnu_linux/rsync/#copy-folder-contents-and-delete-anything-else", "text": "rsync -avz --delete [folder] [host]:[path]", "title": "Copy folder contents and delete anything else"}, {"location": "computer_science/gnu_linux/rsync/#exclude-a-path-or-regex", "text": "rsync --exclude \"[path/regex]\" Where the path is relative to the path we want to sync. thegeekstuff", "title": "Exclude a path or regex"}, {"location": "computer_science/gnu_linux/rxvt-unicode/", "text": "RXVT Unicode (urxvt) \u2691 Debug \u2691 SSH: 'rxvt-unicode-256color': unknown terminal type \u2691 First create the directory to keep the terminfo file in the server: mkdir -p ~/.terminfo/r And then from the host: scp /usr/share/terminfo/r/rxvt-unicode-256color [server]:.terminfo/r alemani It is a good idea to copy it directly to /usr/share/terminfo/r/rxvt-unicode-256color in the remote server if possible.", "title": "rxvt-unicode"}, {"location": "computer_science/gnu_linux/rxvt-unicode/#rxvt-unicode-urxvt", "text": "", "title": "RXVT Unicode (urxvt)"}, {"location": "computer_science/gnu_linux/rxvt-unicode/#debug", "text": "", "title": "Debug"}, {"location": "computer_science/gnu_linux/rxvt-unicode/#ssh-rxvt-unicode-256color-unknown-terminal-type", "text": "First create the directory to keep the terminfo file in the server: mkdir -p ~/.terminfo/r And then from the host: scp /usr/share/terminfo/r/rxvt-unicode-256color [server]:.terminfo/r alemani It is a good idea to copy it directly to /usr/share/terminfo/r/rxvt-unicode-256color in the remote server if possible.", "title": "SSH: 'rxvt-unicode-256color': unknown terminal type"}, {"location": "computer_science/gnu_linux/sed/", "text": "sed \u2691 Replace SSHd port with regexp \u2691 sed -i 's/^Port .*/Port 77/g' /etc/ssh/sshd_config", "title": "sed"}, {"location": "computer_science/gnu_linux/sed/#sed", "text": "", "title": "sed"}, {"location": "computer_science/gnu_linux/sed/#replace-sshd-port-with-regexp", "text": "sed -i 's/^Port .*/Port 77/g' /etc/ssh/sshd_config", "title": "Replace SSHd port with regexp"}, {"location": "computer_science/gnu_linux/shell-utils/", "text": "Shell Utillities \u2691 Reference \u2691 Search \u2691 Search patterns in files \u2691 ripgrep Benchmark and stress \u2691 Stress \u2691 stress Disk usage analyzer \u2691 ncdu Filename Formating \u2691 Cleaning \u2691 detox", "title": "Shell-utils"}, {"location": "computer_science/gnu_linux/shell-utils/#shell-utillities", "text": "", "title": "Shell Utillities"}, {"location": "computer_science/gnu_linux/shell-utils/#reference", "text": "", "title": "Reference"}, {"location": "computer_science/gnu_linux/shell-utils/#search", "text": "", "title": "Search"}, {"location": "computer_science/gnu_linux/shell-utils/#search-patterns-in-files", "text": "ripgrep", "title": "Search patterns in files"}, {"location": "computer_science/gnu_linux/shell-utils/#benchmark-and-stress", "text": "", "title": "Benchmark and stress"}, {"location": "computer_science/gnu_linux/shell-utils/#stress", "text": "stress", "title": "Stress"}, {"location": "computer_science/gnu_linux/shell-utils/#disk-usage-analyzer", "text": "ncdu", "title": "Disk usage analyzer"}, {"location": "computer_science/gnu_linux/shell-utils/#filename-formating", "text": "", "title": "Filename Formating"}, {"location": "computer_science/gnu_linux/shell-utils/#cleaning", "text": "detox", "title": "Cleaning"}, {"location": "computer_science/gnu_linux/shell/", "text": "unix shell \u2691 Colors \u2691 echo -e \"No color. \\033[0;31mcolor \\033[0m no color again\" stackoverflow", "title": "Shell"}, {"location": "computer_science/gnu_linux/shell/#unix-shell", "text": "", "title": "unix shell"}, {"location": "computer_science/gnu_linux/shell/#colors", "text": "echo -e \"No color. \\033[0;31mcolor \\033[0m no color again\" stackoverflow", "title": "Colors"}, {"location": "computer_science/gnu_linux/shnsplit/", "text": "shnsplit utility \u2691 Split multi-track FLAC to single tracks \u2691 You need the cue file for the times and metadata. Then: shnsplit -f file.cue -t %n-%t -o flac file.flac stackexchange", "title": "shnsplit"}, {"location": "computer_science/gnu_linux/shnsplit/#shnsplit-utility", "text": "", "title": "shnsplit utility"}, {"location": "computer_science/gnu_linux/shnsplit/#split-multi-track-flac-to-single-tracks", "text": "You need the cue file for the times and metadata. Then: shnsplit -f file.cue -t %n-%t -o flac file.flac stackexchange", "title": "Split multi-track FLAC to single tracks"}, {"location": "computer_science/gnu_linux/smartmontools/", "text": "smartmontools \u2691 Usage \u2691 Understanding the exit code \u2691 Check the manual for the exit code values interpretation. There is a code for understanding the mask. Debug \u2691 Long test won't finish on a external drive \u2691 If you are getting Interrupted (host reset) in the selftest log it's probably because you are using an external drive and the OS is stopping it after a while. We need the disk to be active for the host all the time to avoid suspension, to do so we can do: sudo bash -c 'while true; do smartctl -a /dev/sdb > /dev/null; sleep 60; done' StackExchange Reference \u2691 General usage \u2691 gentoo wiki", "title": "smartmontools"}, {"location": "computer_science/gnu_linux/smartmontools/#smartmontools", "text": "", "title": "smartmontools"}, {"location": "computer_science/gnu_linux/smartmontools/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/smartmontools/#understanding-the-exit-code", "text": "Check the manual for the exit code values interpretation. There is a code for understanding the mask.", "title": "Understanding the exit code"}, {"location": "computer_science/gnu_linux/smartmontools/#debug", "text": "", "title": "Debug"}, {"location": "computer_science/gnu_linux/smartmontools/#long-test-wont-finish-on-a-external-drive", "text": "If you are getting Interrupted (host reset) in the selftest log it's probably because you are using an external drive and the OS is stopping it after a while. We need the disk to be active for the host all the time to avoid suspension, to do so we can do: sudo bash -c 'while true; do smartctl -a /dev/sdb > /dev/null; sleep 60; done' StackExchange", "title": "Long test won't finish on a external drive"}, {"location": "computer_science/gnu_linux/smartmontools/#reference", "text": "", "title": "Reference"}, {"location": "computer_science/gnu_linux/smartmontools/#general-usage", "text": "gentoo wiki", "title": "General usage"}, {"location": "computer_science/gnu_linux/ss/", "text": "ss \u2691 List TCP binds by process \u2691 ss -ltp", "title": "ss"}, {"location": "computer_science/gnu_linux/ss/#ss", "text": "", "title": "ss"}, {"location": "computer_science/gnu_linux/ss/#list-tcp-binds-by-process", "text": "ss -ltp", "title": "List TCP binds by process"}, {"location": "computer_science/gnu_linux/ssh/", "text": "Setup \u2691 Create SSH key \u2691 ssh-keygen -t ed25519 -b 4096 -o -a 1000 -C \"{username}\" -f .ssh/ { file } Usage \u2691 Connecting \u2691 Force password login \u2691 ssh -o PreferredAuthentications=password -o PubkeyAuthentication=no [host] unix-stack_echange Jumping through a host \u2691 ssh -J [host1] [host2] wiki-gentoo SSH tunneling \u2691 Make Remote Resources Accessible on Your Local System \u2691 ssh -L local_port:remote_address:remote_port username@server.com howtogeek Config \u2691 Multiple similar entries \u2691 If you have multiple similar entries, they can share the common part: Host X01 HostName X01.YYY.com Host X02 HostName X02.YYY.com ... Host X01 X02 ... User my_username Compression yes Ciphers arcfour,blowfish-cbc Protocol 2 ControlMaster auto ControlPath ~/.ssh/%r@%h:%p IdentityFile ~/.ssh/YYY/id_rsa stackexchange Conflicting remote host keys on the same IP \u2691 If you have different servers that use the same IP (at different times maybe), you'll have some annoying security alerts about their keys not matching with the previously stored one (since you only can save one of them). What you can do without risking the connection security is adding thes hosts like this in your ~/.ssh/config : Host server1 Hostname x1.example.com HostKeyAlias server1 CheckHostIP no Port 22001 User karl Host server2 Hostname x2.example.com HostKeyAlias server2 CheckHostIP no Port 22002 User karl The important part is the HostKeyAlias line, that allows the SSH client to store the remote server public keys with the alias instead of with the unique shared IP address. stackoverflow Dynamic IP host verification \u2691 When you have a dynamic IP host, you might get Warning: the [whatever] host key for '[host]' differs from the key for the IP address that is true, but also pretty annoying. If you'd rather just verify a host by its keys, instead of keys+IP, try with: Host nickname HostName example.dynamic.tld CheckHostIP no askubuntu Debug \u2691 Ctrl+s hangs the terminal \u2691 From vimdoc : Note: CTRL-S does not work on all terminals and might block further input, use CTRL-Q to get going again. stackexchange", "title": "SSH"}, {"location": "computer_science/gnu_linux/ssh/#setup", "text": "", "title": "Setup"}, {"location": "computer_science/gnu_linux/ssh/#create-ssh-key", "text": "ssh-keygen -t ed25519 -b 4096 -o -a 1000 -C \"{username}\" -f .ssh/ { file }", "title": "Create SSH key"}, {"location": "computer_science/gnu_linux/ssh/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/ssh/#connecting", "text": "", "title": "Connecting"}, {"location": "computer_science/gnu_linux/ssh/#force-password-login", "text": "ssh -o PreferredAuthentications=password -o PubkeyAuthentication=no [host] unix-stack_echange", "title": "Force password login"}, {"location": "computer_science/gnu_linux/ssh/#jumping-through-a-host", "text": "ssh -J [host1] [host2] wiki-gentoo", "title": "Jumping through a host"}, {"location": "computer_science/gnu_linux/ssh/#ssh-tunneling", "text": "", "title": "SSH tunneling"}, {"location": "computer_science/gnu_linux/ssh/#make-remote-resources-accessible-on-your-local-system", "text": "ssh -L local_port:remote_address:remote_port username@server.com howtogeek", "title": "Make Remote Resources Accessible on Your Local System"}, {"location": "computer_science/gnu_linux/ssh/#config", "text": "", "title": "Config"}, {"location": "computer_science/gnu_linux/ssh/#multiple-similar-entries", "text": "If you have multiple similar entries, they can share the common part: Host X01 HostName X01.YYY.com Host X02 HostName X02.YYY.com ... Host X01 X02 ... User my_username Compression yes Ciphers arcfour,blowfish-cbc Protocol 2 ControlMaster auto ControlPath ~/.ssh/%r@%h:%p IdentityFile ~/.ssh/YYY/id_rsa stackexchange", "title": "Multiple similar entries"}, {"location": "computer_science/gnu_linux/ssh/#conflicting-remote-host-keys-on-the-same-ip", "text": "If you have different servers that use the same IP (at different times maybe), you'll have some annoying security alerts about their keys not matching with the previously stored one (since you only can save one of them). What you can do without risking the connection security is adding thes hosts like this in your ~/.ssh/config : Host server1 Hostname x1.example.com HostKeyAlias server1 CheckHostIP no Port 22001 User karl Host server2 Hostname x2.example.com HostKeyAlias server2 CheckHostIP no Port 22002 User karl The important part is the HostKeyAlias line, that allows the SSH client to store the remote server public keys with the alias instead of with the unique shared IP address. stackoverflow", "title": "Conflicting remote host keys on the same IP"}, {"location": "computer_science/gnu_linux/ssh/#dynamic-ip-host-verification", "text": "When you have a dynamic IP host, you might get Warning: the [whatever] host key for '[host]' differs from the key for the IP address that is true, but also pretty annoying. If you'd rather just verify a host by its keys, instead of keys+IP, try with: Host nickname HostName example.dynamic.tld CheckHostIP no askubuntu", "title": "Dynamic IP host verification"}, {"location": "computer_science/gnu_linux/ssh/#debug", "text": "", "title": "Debug"}, {"location": "computer_science/gnu_linux/ssh/#ctrls-hangs-the-terminal", "text": "From vimdoc : Note: CTRL-S does not work on all terminals and might block further input, use CTRL-Q to get going again. stackexchange", "title": "Ctrl+s hangs the terminal"}, {"location": "computer_science/gnu_linux/stat/", "text": "stat \u2691 Usage \u2691 Get octal permissions of a file or directory \u2691 stat -c \"%a %n\" [ path ] askubuntu", "title": "stat"}, {"location": "computer_science/gnu_linux/stat/#stat", "text": "", "title": "stat"}, {"location": "computer_science/gnu_linux/stat/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/stat/#get-octal-permissions-of-a-file-or-directory", "text": "stat -c \"%a %n\" [ path ] askubuntu", "title": "Get octal permissions of a file or directory"}, {"location": "computer_science/gnu_linux/sysctl/", "text": "sysctl \u2691 Debug \u2691 Computer freezing on almost full RAM \u2691 SWAP needs to be used before. Try to set the minimun free RAM values to a 5-6% of the full memory by core. sysctl -w vm.min_free_kbytes=121268 6% of 8GB multiplied by 4 cores Also: sysctl -w vm.swappiness=5 Values from 0 to 100, being 0 only using SWAP if absolutely necessary. Note: Write this changes in /etc/sysctl.conf to make them permanent. askubuntu", "title": "sysctl"}, {"location": "computer_science/gnu_linux/sysctl/#sysctl", "text": "", "title": "sysctl"}, {"location": "computer_science/gnu_linux/sysctl/#debug", "text": "", "title": "Debug"}, {"location": "computer_science/gnu_linux/sysctl/#computer-freezing-on-almost-full-ram", "text": "SWAP needs to be used before. Try to set the minimun free RAM values to a 5-6% of the full memory by core. sysctl -w vm.min_free_kbytes=121268 6% of 8GB multiplied by 4 cores Also: sysctl -w vm.swappiness=5 Values from 0 to 100, being 0 only using SWAP if absolutely necessary. Note: Write this changes in /etc/sysctl.conf to make them permanent. askubuntu", "title": "Computer freezing on almost full RAM"}, {"location": "computer_science/gnu_linux/systemd/", "text": "systemd \u2691 Usage \u2691 Changing directory \u2691 In a unit.service file: [service] WorkingDirectory=[path] unix-stackexchange Setting a start timeout \u2691 TimoutStartSec= Setting a dealy before restarting \u2691 RestartSec= Debug \u2691 Service unit dependency error \u2691 Instead of using Requires= try using Wants= so that systemd won't fail and retries if configured to do so.", "title": "SystemD"}, {"location": "computer_science/gnu_linux/systemd/#systemd", "text": "", "title": "systemd"}, {"location": "computer_science/gnu_linux/systemd/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/systemd/#changing-directory", "text": "In a unit.service file: [service] WorkingDirectory=[path] unix-stackexchange", "title": "Changing directory"}, {"location": "computer_science/gnu_linux/systemd/#setting-a-start-timeout", "text": "TimoutStartSec=", "title": "Setting a start timeout"}, {"location": "computer_science/gnu_linux/systemd/#setting-a-dealy-before-restarting", "text": "RestartSec=", "title": "Setting a dealy before restarting"}, {"location": "computer_science/gnu_linux/systemd/#debug", "text": "", "title": "Debug"}, {"location": "computer_science/gnu_linux/systemd/#service-unit-dependency-error", "text": "Instead of using Requires= try using Wants= so that systemd won't fail and retries if configured to do so.", "title": "Service unit dependency error"}, {"location": "computer_science/gnu_linux/taskwarrior/", "text": "taskwarrior \u2691 Usage \u2691 General commands \u2691 task all List all tasks (including done). task denotate \"annotation..\" . Cool commands \u2691 task summary : shows projects' progress. Reference \u2691 duration Plugins \u2691 taskwarrior-time-tracking-hook", "title": "Taskwarrior"}, {"location": "computer_science/gnu_linux/taskwarrior/#taskwarrior", "text": "", "title": "taskwarrior"}, {"location": "computer_science/gnu_linux/taskwarrior/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/taskwarrior/#general-commands", "text": "task all List all tasks (including done). task denotate \"annotation..\" .", "title": "General commands"}, {"location": "computer_science/gnu_linux/taskwarrior/#cool-commands", "text": "task summary : shows projects' progress.", "title": "Cool commands"}, {"location": "computer_science/gnu_linux/taskwarrior/#reference", "text": "duration", "title": "Reference"}, {"location": "computer_science/gnu_linux/taskwarrior/#plugins", "text": "taskwarrior-time-tracking-hook", "title": "Plugins"}, {"location": "computer_science/gnu_linux/tcpdump/", "text": "tcpdump \u2691 Usage \u2691 Basic example: tcpdump -i [ interface ] port [ port ] Reference \u2691 Usage examples \u2691 hackertarget", "title": "tcpdump"}, {"location": "computer_science/gnu_linux/tcpdump/#tcpdump", "text": "", "title": "tcpdump"}, {"location": "computer_science/gnu_linux/tcpdump/#usage", "text": "Basic example: tcpdump -i [ interface ] port [ port ]", "title": "Usage"}, {"location": "computer_science/gnu_linux/tcpdump/#reference", "text": "", "title": "Reference"}, {"location": "computer_science/gnu_linux/tcpdump/#usage-examples", "text": "hackertarget", "title": "Usage examples"}, {"location": "computer_science/gnu_linux/telegraf/", "text": "Telegraf: metrics collector \u2691 Install \u2691 For Debian 9 Stretch: cat <<EOF | sudo tee /etc/apt/sources.list.d/influxdata.list deb https://repos.influxdata.com/debian stretch stable EOF curl -sL https://repos.influxdata.com/influxdb.key | apt-key add - apt update && apt install telegraf -y systemctl enable --now telegraf computingforgeeks Config \u2691 Docker \u2691 usermod -a -G docker telegraf Nginx logparser \u2691 usermod -a -G adm telegraf Nginx status \u2691 Enable stub_status : location /nginx_status { stub_status on; allow 127.0.0.1; #only allow requests from localhost deny all; #deny all other hosts } Smartctl \u2691 Install smartmontools and add with visudo the following lines: # Monitoring tool telegraf ALL=(ALL) NOPASSWD: /usr/sbin/smartctl", "title": "Telegraf"}, {"location": "computer_science/gnu_linux/telegraf/#telegraf-metrics-collector", "text": "", "title": "Telegraf: metrics collector"}, {"location": "computer_science/gnu_linux/telegraf/#install", "text": "For Debian 9 Stretch: cat <<EOF | sudo tee /etc/apt/sources.list.d/influxdata.list deb https://repos.influxdata.com/debian stretch stable EOF curl -sL https://repos.influxdata.com/influxdb.key | apt-key add - apt update && apt install telegraf -y systemctl enable --now telegraf computingforgeeks", "title": "Install"}, {"location": "computer_science/gnu_linux/telegraf/#config", "text": "", "title": "Config"}, {"location": "computer_science/gnu_linux/telegraf/#docker", "text": "usermod -a -G docker telegraf", "title": "Docker"}, {"location": "computer_science/gnu_linux/telegraf/#nginx-logparser", "text": "usermod -a -G adm telegraf", "title": "Nginx logparser"}, {"location": "computer_science/gnu_linux/telegraf/#nginx-status", "text": "Enable stub_status : location /nginx_status { stub_status on; allow 127.0.0.1; #only allow requests from localhost deny all; #deny all other hosts }", "title": "Nginx status"}, {"location": "computer_science/gnu_linux/telegraf/#smartctl", "text": "Install smartmontools and add with visudo the following lines: # Monitoring tool telegraf ALL=(ALL) NOPASSWD: /usr/sbin/smartctl", "title": "Smartctl"}, {"location": "computer_science/gnu_linux/telegram-cli/", "text": "telegram-cli usage guide \u2691 Command line launch options \u2691 -k [key] : Telegram server public key. By dafault in /etc/telegram-cli/server.pub --enable-msg-id or -N : Enable showing message ids, useful for viewing media files. askubuntu", "title": "telegram-cli"}, {"location": "computer_science/gnu_linux/telegram-cli/#telegram-cli-usage-guide", "text": "", "title": "telegram-cli usage guide"}, {"location": "computer_science/gnu_linux/telegram-cli/#command-line-launch-options", "text": "-k [key] : Telegram server public key. By dafault in /etc/telegram-cli/server.pub --enable-msg-id or -N : Enable showing message ids, useful for viewing media files. askubuntu", "title": "Command line launch options"}, {"location": "computer_science/gnu_linux/terminal/", "text": "Terminal emulator \u2691 Tips \u2691 Test colors \u2691 cd /tmp wget https://gist.githubusercontent.com/HaleTom/89ffe32783f89f403bba96bd7bcd1263/raw/e50a28ec54188d2413518788de6c6367ffcea4f7/print256colours.sh chmod u+x print256colours.sh ./print256colours.sh askubuntu", "title": "Terminal"}, {"location": "computer_science/gnu_linux/terminal/#terminal-emulator", "text": "", "title": "Terminal emulator"}, {"location": "computer_science/gnu_linux/terminal/#tips", "text": "", "title": "Tips"}, {"location": "computer_science/gnu_linux/terminal/#test-colors", "text": "cd /tmp wget https://gist.githubusercontent.com/HaleTom/89ffe32783f89f403bba96bd7bcd1263/raw/e50a28ec54188d2413518788de6c6367ffcea4f7/print256colours.sh chmod u+x print256colours.sh ./print256colours.sh askubuntu", "title": "Test colors"}, {"location": "computer_science/gnu_linux/termite/", "text": "termite usage guide \u2691 Usage \u2691 Shortcuts \u2691 ctrl-shift-r : Reload configuration file. Config \u2691 Color themes \u2691 solarized Debug \u2691 SSH problems \u2691 github-issue References \u2691 github archlinux-wiki", "title": "Termite"}, {"location": "computer_science/gnu_linux/termite/#termite-usage-guide", "text": "", "title": "termite usage guide"}, {"location": "computer_science/gnu_linux/termite/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/termite/#shortcuts", "text": "ctrl-shift-r : Reload configuration file.", "title": "Shortcuts"}, {"location": "computer_science/gnu_linux/termite/#config", "text": "", "title": "Config"}, {"location": "computer_science/gnu_linux/termite/#color-themes", "text": "solarized", "title": "Color themes"}, {"location": "computer_science/gnu_linux/termite/#debug", "text": "", "title": "Debug"}, {"location": "computer_science/gnu_linux/termite/#ssh-problems", "text": "github-issue", "title": "SSH problems"}, {"location": "computer_science/gnu_linux/termite/#references", "text": "github archlinux-wiki", "title": "References"}, {"location": "computer_science/gnu_linux/timedatectl/", "text": "timedatectl \u2014- control the system time and date. Usage \u2691 Get available timezones \u2691 timedatectl list-timezones Change the system timezone \u2691 timedatectl set-timezone { timezone }", "title": "timedatectl"}, {"location": "computer_science/gnu_linux/timedatectl/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/timedatectl/#get-available-timezones", "text": "timedatectl list-timezones", "title": "Get available timezones"}, {"location": "computer_science/gnu_linux/timedatectl/#change-the-system-timezone", "text": "timedatectl set-timezone { timezone }", "title": "Change the system timezone"}, {"location": "computer_science/gnu_linux/tmux/", "text": "tmux \u2691 Usage \u2691 Managing panes and windows \u2691 Resize a pane \u2691 Ctrl+b and then: :resize-pane -D (Resizes the current pane down) :resize-pane -U (Resizes the current pane upward) :resize-pane -L (Resizes the current pane left) :resize-pane -R (Resizes the current pane right) :resize-pane -D 10 (Resizes the current pane down by 10 cells) :resize-pane -U 10 (Resizes the current pane upward by 10 cells) :resize-pane -L 10 (Resizes the current pane left by 10 cells) :resize-pane -R 10 (Resizes the current pane right by 10 cells) micahelsoolee Config \u2691 Default setup \u2691 Create a file with the instructions. For example ~/.tmux/main : #main new -s main htop splitw -v -p 50 -t 0 \"docker stats $(docker ps --format '{{.Names}}')\" splitw -h -p 50 -t 0 nload eth0 neww selectw -t 0 selectp -t 2 And then source it with a bind or by default (so it is used when running tmux a without an existing session) in ~/.tmux.conf : source-file ~/.tmux/main stackoverflow Debug \u2691 Protocol version mismatch \u2691 When upgrading a system and trying to attach an existing Tmux session that was created with a different version of the currently installed one. pgrep tmux /proc/ [ pid ] /exe attach stackexchange", "title": "tmux"}, {"location": "computer_science/gnu_linux/tmux/#tmux", "text": "", "title": "tmux"}, {"location": "computer_science/gnu_linux/tmux/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/tmux/#managing-panes-and-windows", "text": "", "title": "Managing panes and windows"}, {"location": "computer_science/gnu_linux/tmux/#resize-a-pane", "text": "Ctrl+b and then: :resize-pane -D (Resizes the current pane down) :resize-pane -U (Resizes the current pane upward) :resize-pane -L (Resizes the current pane left) :resize-pane -R (Resizes the current pane right) :resize-pane -D 10 (Resizes the current pane down by 10 cells) :resize-pane -U 10 (Resizes the current pane upward by 10 cells) :resize-pane -L 10 (Resizes the current pane left by 10 cells) :resize-pane -R 10 (Resizes the current pane right by 10 cells) micahelsoolee", "title": "Resize a pane"}, {"location": "computer_science/gnu_linux/tmux/#config", "text": "", "title": "Config"}, {"location": "computer_science/gnu_linux/tmux/#default-setup", "text": "Create a file with the instructions. For example ~/.tmux/main : #main new -s main htop splitw -v -p 50 -t 0 \"docker stats $(docker ps --format '{{.Names}}')\" splitw -h -p 50 -t 0 nload eth0 neww selectw -t 0 selectp -t 2 And then source it with a bind or by default (so it is used when running tmux a without an existing session) in ~/.tmux.conf : source-file ~/.tmux/main stackoverflow", "title": "Default setup"}, {"location": "computer_science/gnu_linux/tmux/#debug", "text": "", "title": "Debug"}, {"location": "computer_science/gnu_linux/tmux/#protocol-version-mismatch", "text": "When upgrading a system and trying to attach an existing Tmux session that was created with a different version of the currently installed one. pgrep tmux /proc/ [ pid ] /exe attach stackexchange", "title": "Protocol version mismatch"}, {"location": "computer_science/gnu_linux/tor/", "text": "TOR \u2691 Configuration \u2691 Hidden services \u2691 Enable HiddenServiceDir and at least one HiddenServicePort in /etc/tor/torrc . Then create the HiddenServiceDir and give it the proper permissions, for example: mkdir /var/lib/tor/hidden_service/ chown debian-tor:debian-tor /var/lib/tor/hidden_service/ chmod 0700 /var/lib/tor/hidden_service/ Restart the tor service. You can get the hostname (.onion) from HiddenServiceDir /hostname . medium.com Custom onion hostname \u2691 To get a customized .onion url you can use Shallot . Debug \u2691 Check if Tor is working from the command line \u2691 curl --socks5 localhost:9050 --socks5-hostname localhost:9050 -s https://check.torproject.org/ | cat | grep -m 1 Congratulations | xargs stackexchange", "title": "TOR"}, {"location": "computer_science/gnu_linux/tor/#tor", "text": "", "title": "TOR"}, {"location": "computer_science/gnu_linux/tor/#configuration", "text": "", "title": "Configuration"}, {"location": "computer_science/gnu_linux/tor/#hidden-services", "text": "Enable HiddenServiceDir and at least one HiddenServicePort in /etc/tor/torrc . Then create the HiddenServiceDir and give it the proper permissions, for example: mkdir /var/lib/tor/hidden_service/ chown debian-tor:debian-tor /var/lib/tor/hidden_service/ chmod 0700 /var/lib/tor/hidden_service/ Restart the tor service. You can get the hostname (.onion) from HiddenServiceDir /hostname . medium.com", "title": "Hidden services"}, {"location": "computer_science/gnu_linux/tor/#custom-onion-hostname", "text": "To get a customized .onion url you can use Shallot .", "title": "Custom onion hostname"}, {"location": "computer_science/gnu_linux/tor/#debug", "text": "", "title": "Debug"}, {"location": "computer_science/gnu_linux/tor/#check-if-tor-is-working-from-the-command-line", "text": "curl --socks5 localhost:9050 --socks5-hostname localhost:9050 -s https://check.torproject.org/ | cat | grep -m 1 Congratulations | xargs stackexchange", "title": "Check if Tor is working from the command line"}, {"location": "computer_science/gnu_linux/uptimed/", "text": "uptimed is an uptime record daemon keeping track of the highest uptimes a computer system ever had. It uses the system boot time to keep sessions apart from each other. uptimed comes with a console front-end to parse the records, which can also easily be used to show your records on a web page. To set up the program just install it with your package manager and it will start running in the background by default and keeping track of your uptime. To check the stats run uprecords .", "title": "uptimed"}, {"location": "computer_science/gnu_linux/vagrant/", "text": "vagrant \u2691 Provisioning \u2691 Shell \u2691 config.vm.provision \"shell\", inline: \"echo hello\" vagrant-doc Ansible \u2691 # This guide is optimized for Vagrant 1.7 and above. # Although versions 1.6.x should behave very similarly, it is recommended # to upgrade instead of disabling the requirement below. Vagrant.require_version \">= 1.7.0\" Vagrant.configure(2) do |config| config.vm.box = \"debian/stretch64\" # Disable the new default behavior introduced in Vagrant 1.7, to # ensure that all Vagrant machines will use the same SSH key pair. # See https://github.com/mitchellh/vagrant/issues/5005 config.ssh.insert_key = false config.vm.provision \"ansible\" do |ansible| ansible.verbose = \"v\" ansible.playbook = \"playbook.yml\" ansible.host_key_checking = false ansible.extra_vars = { ansible_ssh_user: 'vagrant', testing: true } end end ansible-doc Workflow \u2691 First, start the VM (this will automatically deploy the playbook): vagrant up If you need to check something: vagrant ssh If you need to re-run the playbook: vagrant provision To stop and delete the VM: vagrant destroy --force Configuration \u2691 Common options \u2691 ansible.inventory_path = \"[path]\" ```vagrant ansible.groups = { \"web\" => [\"vm1\", \"vm2\"], \"db\" => [\"vm3\"] } [vagrant-doc](https://www.vagrantup.com/docs/provisioning/ansible_common.html) ## Tips ### Disable synced folder ```vagrant config.vm.synced_folder '.', '/vagrant', disabled: true superuser", "title": "Vagrant"}, {"location": "computer_science/gnu_linux/vagrant/#vagrant", "text": "", "title": "vagrant"}, {"location": "computer_science/gnu_linux/vagrant/#provisioning", "text": "", "title": "Provisioning"}, {"location": "computer_science/gnu_linux/vagrant/#shell", "text": "config.vm.provision \"shell\", inline: \"echo hello\" vagrant-doc", "title": "Shell"}, {"location": "computer_science/gnu_linux/vagrant/#ansible", "text": "# This guide is optimized for Vagrant 1.7 and above. # Although versions 1.6.x should behave very similarly, it is recommended # to upgrade instead of disabling the requirement below. Vagrant.require_version \">= 1.7.0\" Vagrant.configure(2) do |config| config.vm.box = \"debian/stretch64\" # Disable the new default behavior introduced in Vagrant 1.7, to # ensure that all Vagrant machines will use the same SSH key pair. # See https://github.com/mitchellh/vagrant/issues/5005 config.ssh.insert_key = false config.vm.provision \"ansible\" do |ansible| ansible.verbose = \"v\" ansible.playbook = \"playbook.yml\" ansible.host_key_checking = false ansible.extra_vars = { ansible_ssh_user: 'vagrant', testing: true } end end ansible-doc", "title": "Ansible"}, {"location": "computer_science/gnu_linux/vagrant/#workflow", "text": "First, start the VM (this will automatically deploy the playbook): vagrant up If you need to check something: vagrant ssh If you need to re-run the playbook: vagrant provision To stop and delete the VM: vagrant destroy --force", "title": "Workflow"}, {"location": "computer_science/gnu_linux/vagrant/#configuration", "text": "", "title": "Configuration"}, {"location": "computer_science/gnu_linux/vagrant/#common-options", "text": "ansible.inventory_path = \"[path]\" ```vagrant ansible.groups = { \"web\" => [\"vm1\", \"vm2\"], \"db\" => [\"vm3\"] } [vagrant-doc](https://www.vagrantup.com/docs/provisioning/ansible_common.html) ## Tips ### Disable synced folder ```vagrant config.vm.synced_folder '.', '/vagrant', disabled: true superuser", "title": "Common options"}, {"location": "computer_science/gnu_linux/vim/", "text": "Usage \u2691 Windows (split mode) \u2691 Switch between windows \u2691 Ctrl+w and the direction. Useful for vimdiff . quora Links \u2691 Follow link \u2691 Ctrl+] wikia Spell checking \u2691 To move to a misspelled word, use ]s and [s . To show suggestions use z= . To add a word to the dictionary use zg . To mark a correct word as misspelled, use zw . linux Set tabulation \u2691 Execute set tabstop=2 shiftwidth=2 expandtab and then, it's a good idea to execute :retab . stackoverflow Registers \u2691 Vim saves the \"clipboard\" history as registers. You can check the saved ones with :reg . If you want to paste the content of one of them use \"3p for example. Reference : superuser Sort \u2691 Vim has a very powerful built-in sort utility , or it can interface with an external one. In order to keep only unique lines and sort, : {range} sort u You can make a selection (with v or V for example) and then : '<,' > sort u Tips \u2691 Go to th nth line \u2691 [n]G for example: 42G . wikia Set filetype (useful for snippets) \u2691 :set filetype=[filetype] Disabling line numbers \u2691 Useful for copying. :set norelativenumber wikia Deleting trailing whitespaces automatically \u2691 Add the following line to your .vimrc to automatically delete the trailing whitespaces when saving the file if it's one of the specific file types: autocmd FileType c,cpp,java,php autocmd BufWritePre <buffer> %s/\\s\\+$//e wikia Breaking long lines automatically \u2691 set textwidth=79 stackexchange Change filetype based on directory path \u2691 autocmd BufRead,BufNewFile [path regex] set syntax=html wikia Autoindent with tab as 4 spaces \u2691 Set in .vimrc the following lines: syntax enable set smartindent set tabstop=4 set shiftwidth=4 set expandtab If you are working on a file and you want to indent it automatically from the beginning to the end use gg=G . coderwall Plugins \u2691 Jedi \u2691 davidhalter/jedi-vim uses the jedi Python autocompletion library for VIM. Shortcuts \u2691 Completion <C-Space> Goto assignment <leader>g (typical goto function) Goto definition <leader>d (follow identifier as far as possible, includes imports and statements) Goto (typing) stub <leader>s Show Documentation/Pydoc K (shows a popup with assignments) Renaming <leader>r Usages <leader>n (shows all the usages of a name) Open module, e.g. :Pyimport os (opens the os module) Syntastic \u2691 Disable Syntastic \u2691 :SyntasticToggleMode stackoverflow CtrlP \u2691 CtrlP changes working directory annoyingly \u2691 Disable working path mode feature: let g:ctrlp_working_path_mode = '0' stackoverflow UltiSnips and YouCompleteMe \u2691 Since by default they both use as a expand tab, we must do something about it. Using the SuperTab plugin: ```vimrc \" make YCM compatible with UltiSnips (using supertab) let g:ycm_key_list_select_completion = [' ', ' '] let g:ycm_key_list_previous_completion = [' ', ' '] let g:SuperTabDefaultCompletionType = ' ' \" better key bindings for UltiSnipsExpandTrigger let g:UltiSnipsExpandTrigger = \" \" let g:UltiSnipsJumpForwardTrigger = \" \" let g:UltiSnipsJumpBackwardTrigger = \" \" ```` stackoverflow Reference \u2691 spell checking window movement Registers \u2691 stackoverflow brianstorti Plugins \u2691 vim-autoclose : enable an auto-close chars feature.", "title": "Vim"}, {"location": "computer_science/gnu_linux/vim/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/vim/#windows-split-mode", "text": "", "title": "Windows (split mode)"}, {"location": "computer_science/gnu_linux/vim/#switch-between-windows", "text": "Ctrl+w and the direction. Useful for vimdiff . quora", "title": "Switch between windows"}, {"location": "computer_science/gnu_linux/vim/#links", "text": "", "title": "Links"}, {"location": "computer_science/gnu_linux/vim/#follow-link", "text": "Ctrl+] wikia", "title": "Follow link"}, {"location": "computer_science/gnu_linux/vim/#spell-checking", "text": "To move to a misspelled word, use ]s and [s . To show suggestions use z= . To add a word to the dictionary use zg . To mark a correct word as misspelled, use zw . linux", "title": "Spell checking"}, {"location": "computer_science/gnu_linux/vim/#set-tabulation", "text": "Execute set tabstop=2 shiftwidth=2 expandtab and then, it's a good idea to execute :retab . stackoverflow", "title": "Set tabulation"}, {"location": "computer_science/gnu_linux/vim/#registers", "text": "Vim saves the \"clipboard\" history as registers. You can check the saved ones with :reg . If you want to paste the content of one of them use \"3p for example. Reference : superuser", "title": "Registers"}, {"location": "computer_science/gnu_linux/vim/#sort", "text": "Vim has a very powerful built-in sort utility , or it can interface with an external one. In order to keep only unique lines and sort, : {range} sort u You can make a selection (with v or V for example) and then : '<,' > sort u", "title": "Sort"}, {"location": "computer_science/gnu_linux/vim/#tips", "text": "", "title": "Tips"}, {"location": "computer_science/gnu_linux/vim/#go-to-th-nth-line", "text": "[n]G for example: 42G . wikia", "title": "Go to th nth line"}, {"location": "computer_science/gnu_linux/vim/#set-filetype-useful-for-snippets", "text": ":set filetype=[filetype]", "title": "Set filetype (useful for snippets)"}, {"location": "computer_science/gnu_linux/vim/#disabling-line-numbers", "text": "Useful for copying. :set norelativenumber wikia", "title": "Disabling line numbers"}, {"location": "computer_science/gnu_linux/vim/#deleting-trailing-whitespaces-automatically", "text": "Add the following line to your .vimrc to automatically delete the trailing whitespaces when saving the file if it's one of the specific file types: autocmd FileType c,cpp,java,php autocmd BufWritePre <buffer> %s/\\s\\+$//e wikia", "title": "Deleting trailing whitespaces automatically"}, {"location": "computer_science/gnu_linux/vim/#breaking-long-lines-automatically", "text": "set textwidth=79 stackexchange", "title": "Breaking long lines automatically"}, {"location": "computer_science/gnu_linux/vim/#change-filetype-based-on-directory-path", "text": "autocmd BufRead,BufNewFile [path regex] set syntax=html wikia", "title": "Change filetype based on directory path"}, {"location": "computer_science/gnu_linux/vim/#autoindent-with-tab-as-4-spaces", "text": "Set in .vimrc the following lines: syntax enable set smartindent set tabstop=4 set shiftwidth=4 set expandtab If you are working on a file and you want to indent it automatically from the beginning to the end use gg=G . coderwall", "title": "Autoindent with tab as 4 spaces"}, {"location": "computer_science/gnu_linux/vim/#plugins", "text": "", "title": "Plugins"}, {"location": "computer_science/gnu_linux/vim/#jedi", "text": "davidhalter/jedi-vim uses the jedi Python autocompletion library for VIM.", "title": "Jedi"}, {"location": "computer_science/gnu_linux/vim/#shortcuts", "text": "Completion <C-Space> Goto assignment <leader>g (typical goto function) Goto definition <leader>d (follow identifier as far as possible, includes imports and statements) Goto (typing) stub <leader>s Show Documentation/Pydoc K (shows a popup with assignments) Renaming <leader>r Usages <leader>n (shows all the usages of a name) Open module, e.g. :Pyimport os (opens the os module)", "title": "Shortcuts"}, {"location": "computer_science/gnu_linux/vim/#syntastic", "text": "", "title": "Syntastic"}, {"location": "computer_science/gnu_linux/vim/#disable-syntastic", "text": ":SyntasticToggleMode stackoverflow", "title": "Disable Syntastic"}, {"location": "computer_science/gnu_linux/vim/#ctrlp", "text": "", "title": "CtrlP"}, {"location": "computer_science/gnu_linux/vim/#ctrlp-changes-working-directory-annoyingly", "text": "Disable working path mode feature: let g:ctrlp_working_path_mode = '0' stackoverflow", "title": "CtrlP changes working directory annoyingly"}, {"location": "computer_science/gnu_linux/vim/#ultisnips-and-youcompleteme", "text": "Since by default they both use as a expand tab, we must do something about it. Using the SuperTab plugin: ```vimrc \" make YCM compatible with UltiSnips (using supertab) let g:ycm_key_list_select_completion = [' ', ' '] let g:ycm_key_list_previous_completion = [' ', ' '] let g:SuperTabDefaultCompletionType = ' ' \" better key bindings for UltiSnipsExpandTrigger let g:UltiSnipsExpandTrigger = \" \" let g:UltiSnipsJumpForwardTrigger = \" \" let g:UltiSnipsJumpBackwardTrigger = \" \" ```` stackoverflow", "title": "UltiSnips and YouCompleteMe"}, {"location": "computer_science/gnu_linux/vim/#reference", "text": "spell checking window movement", "title": "Reference"}, {"location": "computer_science/gnu_linux/vim/#registers_1", "text": "stackoverflow brianstorti", "title": "Registers"}, {"location": "computer_science/gnu_linux/vim/#plugins_1", "text": "vim-autoclose : enable an auto-close chars feature.", "title": "Plugins"}, {"location": "computer_science/gnu_linux/vimdiff/", "text": "vimdiff \u2691 Plugins \u2691 Git \u2691 vim-gutter Diff \u2691 DirDiff Reference \u2691 Cheatsheet \u2691 github", "title": "vimdiff"}, {"location": "computer_science/gnu_linux/vimdiff/#vimdiff", "text": "", "title": "vimdiff"}, {"location": "computer_science/gnu_linux/vimdiff/#plugins", "text": "", "title": "Plugins"}, {"location": "computer_science/gnu_linux/vimdiff/#git", "text": "vim-gutter", "title": "Git"}, {"location": "computer_science/gnu_linux/vimdiff/#diff", "text": "DirDiff", "title": "Diff"}, {"location": "computer_science/gnu_linux/vimdiff/#reference", "text": "", "title": "Reference"}, {"location": "computer_science/gnu_linux/vimdiff/#cheatsheet", "text": "github", "title": "Cheatsheet"}, {"location": "computer_science/gnu_linux/virt-manager/", "text": "Virtual Machine Manager is a desktop user interface for managing virtual machines through libvirt. It primarily targets KVM VMs, but also manages Xen and LXC (linux containers). Guest additions \u2691 To enable features such as shared clipboard, drag and drop, etc. between the host and the guest using [[virt-manager]] you need to: Install spice-guest-tools in the [[Windows]] guest or spice-vdagent for a [[GNU/Linux]] one. In virt-manager: Add Hardware -> Channel, set name to \"com.redhat.spice.0\" (or similar), set device type as \"Spice agent (spicevmc)\". Reference: vnc - virt-manager copy paste functionality to the vm - Unix & Linux Stack Exchange .", "title": "virt-manager"}, {"location": "computer_science/gnu_linux/virt-manager/#guest-additions", "text": "To enable features such as shared clipboard, drag and drop, etc. between the host and the guest using [[virt-manager]] you need to: Install spice-guest-tools in the [[Windows]] guest or spice-vdagent for a [[GNU/Linux]] one. In virt-manager: Add Hardware -> Channel, set name to \"com.redhat.spice.0\" (or similar), set device type as \"Spice agent (spicevmc)\". Reference: vnc - virt-manager copy paste functionality to the vm - Unix & Linux Stack Exchange .", "title": "Guest additions"}, {"location": "computer_science/gnu_linux/virtualenvwrapper/", "text": "virtualenvwrapper \u2691 Usage \u2691 Create a virtualenv \u2691 mkvirtualenv --python ` which python2 ` [ name ] Switch between virtualenvs \u2691 workon [name] Install \u2691 export WORKON_HOME = ~/Envs mkdir -p $WORKON_HOME source /usr/local/bin/virtualenvwrapper.sh virtualenvwrapper-doc Config \u2691 Setup enviroment variables in a virtualenv \u2691 Edit $VIRTUAL_ENV/bin/postactivate and there add: export VAR = value stackoverflow", "title": "virtualenvwrapper"}, {"location": "computer_science/gnu_linux/virtualenvwrapper/#virtualenvwrapper", "text": "", "title": "virtualenvwrapper"}, {"location": "computer_science/gnu_linux/virtualenvwrapper/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/virtualenvwrapper/#create-a-virtualenv", "text": "mkvirtualenv --python ` which python2 ` [ name ]", "title": "Create a virtualenv"}, {"location": "computer_science/gnu_linux/virtualenvwrapper/#switch-between-virtualenvs", "text": "workon [name]", "title": "Switch between virtualenvs"}, {"location": "computer_science/gnu_linux/virtualenvwrapper/#install", "text": "export WORKON_HOME = ~/Envs mkdir -p $WORKON_HOME source /usr/local/bin/virtualenvwrapper.sh virtualenvwrapper-doc", "title": "Install"}, {"location": "computer_science/gnu_linux/virtualenvwrapper/#config", "text": "", "title": "Config"}, {"location": "computer_science/gnu_linux/virtualenvwrapper/#setup-enviroment-variables-in-a-virtualenv", "text": "Edit $VIRTUAL_ENV/bin/postactivate and there add: export VAR = value stackoverflow", "title": "Setup enviroment variables in a virtualenv"}, {"location": "computer_science/gnu_linux/wallabag/", "text": "Installation \u2691 NGINX reverse proxy \u2691 Block all feeds except starred \u2691 If you want to share your Wallabag starred RSS feed but keep the others ( all , read ...) private, add: location ~ /feed/ { user}/{token}/(?!starred) { deny all ; return 403 ; }", "title": "Wallabag"}, {"location": "computer_science/gnu_linux/wallabag/#installation", "text": "", "title": "Installation"}, {"location": "computer_science/gnu_linux/wallabag/#nginx-reverse-proxy", "text": "", "title": "NGINX reverse proxy"}, {"location": "computer_science/gnu_linux/wallabag/#block-all-feeds-except-starred", "text": "If you want to share your Wallabag starred RSS feed but keep the others ( all , read ...) private, add: location ~ /feed/ { user}/{token}/(?!starred) { deny all ; return 403 ; }", "title": "Block all feeds except starred"}, {"location": "computer_science/gnu_linux/weechat/", "text": "weechat \u2691 Usage \u2691 IRC \u2691 Set autojoin chat rooms \u2691 /set irc.server.freenode.autojoin \"#channel1,#channel2\" Reference \u2691 weechat-doc", "title": "WeeChat"}, {"location": "computer_science/gnu_linux/weechat/#weechat", "text": "", "title": "weechat"}, {"location": "computer_science/gnu_linux/weechat/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/weechat/#irc", "text": "", "title": "IRC"}, {"location": "computer_science/gnu_linux/weechat/#set-autojoin-chat-rooms", "text": "/set irc.server.freenode.autojoin \"#channel1,#channel2\"", "title": "Set autojoin chat rooms"}, {"location": "computer_science/gnu_linux/weechat/#reference", "text": "weechat-doc", "title": "Reference"}, {"location": "computer_science/gnu_linux/wget/", "text": "Usage \u2691 Redirect output to stdout \u2691 wget -qO- [ url ] Download only if newer version is available \u2691 wget -N [url] This will replace the old file when a newer version is found. askubuntu", "title": "wget"}, {"location": "computer_science/gnu_linux/wget/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/wget/#redirect-output-to-stdout", "text": "wget -qO- [ url ]", "title": "Redirect output to stdout"}, {"location": "computer_science/gnu_linux/wget/#download-only-if-newer-version-is-available", "text": "wget -N [url] This will replace the old file when a newer version is found. askubuntu", "title": "Download only if newer version is available"}, {"location": "computer_science/gnu_linux/woeusb/", "text": "WoeUSB/WoeUSB is a Microsoft Windows\u00ae USB installation media preparer for GNU+Linux. Unlike other operating systems, winbugs ISOs can't be directly flashed, so a special process has to be done for creating a bootable winbugs USB. This tool will create a bootable winbugs installer USB. If you want to create a Window To Go portable USB instead, check WinToUsb . Usage \u2691 Download the latest WoeUSB bash script from the releases page. Download a winbugs ISO from here . Execute sudo { path to woeusb.bash } -v --target-filesystem NTFS --device { path to ISO } { path to USB device } Don't add the USB partition number to the device. For example use /dev/sdb/ instead of /dev/sdb1 . The you'll be ready to go. Fuck winbugs.", "title": "WoeUSB"}, {"location": "computer_science/gnu_linux/woeusb/#usage", "text": "Download the latest WoeUSB bash script from the releases page. Download a winbugs ISO from here . Execute sudo { path to woeusb.bash } -v --target-filesystem NTFS --device { path to ISO } { path to USB device } Don't add the USB partition number to the device. For example use /dev/sdb/ instead of /dev/sdb1 . The you'll be ready to go. Fuck winbugs.", "title": "Usage"}, {"location": "computer_science/gnu_linux/x-utilities/", "text": "Graphic (X) utilities \u2691 Image viewers \u2691 mirage: very complete. feh: simple. pinta: it's also an editor. ubuntuforums", "title": "X-utilities"}, {"location": "computer_science/gnu_linux/x-utilities/#graphic-x-utilities", "text": "", "title": "Graphic (X) utilities"}, {"location": "computer_science/gnu_linux/x-utilities/#image-viewers", "text": "mirage: very complete. feh: simple. pinta: it's also an editor. ubuntuforums", "title": "Image viewers"}, {"location": "computer_science/gnu_linux/xclip/", "text": "Usage \u2691 Copy pipe input to clipboard \u2691 somecommand | xclip -selection clipboard Save an image from the clipboard \u2691 If you have copied an image to the clipboard and you want to save it as a file, use: xclip -selection clipboard -target image/png -out > out.png stackoverflow", "title": "xclip"}, {"location": "computer_science/gnu_linux/xclip/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/xclip/#copy-pipe-input-to-clipboard", "text": "somecommand | xclip -selection clipboard", "title": "Copy pipe input to clipboard"}, {"location": "computer_science/gnu_linux/xclip/#save-an-image-from-the-clipboard", "text": "If you have copied an image to the clipboard and you want to save it as a file, use: xclip -selection clipboard -target image/png -out > out.png stackoverflow", "title": "Save an image from the clipboard"}, {"location": "computer_science/gnu_linux/yaml/", "text": "YAML \u2691 Syntax \u2691 Multiline variables \u2691 Folding block (joins multiple lines together by spaces): key : > hello world! Literal block (really multiline): key : | thing1 thing2 anotherthing stackoverflow", "title": "YAML"}, {"location": "computer_science/gnu_linux/yaml/#yaml", "text": "", "title": "YAML"}, {"location": "computer_science/gnu_linux/yaml/#syntax", "text": "", "title": "Syntax"}, {"location": "computer_science/gnu_linux/yaml/#multiline-variables", "text": "Folding block (joins multiple lines together by spaces): key : > hello world! Literal block (really multiline): key : | thing1 thing2 anotherthing stackoverflow", "title": "Multiline variables"}, {"location": "computer_science/gnu_linux/youtube-dl/", "text": "Download methods \u2691 Dowload only the audio \u2691 youtube-dl --extract-audio [url] Download audio and video in custom qualities and merge to mp4 \u2691 youtube-dl -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4' [url] Download subtitles \u2691 To download a video along with its English subtitles in srt format, use youtube-dl --sub-lang en --convert-subs srt --write-sub { URL } The subtitles will be written to a separate file. Tips \u2691 Ignore errors (missing videos) \u2691 --ignore-errors or -i Parallel downloads \u2691 youtube-dl --get-id { playlist_url } | xargs -I '{}' -P 5 youtube-dl 'https://youtube.com/watch?v={}' The first command ( --get-id ) gets a list of video IDs in the playlist, one per line. Those IDs get piped to xargs , which calls individual instances of youtube-dl to download each video. Because we're passing -P 5 to xargs , it runs up to 5 parallel instances of youtube-dl at a time. Reference: alexwlchan", "title": "youtube-dl"}, {"location": "computer_science/gnu_linux/youtube-dl/#download-methods", "text": "", "title": "Download methods"}, {"location": "computer_science/gnu_linux/youtube-dl/#dowload-only-the-audio", "text": "youtube-dl --extract-audio [url]", "title": "Dowload only the audio"}, {"location": "computer_science/gnu_linux/youtube-dl/#download-audio-and-video-in-custom-qualities-and-merge-to-mp4", "text": "youtube-dl -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4' [url]", "title": "Download audio and video in custom qualities and merge to mp4"}, {"location": "computer_science/gnu_linux/youtube-dl/#download-subtitles", "text": "To download a video along with its English subtitles in srt format, use youtube-dl --sub-lang en --convert-subs srt --write-sub { URL } The subtitles will be written to a separate file.", "title": "Download subtitles"}, {"location": "computer_science/gnu_linux/youtube-dl/#tips", "text": "", "title": "Tips"}, {"location": "computer_science/gnu_linux/youtube-dl/#ignore-errors-missing-videos", "text": "--ignore-errors or -i", "title": "Ignore errors (missing videos)"}, {"location": "computer_science/gnu_linux/youtube-dl/#parallel-downloads", "text": "youtube-dl --get-id { playlist_url } | xargs -I '{}' -P 5 youtube-dl 'https://youtube.com/watch?v={}' The first command ( --get-id ) gets a list of video IDs in the playlist, one per line. Those IDs get piped to xargs , which calls individual instances of youtube-dl to download each video. Because we're passing -P 5 to xargs , it runs up to 5 parallel instances of youtube-dl at a time. Reference: alexwlchan", "title": "Parallel downloads"}, {"location": "computer_science/gnu_linux/zip/", "text": "ZIP \u2691 Usage \u2691 Compress file(s) \u2691 To compress one or more files into a zip archive: zip [archive name].zip [file1] [file2] [...] stackexchange Compress a directory \u2691 zip -r [archive name].zip [dir] stackexchange", "title": "zip"}, {"location": "computer_science/gnu_linux/zip/#zip", "text": "", "title": "ZIP"}, {"location": "computer_science/gnu_linux/zip/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/gnu_linux/zip/#compress-files", "text": "To compress one or more files into a zip archive: zip [archive name].zip [file1] [file2] [...] stackexchange", "title": "Compress file(s)"}, {"location": "computer_science/gnu_linux/zip/#compress-a-directory", "text": "zip -r [archive name].zip [dir] stackexchange", "title": "Compress a directory"}, {"location": "computer_science/hardware/asus_prime_b450_plus/", "text": "BIOS update \u2691 Download the latest stable BIOS version from PRIME B450-PLUS\uff5cMotherboards\uff5cASUS USA Uncompress the zip file. Format an USB drive in FAT format. Copy the uncompressed files to the root directory of the FAT partition. Plug the USB drive to the motherboard and boot pressing the F2 key. Press F7 for advanced options and go to Tools > EZ Flash utility . Select the BIOS file and click Enter . The process will take around 5 minutes to complete and the motherboard will reboot automatically after it.", "title": "Asus Prime B450 Plus motherboard"}, {"location": "computer_science/hardware/asus_prime_b450_plus/#bios-update", "text": "Download the latest stable BIOS version from PRIME B450-PLUS\uff5cMotherboards\uff5cASUS USA Uncompress the zip file. Format an USB drive in FAT format. Copy the uncompressed files to the root directory of the FAT partition. Plug the USB drive to the motherboard and boot pressing the F2 key. Press F7 for advanced options and go to Tools > EZ Flash utility . Select the BIOS file and click Enter . The process will take around 5 minutes to complete and the motherboard will reboot automatically after it.", "title": "BIOS update"}, {"location": "computer_science/hardware/remarkable/", "text": "reMarkable is an E-Ink writing tablet for reading documents and textbooks, sketching and note-taking with the goal of a paper-like writing experience. It runs GNU/Linux B-) Software \u2691 reStream \u2691 Stream your reMarkable screen over SSH. Installation \u2691 Follow the instructions from the repo Usage \u2691 Plug-in the reMarkable to your computer and from the computer run restream . Options \u2691 -p : portrait mode. -s {ssh_destination} : arbitrary SSH destination instead of the default ( root@10.11.99.1 ). Useful for connecting over wifi (no need to plug it in).", "title": "reMarkable"}, {"location": "computer_science/hardware/remarkable/#software", "text": "", "title": "Software"}, {"location": "computer_science/hardware/remarkable/#restream", "text": "Stream your reMarkable screen over SSH.", "title": "reStream"}, {"location": "computer_science/hardware/remarkable/#installation", "text": "Follow the instructions from the repo", "title": "Installation"}, {"location": "computer_science/hardware/remarkable/#usage", "text": "Plug-in the reMarkable to your computer and from the computer run restream .", "title": "Usage"}, {"location": "computer_science/hardware/remarkable/#options", "text": "-p : portrait mode. -s {ssh_destination} : arbitrary SSH destination instead of the default ( root@10.11.99.1 ). Useful for connecting over wifi (no need to plug it in).", "title": "Options"}, {"location": "computer_science/hardware/t14_amd_gen1/", "text": "Usage \u2691 BIOS upgrade \u2691 There are several ways of upgrading the BIOS of this laptop. One of them is using fwupdate , other is running an executable from winbugs and the last one is from a bootable USB. Keep in mind that the upgrades might require the laptop to be plugged to a power supply and/or have a level of charge over 50%, 80%... Bootable USB \u2691 First, create the bootable USB: Download the BIOS update (Bootable CD) from lenovo . Check the integrity of the downloaded file with sha256sum {downloaded_file} Extract the bootable image: geteltorito -o t14.img { downloaded_file } Flash the extracted image to an usb: dd if = t14.img of = /dev/sdX Reboot, interrupt the boot (press enter), press F12 and select the USB as the boot device. Follow the on-screen instructions. Issues \u2691 Flashing colors on the LCD screen \u2691 TL;DR: power off the laptop and unplug it from the AC adapter and press the emergency-reset button located in the bottom case. I opened my laptop, which was suspended, and the screen was flashing in different colors as shown on this video I panicked a bit and look the problem up, finding only this thread where they suggested reinstalling the BIOS by using an external screen. I've tried to do so by connecting the laptop to the ThinkPad USB-C Dock Gen 2 but the screens showed no output. Before trying anything else, I decided to go for the ol' reliable \"have you tried turning it off and on again\". So I opened the bottom case, which is a bit annoying but easily doable, as shown on the following video Then, I unplugged the battery and the BIOS button battery and replugged them again. I checked that it worked properly before putting back the bottom case. But then, I've learned that Thinkpads with a non-removable battery generally have a \"emergency-reset hole\", which I could have just pressed instead of opening the laptop xD There is more information about it in the T14 Gen 1 and P14s Gen 1 Hardware Maintenance Manual .", "title": "Thinkpad T14 (AMD) Gen1"}, {"location": "computer_science/hardware/t14_amd_gen1/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/hardware/t14_amd_gen1/#bios-upgrade", "text": "There are several ways of upgrading the BIOS of this laptop. One of them is using fwupdate , other is running an executable from winbugs and the last one is from a bootable USB. Keep in mind that the upgrades might require the laptop to be plugged to a power supply and/or have a level of charge over 50%, 80%...", "title": "BIOS upgrade"}, {"location": "computer_science/hardware/t14_amd_gen1/#bootable-usb", "text": "First, create the bootable USB: Download the BIOS update (Bootable CD) from lenovo . Check the integrity of the downloaded file with sha256sum {downloaded_file} Extract the bootable image: geteltorito -o t14.img { downloaded_file } Flash the extracted image to an usb: dd if = t14.img of = /dev/sdX Reboot, interrupt the boot (press enter), press F12 and select the USB as the boot device. Follow the on-screen instructions.", "title": "Bootable USB"}, {"location": "computer_science/hardware/t14_amd_gen1/#issues", "text": "", "title": "Issues"}, {"location": "computer_science/hardware/t14_amd_gen1/#flashing-colors-on-the-lcd-screen", "text": "TL;DR: power off the laptop and unplug it from the AC adapter and press the emergency-reset button located in the bottom case. I opened my laptop, which was suspended, and the screen was flashing in different colors as shown on this video I panicked a bit and look the problem up, finding only this thread where they suggested reinstalling the BIOS by using an external screen. I've tried to do so by connecting the laptop to the ThinkPad USB-C Dock Gen 2 but the screens showed no output. Before trying anything else, I decided to go for the ol' reliable \"have you tried turning it off and on again\". So I opened the bottom case, which is a bit annoying but easily doable, as shown on the following video Then, I unplugged the battery and the BIOS button battery and replugged them again. I checked that it worked properly before putting back the bottom case. But then, I've learned that Thinkpads with a non-removable battery generally have a \"emergency-reset hole\", which I could have just pressed instead of opening the laptop xD There is more information about it in the T14 Gen 1 and P14s Gen 1 Hardware Maintenance Manual .", "title": "Flashing colors on the LCD screen"}, {"location": "computer_science/programming/jinja/", "text": "Filters \u2691 Variables can be modified by filters. Filters are separated from the variable by a pipe symbol ( | ) and may have optional arguments in parentheses. Multiple filters can be chained. The output of one filter is applied to the next. Built-in filters \u2691 These are some of built-in filters : lower : convert a value to lowercase.", "title": "Jinja"}, {"location": "computer_science/programming/jinja/#filters", "text": "Variables can be modified by filters. Filters are separated from the variable by a pipe symbol ( | ) and may have optional arguments in parentheses. Multiple filters can be chained. The output of one filter is applied to the next.", "title": "Filters"}, {"location": "computer_science/programming/jinja/#built-in-filters", "text": "These are some of built-in filters : lower : convert a value to lowercase.", "title": "Built-in filters"}, {"location": "computer_science/programming/tdd/", "text": "Test-driven development (TDD) is a software development process consisting in small development cycles. The goal is clean code that works. Some advantages of this methodology are that it reduces stress in the development process and produces functional code that is a pleasure to work with. Motivation \u2691 Are you scared about modifying your code? Do you feel like you need a full empty day to add some new functionality to not be interrupted in the process? Didn't it happen to you that you started refactoring a simple part of code and ended up lost and confused with changes in tens of different files and the code not working anymore? This is what happens to the Refactoring Cat: If you want to avoid this, stick to small steps, keep refactoring and functionality changes entirely separate. Be like the Testing Goat, obey the testing goat: The Testing Goat might be less smart than the Refactoring Cat, but it can reach higher peeks just by going step by step. Programming is hard, TDD helps keeping it simple so that you don't have to make extra thinking efforts all the time. It let's you save your progress, take a break, and make sure you never slip backwards. Getting started \u2691 TDD is a discipline. To get started, try doing a kata every day: Kata - The only way to learn TDD - Peter Provost's Geek Noise . Development cycle \u2691 Write a test. Run the tests and check that the new test fails. Make the minimum code change to address the current test failure. Run the tests and check that all pass. Refactor the code (improve clarity, performance\u2026). Use the tests to help you validate the changes. One of this cycles might have subcycles. For example, if you want to add a new high level function for which you write an end-to-end (E2E) test, start writing a test for that function and use small cycles of TDD for the helper functions or dependencies in lower level layers that the new function requires. Go outside-in (from higher level to lower level) instead of inside-out to: Avoid developing unnecessary code. Since at first it's hard to guess what the higher level function will need and you might be tempted to cover more cases than the actually required ones. Develop components that are convenient for the upper layer that will use them intead of being suited for their lower level dependencies. You will be able to imagine the most convenient API you could want from the underneath layer. Exploratory coding (spiking) \u2691 When learning a new tool or exploring a new possible solution, it\u2019s often appropriate to leave the rigorous TDD process to one side, and build a little prototype without tests, or perhaps with very few tests. The goat doesn't mind looking the other way for a bit. For de-spiking, rewrite your prototype code using TDD. Tests \u2691 Try to keep tests as simple as possible: * Each test should test one feature. * Avoid a lot of setup, specially mocks. If you need to mock often, check the architecture design of your code and revisit the S.O.L.I.D. principles. For dependencies from other layers try to keep them together in one place, maybe with a fixture or a helper function, so that they will be easier to change in the future if needed. For example, if you need to import the class Circle from another layer during the tests, define a function to instantiate Circle instead of calling it directly from the tests, so that if the functions signature changes, you'll only have to modify the tests in one place. Types of tests \u2691 Unit tests: Use them to test functionality units in your code. Don't test dependencies or Python itself (setting constants, basic operators\u2026). You don't need to unit test every line of the code, this will make refactoring tedious. Instead, test the parts of your code that you really care about, not the implementation particularities (you don't have to test helper functions for example). Integration tests. Check the compatibility between modules or layers at the boundaries. E2E tests: Test the system from the beginning to end to ensure that the functionality that the user wants works as expected. Make as few tests of this type as possible, since they are the slowest and will give you the less information about where the test originated. References \u2691 \u201cTest-Driven Development with Python\u201d by Harry Percival \u201cFast Test, Slow Test\u201d by Gary Bernhardt", "title": "TDD"}, {"location": "computer_science/programming/tdd/#motivation", "text": "Are you scared about modifying your code? Do you feel like you need a full empty day to add some new functionality to not be interrupted in the process? Didn't it happen to you that you started refactoring a simple part of code and ended up lost and confused with changes in tens of different files and the code not working anymore? This is what happens to the Refactoring Cat: If you want to avoid this, stick to small steps, keep refactoring and functionality changes entirely separate. Be like the Testing Goat, obey the testing goat: The Testing Goat might be less smart than the Refactoring Cat, but it can reach higher peeks just by going step by step. Programming is hard, TDD helps keeping it simple so that you don't have to make extra thinking efforts all the time. It let's you save your progress, take a break, and make sure you never slip backwards.", "title": "Motivation"}, {"location": "computer_science/programming/tdd/#getting-started", "text": "TDD is a discipline. To get started, try doing a kata every day: Kata - The only way to learn TDD - Peter Provost's Geek Noise .", "title": "Getting started"}, {"location": "computer_science/programming/tdd/#development-cycle", "text": "Write a test. Run the tests and check that the new test fails. Make the minimum code change to address the current test failure. Run the tests and check that all pass. Refactor the code (improve clarity, performance\u2026). Use the tests to help you validate the changes. One of this cycles might have subcycles. For example, if you want to add a new high level function for which you write an end-to-end (E2E) test, start writing a test for that function and use small cycles of TDD for the helper functions or dependencies in lower level layers that the new function requires. Go outside-in (from higher level to lower level) instead of inside-out to: Avoid developing unnecessary code. Since at first it's hard to guess what the higher level function will need and you might be tempted to cover more cases than the actually required ones. Develop components that are convenient for the upper layer that will use them intead of being suited for their lower level dependencies. You will be able to imagine the most convenient API you could want from the underneath layer.", "title": "Development cycle"}, {"location": "computer_science/programming/tdd/#exploratory-coding-spiking", "text": "When learning a new tool or exploring a new possible solution, it\u2019s often appropriate to leave the rigorous TDD process to one side, and build a little prototype without tests, or perhaps with very few tests. The goat doesn't mind looking the other way for a bit. For de-spiking, rewrite your prototype code using TDD.", "title": "Exploratory coding (spiking)"}, {"location": "computer_science/programming/tdd/#tests", "text": "Try to keep tests as simple as possible: * Each test should test one feature. * Avoid a lot of setup, specially mocks. If you need to mock often, check the architecture design of your code and revisit the S.O.L.I.D. principles. For dependencies from other layers try to keep them together in one place, maybe with a fixture or a helper function, so that they will be easier to change in the future if needed. For example, if you need to import the class Circle from another layer during the tests, define a function to instantiate Circle instead of calling it directly from the tests, so that if the functions signature changes, you'll only have to modify the tests in one place.", "title": "Tests"}, {"location": "computer_science/programming/tdd/#types-of-tests", "text": "Unit tests: Use them to test functionality units in your code. Don't test dependencies or Python itself (setting constants, basic operators\u2026). You don't need to unit test every line of the code, this will make refactoring tedious. Instead, test the parts of your code that you really care about, not the implementation particularities (you don't have to test helper functions for example). Integration tests. Check the compatibility between modules or layers at the boundaries. E2E tests: Test the system from the beginning to end to ensure that the functionality that the user wants works as expected. Make as few tests of this type as possible, since they are the slowest and will give you the less information about where the test originated.", "title": "Types of tests"}, {"location": "computer_science/programming/tdd/#references", "text": "\u201cTest-Driven Development with Python\u201d by Harry Percival \u201cFast Test, Slow Test\u201d by Gary Bernhardt", "title": "References"}, {"location": "computer_science/programming/code_style/git_commits/", "text": "Commit Message Guidelines \u2691 Angular commit convention can be a good reference. Commit Message Format \u2691 Each commit message consists of a header , a body and a footer . The header has a special format that includes a type , a scope and a subject : <type>(<scope>): <subject> <BLANK LINE> <body> <BLANK LINE> <footer> The header is mandatory and the scope of the header is optional. Any line of the commit message cannot be longer 100 characters! This allows the message to be easier to read on GitHub as well as in various git tools. The footer should contain a closing reference to an issue if any. Samples: (even more samples ) docs(changelog): update changelog to beta.5 fix(release): need to depend on latest rxjs and zone.js The version in our package.json gets copied to the one we publish, and users need the latest of these. Revert \u2691 If the commit reverts a previous commit, it should begin with revert: , followed by the header of the reverted commit. In the body it should say: This reverts commit <hash>. , where the hash is the SHA of the commit being reverted. Type \u2691 Must be one of the following: build : Changes that affect the build system or external dependencies (example scopes: gulp, broccoli, npm) ci : Changes to our CI configuration files and scripts (example scopes: Travis, Circle, BrowserStack, SauceLabs) docs : Documentation only changes feat : A new feature fix : A bug fix perf : A code change that improves performance refactor : A code change that neither fixes a bug nor adds a feature style : Changes that do not affect the meaning of the code (white-space, formatting, missing semi-colons, etc) test : Adding missing tests or correcting existing tests Scope \u2691 The scope should be the name of the file or package changed. Subject \u2691 The subject contains a succinct description of the change: use the imperative, present tense: \"change\" not \"changed\" nor \"changes\" don't capitalize the first letter no dot (.) at the end Body \u2691 Just as in the subject , use the imperative, present tense: \"change\" not \"changed\" nor \"changes\". The body should include the motivation for the change and contrast this with previous behavior. Footer \u2691 The footer should contain any information about Breaking Changes and is also the place to reference GitHub issues that this commit Closes . Breaking Changes should start with the word BREAKING CHANGE: with a space or two newlines. The rest of the commit message is then used for this.", "title": "Git commits"}, {"location": "computer_science/programming/code_style/git_commits/#commit-message-guidelines", "text": "Angular commit convention can be a good reference.", "title": "Commit Message Guidelines"}, {"location": "computer_science/programming/code_style/git_commits/#commit-message-format", "text": "Each commit message consists of a header , a body and a footer . The header has a special format that includes a type , a scope and a subject : <type>(<scope>): <subject> <BLANK LINE> <body> <BLANK LINE> <footer> The header is mandatory and the scope of the header is optional. Any line of the commit message cannot be longer 100 characters! This allows the message to be easier to read on GitHub as well as in various git tools. The footer should contain a closing reference to an issue if any. Samples: (even more samples ) docs(changelog): update changelog to beta.5 fix(release): need to depend on latest rxjs and zone.js The version in our package.json gets copied to the one we publish, and users need the latest of these.", "title": "Commit Message Format"}, {"location": "computer_science/programming/code_style/git_commits/#revert", "text": "If the commit reverts a previous commit, it should begin with revert: , followed by the header of the reverted commit. In the body it should say: This reverts commit <hash>. , where the hash is the SHA of the commit being reverted.", "title": "Revert"}, {"location": "computer_science/programming/code_style/git_commits/#type", "text": "Must be one of the following: build : Changes that affect the build system or external dependencies (example scopes: gulp, broccoli, npm) ci : Changes to our CI configuration files and scripts (example scopes: Travis, Circle, BrowserStack, SauceLabs) docs : Documentation only changes feat : A new feature fix : A bug fix perf : A code change that improves performance refactor : A code change that neither fixes a bug nor adds a feature style : Changes that do not affect the meaning of the code (white-space, formatting, missing semi-colons, etc) test : Adding missing tests or correcting existing tests", "title": "Type"}, {"location": "computer_science/programming/code_style/git_commits/#scope", "text": "The scope should be the name of the file or package changed.", "title": "Scope"}, {"location": "computer_science/programming/code_style/git_commits/#subject", "text": "The subject contains a succinct description of the change: use the imperative, present tense: \"change\" not \"changed\" nor \"changes\" don't capitalize the first letter no dot (.) at the end", "title": "Subject"}, {"location": "computer_science/programming/code_style/git_commits/#body", "text": "Just as in the subject , use the imperative, present tense: \"change\" not \"changed\" nor \"changes\". The body should include the motivation for the change and contrast this with previous behavior.", "title": "Body"}, {"location": "computer_science/programming/code_style/git_commits/#footer", "text": "The footer should contain any information about Breaking Changes and is also the place to reference GitHub issues that this commit Closes . Breaking Changes should start with the word BREAKING CHANGE: with a space or two newlines. The rest of the commit message is then used for this.", "title": "Footer"}, {"location": "computer_science/programming/flutter/basics/", "text": "Usage \u2691 Commands \u2691 flutter --version : See Flutter and Dart version. Operators \u2691 .? \u2691 Use ?. when you want to call a method/getter on an object if that object is not null (otherwise, return null). Example: currentState ? . open (); ?? (if null) \u2691 Get a default value if object is null: var value ; ... value = value ?? 2 ; Built-in data types \u2691 Enum \u2691 enum Day { monday , tuesday } Get the value of an enum element \u2691 Day . monday . name List \u2691 Find first element that satisfies condition \u2691 Use .firstWhere() : List < Currency > currencies = ...; Currency dollar = currencies . firstWhere (( currency ) => currency . code == \"USD\" ); Map \u2691 Map < String , int > myMap = { \"apple\" : 3 , \"orange\" : 5 , }; Iterate through map entries (keys and values) \u2691 List < String > myList = myMap . entries . map ( ( var entry ) => \" ${ entry . key } : ${ entry . value } \" ). toList (); Combine/merge/concat maps \u2691 You can use spread operator ... : final firstMap = { \"1\" : \"2\" }; final secondMap = { \"2\" : \"3\" }; final thirdMap = { ... firstMap , ... secondMap , }; Writing documentation \u2691 Add comments with // or /// , the later will make the comments be included by dartdoc . Rules: DO format comments like sentences (capitalization and punctuation). DON\u2019T use block comments for documentation. DO use /// doc comments to document members and types in the preceding line. DO start doc comments with a single-sentence summary and continue after an empty comment line if necessary. Generate the docs \u2691 Run flutter pub global run dartdoc:dartdoc", "title": "Basics"}, {"location": "computer_science/programming/flutter/basics/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/programming/flutter/basics/#commands", "text": "flutter --version : See Flutter and Dart version.", "title": "Commands"}, {"location": "computer_science/programming/flutter/basics/#operators", "text": "", "title": "Operators"}, {"location": "computer_science/programming/flutter/basics/#_1", "text": "Use ?. when you want to call a method/getter on an object if that object is not null (otherwise, return null). Example: currentState ? . open ();", "title": ".?"}, {"location": "computer_science/programming/flutter/basics/#if-null", "text": "Get a default value if object is null: var value ; ... value = value ?? 2 ;", "title": "?? (if null)"}, {"location": "computer_science/programming/flutter/basics/#built-in-data-types", "text": "", "title": "Built-in data types"}, {"location": "computer_science/programming/flutter/basics/#enum", "text": "enum Day { monday , tuesday }", "title": "Enum"}, {"location": "computer_science/programming/flutter/basics/#get-the-value-of-an-enum-element", "text": "Day . monday . name", "title": "Get the value of an enum element"}, {"location": "computer_science/programming/flutter/basics/#list", "text": "", "title": "List"}, {"location": "computer_science/programming/flutter/basics/#find-first-element-that-satisfies-condition", "text": "Use .firstWhere() : List < Currency > currencies = ...; Currency dollar = currencies . firstWhere (( currency ) => currency . code == \"USD\" );", "title": "Find first element that satisfies condition"}, {"location": "computer_science/programming/flutter/basics/#map", "text": "Map < String , int > myMap = { \"apple\" : 3 , \"orange\" : 5 , };", "title": "Map"}, {"location": "computer_science/programming/flutter/basics/#iterate-through-map-entries-keys-and-values", "text": "List < String > myList = myMap . entries . map ( ( var entry ) => \" ${ entry . key } : ${ entry . value } \" ). toList ();", "title": "Iterate through map entries (keys and values)"}, {"location": "computer_science/programming/flutter/basics/#combinemergeconcat-maps", "text": "You can use spread operator ... : final firstMap = { \"1\" : \"2\" }; final secondMap = { \"2\" : \"3\" }; final thirdMap = { ... firstMap , ... secondMap , };", "title": "Combine/merge/concat maps"}, {"location": "computer_science/programming/flutter/basics/#writing-documentation", "text": "Add comments with // or /// , the later will make the comments be included by dartdoc . Rules: DO format comments like sentences (capitalization and punctuation). DON\u2019T use block comments for documentation. DO use /// doc comments to document members and types in the preceding line. DO start doc comments with a single-sentence summary and continue after an empty comment line if necessary.", "title": "Writing documentation"}, {"location": "computer_science/programming/flutter/basics/#generate-the-docs", "text": "Run flutter pub global run dartdoc:dartdoc", "title": "Generate the docs"}, {"location": "computer_science/programming/flutter/debugging/", "text": "Import dart:developer and add debugger(); wherever you want. Then, open your browsers developer tools and use the console.", "title": "Debugging"}, {"location": "computer_science/programming/flutter/material/", "text": "Classes \u2691 Color \u2691 Parse hexadecimal color string to Color \u2691 /// Construct a color from a hex code string, of the format #RRGGBB. Color hexToColor ( String code ) { return new Color ( int . parse ( code . substring ( 1 , 7 ), radix: 16 ) + 0xFF000000 ); } InkWell \u2691 Make a component clickable (with animations on hover and tap): InkWell ( onTap: () { // To do }, child: Card (), )", "title": "Material"}, {"location": "computer_science/programming/flutter/material/#classes", "text": "", "title": "Classes"}, {"location": "computer_science/programming/flutter/material/#color", "text": "", "title": "Color"}, {"location": "computer_science/programming/flutter/material/#parse-hexadecimal-color-string-to-color", "text": "/// Construct a color from a hex code string, of the format #RRGGBB. Color hexToColor ( String code ) { return new Color ( int . parse ( code . substring ( 1 , 7 ), radix: 16 ) + 0xFF000000 ); }", "title": "Parse hexadecimal color string to Color"}, {"location": "computer_science/programming/flutter/material/#inkwell", "text": "Make a component clickable (with animations on hover and tap): InkWell ( onTap: () { // To do }, child: Card (), )", "title": "InkWell"}, {"location": "computer_science/programming/flutter/provider/", "text": "A relatively simple and efficient tool for state management in Flutter is provider . Usage \u2691 ChangeNotifierProxyProvider \u2691 When an provider needs information from another, use ChangeNotifierProxyProvider . class MyModel with ChangeNotifier { ... } } class MyChangeNotifier with ChangeNotifier { void update ( MyModel myModel ) { // Do some custom work based on myModel that may call `notifyListeners` } } ChangeNotifierProxyProvider < MyModel , MyChangeNotifier > ( create: ( _ ) => MyChangeNotifier (), update: ( _ , myModel , myNotifier ) => myNotifier .. update ( myModel ), child: ... ); Pass the provider dependency as the first argument, which must be declared already (e.g., as a ChangeNotifierProvider in a MultiProvider ).", "title": "Provider"}, {"location": "computer_science/programming/flutter/provider/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/programming/flutter/provider/#changenotifierproxyprovider", "text": "When an provider needs information from another, use ChangeNotifierProxyProvider . class MyModel with ChangeNotifier { ... } } class MyChangeNotifier with ChangeNotifier { void update ( MyModel myModel ) { // Do some custom work based on myModel that may call `notifyListeners` } } ChangeNotifierProxyProvider < MyModel , MyChangeNotifier > ( create: ( _ ) => MyChangeNotifier (), update: ( _ , myModel , myNotifier ) => myNotifier .. update ( myModel ), child: ... ); Pass the provider dependency as the first argument, which must be declared already (e.g., as a ChangeNotifierProvider in a MultiProvider ).", "title": "ChangeNotifierProxyProvider"}, {"location": "computer_science/programming/python/asyncio/", "text": "asyncio is a library to write concurrent code using the async / await syntax. Basic example: \"\"\"Asyncio example.\"\"\" import asyncio from typing import Dict async def function ( number : int ) -> str : \"\"\"Sleep 1 second and return the passed number as a string.\"\"\" await asyncio . sleep ( 1 ) return str ( number ) async def main () -> None : \"\"\"Call function 100 times and save the outputs in a dictionary.\"\"\" args = list ( range ( 100 )) results = await asyncio . gather ( * [ function ( n ) for n in args ]) result : Dict [ int , str ] = dict ( zip ( args , results )) print ( result ) asyncio . run ( main ()) This code runs in approximately one second, instead of the expected 100 seconds of its non concurrent version. Tips \u2691 Limit concurrency \u2691 Use asyncio.Semaphore . sem = asyncio . Semaphore ( 10 ) async with sem : # work with shared resource Note that this method is not thread-safe.", "title": "asyncio"}, {"location": "computer_science/programming/python/asyncio/#tips", "text": "", "title": "Tips"}, {"location": "computer_science/programming/python/asyncio/#limit-concurrency", "text": "Use asyncio.Semaphore . sem = asyncio . Semaphore ( 10 ) async with sem : # work with shared resource Note that this method is not thread-safe.", "title": "Limit concurrency"}, {"location": "computer_science/programming/python/asyncpg/", "text": "MagicStack/asyncpg is a fast PostgreSQL Database Client Library for Python/asyncio. Basic usage: import asyncio import asyncpg async def run (): conn = await asyncpg . connect ( user = 'user' , password = 'password' , database = 'database' , host = '127.0.0.1' ) values = await conn . fetch ( 'SELECT * FROM mytable WHERE id = $1' , 10 , ) await conn . close () loop = asyncio . get_event_loop () loop . run_until_complete ( run ())", "title": "asyncpg"}, {"location": "computer_science/programming/python/basics/", "text": "Built-in types \u2691 Classes \u2691 A class is an object from which we can generate instances. A basic definition of one is as follows class Whatever : def __init__ ( self , arg ): self . arg = arg var = 3 def function ( self , n ): ... where arg is an argument that then becomes an attribute of the generated instance, var is another attribute and function is a method of the class. A more extensive definition can be found at python-docs . To get the class attributes of an object, do object.__dict__ . Mapping Types (dict) \u2691 A mapping object maps hashable values to arbitrary objects. Mappings are mutable objects. There is currently only one standard mapping type, the dictionary. setdefault \u2691 setdefault(key[, default]) : If key is in the dictionary, return its value. If not, insert key with a value of default and return default . default defaults to None . Rename a dictionary key \u2691 mydict [ k_new ] = mydict . pop ( k_old ) Ranges \u2691 A range is a Python built-in type that represents an immutable sequence of numbers and is commonly used for looping a specific number of times in for loops. Some examples are for i in range ( end ): print ( i ) for i in range ( start , stop , step ): print ( i ) To reverse the order in the range you can do reversed ( range ( n )) String \u2691 Methods \u2691 str.count(sub[, start[, end]]) : Return the number of non-overlapping occurrences of substring sub in the range [ start , end ]. str.removeprefix(prefix) : If the string starts with the prefix string, return str[len(prefix):] . Otherwise, return a copy of the original string. str.removesuffix(suffix) : If the string ends with the suffix string and that suffix is not empty, return str[:-len(suffix)] . Otherwise, return a copy of the original string. str.strip([chars]) : Return a copy of the string with the leading and trailing characters removed. Built-in functions \u2691 filter \u2691 Use filter(function, iterable) to construct an iterator from those elements of iterable for which function returns true. getattr \u2691 getattr ( object , name [, default ]) Return the value of the named attribute of object . name must be a string. If the string is the name of one of the object's attributes, the result is the value of that attribute. If the named attribute does not exist, default is returned if provided, otherwise AttributeError is raised. isinstance \u2691 To check if an object is an instance of a class use isinstance(object, class) . For example: d = { \"a\" : 4 } isinstance ( d , dict ) issubclass \u2691 issubclass(class, classinfo) : Return True if class is a subclass (direct, indirect or virtual) of classinfo . A class is considered a subclass of itself. classinfo may be a tuple of class objects, in which case every entry in classinfo will be checked. In any other case, a TypeError exception is raised. Sort \u2691 To sort the objects of a list based on an attribute of them you can do list . sort ( key = lambda x : x . attribute , reverse = True ) # Higher first This fragment comes from stackoverflow . Other functions \u2691 Shuffle \u2691 To shuffle the elements order inside a list you can do from random import shuffle x = [ i for i in range ( 10 )] shuffle ( x ) This fragment comes from stackoverflow . Generic Operating System Services \u2691 os \u2691 listdir \u2691 os.listdir(path='.') returns a list containing the names of the entries in the directory given by path . Text processing services \u2691 re \u2691 The re module provides regular expression matching operations similar to those found in Perl. Usage \u2691 Check if string matches a pattern \u2691 The usage is re.match(pattern, string) . Example: import re string = \"whatever\" if re . match ( \"what.*\" , string ): print ( \"yes\" ) Tips \u2691 Try your RegEx at Pythex . time \u2691 The module time provides various time-related functions. Usage \u2691 Measure elapsed time between two points \u2691 To measure elapsed time between two points do: import time start = time . time () print ( \"hello\" ) end = time . time () print ( end - start ) Data types \u2691 datetime \u2691 Methods \u2691 timestamp() : Return POSIX timestamp. now() : Return the current local date and time. enum \u2691 An enumeration is a set of symbolic names (members) bound to unique, constant values. Within an enumeration, the members can be compared by identity, and the enumeration itself can be iterated over. Example: from enum import Enum class Color ( Enum ): RED = 1 GREEN = 2 BLUE = 3 isinstance ( Color . GREEN , Color ) # True color = Color . RED color . name # RED color . value # 1 Enumeration members are hashable, so they can be used in dictionaries and sets. I/O \u2691 Files \u2691 You can operate with files from a filesystem directly from python. A common way of doing so is f = open ( '[file]' , '[mode]' ) Where [file] is the file path and [mode] is one of the following modes: w : For rewritting the file. r : For reading from the file. a : For appending at the end of the file. Then you can use the following methods (depending on the selected mode): f . write ( 'test' ) f . read () ... Nevertheless, it is a good practice to use the with keyword when dealing with file objects, since it will automatically close it after the work is done. It can be used as follows with open ( 'file_path' ) as f : file_data = f . read () Otherwise, f.close() should be called in order to close the file and thus freeing up any system resource used by it. String formatting \u2691 Formatted string literals (f-strings) \u2691 Formatted string literals (also called f-strings for short) let you include the value of Python expressions inside a string by prefixing the string with f or F and writing expressions as {expression} . For example: name = \"robot\" print ( f \"Hello { name } \" ) Scientific notation for numbers \u2691 To print a number using scientific notation with n decimals, do number = 0.000123 print ( \"{:. {n} e}\" . format ( number )) which will return 1.23e-04 with n=2 . Get the name of the weekday \u2691 To get the name of the weekday of a datetime object use .strftime(\"%A\") . For example: >>> from datetime import datetime as date >>> date . today () . strftime ( \"%A\" ) 'Monday' Internet protocols and support \u2691 http.server \u2691 You can create a basic HTTP server that serves the files in the current directory with mkdir /tmp/www echo \"Hello world!\" > /tmp/index.html cd /tmp/www ; python3 -m http.server if you want to leave it running in the background even if you close the console session, do nohup python3 -m http.server & instead. Built-in exceptions \u2691 Most common: TypeError : Raised when an operation or function is applied to an object of inappropriate type. ValueError : Raised when an operation or function receives an argument that has the right type but an inappropriate value. Custom exception \u2691 To provide more insightful error messages related to our code, we can create custom exceptions. For example: class ColorError ( ValueError ): def __init__ ( self , color ): message = f \"Invalid color { color } .\" super () . __init__ ( message ) Functional programming modules \u2691 functools \u2691 The functools module is for higher-order functions: functions that act on or return other functions. Usage \u2691 Change function default argument value \u2691 from functools import partial def f ( num : int = 0 ) -> str : return \"The value of num is: \" + str ( num ) f_p = partial ( f , num = 1 ) f_p () To keep the docstring of the original function, just copy it with: f_p . __doc__ = f . __doc__ Python runtime services \u2691 Abstract Base Classes \u2691 This module provides the infrastructure for defining abstract base classes (ABCs) in Python, as outlined in PEP 3119 . To create an abstract base class, to define and interface and can be inherited but not instantiated, do: from abc import ABC , abstractmethod class Switchable ( ABC ): \"\"\"Switchable interface.\"\"\" is_on : bool = False @abstractmethod def turn_on ( self ): \"\"\"Method to turn on.\"\" @abstractmethod def turn_off(self): \"\"\" Method to turn off . \"\" class LightBulb ( Switchable ): \"\"\"Light bulb class.\"\"\" def turn_on ( self ): self . is_on = True print ( \"Light is on.\" ) def turn_on ( self ): self . is_on = False print ( \"Light is off.\" ) light_bulb_1 = LightBulb () light_bulb_1 . turn_on () This code is an example for an abstract class that doesn't follow the composition over inheritance principle. It would be better to implement separate turn_on and turn_off functions that get a Switchable object as their argument. Note : Use @abstractmethod before classmethod . See Issue 16267 . Development tools \u2691 typing \u2691 Provides runtime support for type hints. Types \u2691 TypedDict \u2691 Special construct to add type hints to a dictionary. At runtime it is a plain dict . Example: class Point2D ( TypedDict ): x : int y : int label : str a : Point2D = { 'x' : 1 , 'y' : 2 , 'label' : 'good' } # OK b : Point2D = { 'z' : 3 , 'label' : 'bad' } # Fails type check By default, all keys must be present in a TypedDict . It is possible to override this by specifying totality. Usage: class point2D ( TypedDict , total = False ): x : int y : int", "title": "Basics"}, {"location": "computer_science/programming/python/basics/#built-in-types", "text": "", "title": "Built-in types"}, {"location": "computer_science/programming/python/basics/#classes", "text": "A class is an object from which we can generate instances. A basic definition of one is as follows class Whatever : def __init__ ( self , arg ): self . arg = arg var = 3 def function ( self , n ): ... where arg is an argument that then becomes an attribute of the generated instance, var is another attribute and function is a method of the class. A more extensive definition can be found at python-docs . To get the class attributes of an object, do object.__dict__ .", "title": "Classes"}, {"location": "computer_science/programming/python/basics/#mapping-types-dict", "text": "A mapping object maps hashable values to arbitrary objects. Mappings are mutable objects. There is currently only one standard mapping type, the dictionary.", "title": "Mapping Types (dict)"}, {"location": "computer_science/programming/python/basics/#setdefault", "text": "setdefault(key[, default]) : If key is in the dictionary, return its value. If not, insert key with a value of default and return default . default defaults to None .", "title": "setdefault"}, {"location": "computer_science/programming/python/basics/#rename-a-dictionary-key", "text": "mydict [ k_new ] = mydict . pop ( k_old )", "title": "Rename a dictionary key"}, {"location": "computer_science/programming/python/basics/#ranges", "text": "A range is a Python built-in type that represents an immutable sequence of numbers and is commonly used for looping a specific number of times in for loops. Some examples are for i in range ( end ): print ( i ) for i in range ( start , stop , step ): print ( i ) To reverse the order in the range you can do reversed ( range ( n ))", "title": "Ranges"}, {"location": "computer_science/programming/python/basics/#string", "text": "", "title": "String"}, {"location": "computer_science/programming/python/basics/#methods", "text": "str.count(sub[, start[, end]]) : Return the number of non-overlapping occurrences of substring sub in the range [ start , end ]. str.removeprefix(prefix) : If the string starts with the prefix string, return str[len(prefix):] . Otherwise, return a copy of the original string. str.removesuffix(suffix) : If the string ends with the suffix string and that suffix is not empty, return str[:-len(suffix)] . Otherwise, return a copy of the original string. str.strip([chars]) : Return a copy of the string with the leading and trailing characters removed.", "title": "Methods"}, {"location": "computer_science/programming/python/basics/#built-in-functions", "text": "", "title": "Built-in functions"}, {"location": "computer_science/programming/python/basics/#filter", "text": "Use filter(function, iterable) to construct an iterator from those elements of iterable for which function returns true.", "title": "filter"}, {"location": "computer_science/programming/python/basics/#getattr", "text": "getattr ( object , name [, default ]) Return the value of the named attribute of object . name must be a string. If the string is the name of one of the object's attributes, the result is the value of that attribute. If the named attribute does not exist, default is returned if provided, otherwise AttributeError is raised.", "title": "getattr"}, {"location": "computer_science/programming/python/basics/#isinstance", "text": "To check if an object is an instance of a class use isinstance(object, class) . For example: d = { \"a\" : 4 } isinstance ( d , dict )", "title": "isinstance"}, {"location": "computer_science/programming/python/basics/#issubclass", "text": "issubclass(class, classinfo) : Return True if class is a subclass (direct, indirect or virtual) of classinfo . A class is considered a subclass of itself. classinfo may be a tuple of class objects, in which case every entry in classinfo will be checked. In any other case, a TypeError exception is raised.", "title": "issubclass"}, {"location": "computer_science/programming/python/basics/#sort", "text": "To sort the objects of a list based on an attribute of them you can do list . sort ( key = lambda x : x . attribute , reverse = True ) # Higher first This fragment comes from stackoverflow .", "title": "Sort"}, {"location": "computer_science/programming/python/basics/#other-functions", "text": "", "title": "Other functions"}, {"location": "computer_science/programming/python/basics/#shuffle", "text": "To shuffle the elements order inside a list you can do from random import shuffle x = [ i for i in range ( 10 )] shuffle ( x ) This fragment comes from stackoverflow .", "title": "Shuffle"}, {"location": "computer_science/programming/python/basics/#generic-operating-system-services", "text": "", "title": "Generic Operating System Services"}, {"location": "computer_science/programming/python/basics/#os", "text": "", "title": "os"}, {"location": "computer_science/programming/python/basics/#listdir", "text": "os.listdir(path='.') returns a list containing the names of the entries in the directory given by path .", "title": "listdir"}, {"location": "computer_science/programming/python/basics/#text-processing-services", "text": "", "title": "Text processing services"}, {"location": "computer_science/programming/python/basics/#re", "text": "The re module provides regular expression matching operations similar to those found in Perl.", "title": "re"}, {"location": "computer_science/programming/python/basics/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/programming/python/basics/#check-if-string-matches-a-pattern", "text": "The usage is re.match(pattern, string) . Example: import re string = \"whatever\" if re . match ( \"what.*\" , string ): print ( \"yes\" )", "title": "Check if string matches a pattern"}, {"location": "computer_science/programming/python/basics/#tips", "text": "Try your RegEx at Pythex .", "title": "Tips"}, {"location": "computer_science/programming/python/basics/#time", "text": "The module time provides various time-related functions.", "title": "time"}, {"location": "computer_science/programming/python/basics/#usage_1", "text": "", "title": "Usage"}, {"location": "computer_science/programming/python/basics/#measure-elapsed-time-between-two-points", "text": "To measure elapsed time between two points do: import time start = time . time () print ( \"hello\" ) end = time . time () print ( end - start )", "title": "Measure elapsed time between two points"}, {"location": "computer_science/programming/python/basics/#data-types", "text": "", "title": "Data types"}, {"location": "computer_science/programming/python/basics/#datetime", "text": "", "title": "datetime"}, {"location": "computer_science/programming/python/basics/#methods_1", "text": "timestamp() : Return POSIX timestamp. now() : Return the current local date and time.", "title": "Methods"}, {"location": "computer_science/programming/python/basics/#enum", "text": "An enumeration is a set of symbolic names (members) bound to unique, constant values. Within an enumeration, the members can be compared by identity, and the enumeration itself can be iterated over. Example: from enum import Enum class Color ( Enum ): RED = 1 GREEN = 2 BLUE = 3 isinstance ( Color . GREEN , Color ) # True color = Color . RED color . name # RED color . value # 1 Enumeration members are hashable, so they can be used in dictionaries and sets.", "title": "enum"}, {"location": "computer_science/programming/python/basics/#io", "text": "", "title": "I/O"}, {"location": "computer_science/programming/python/basics/#files", "text": "You can operate with files from a filesystem directly from python. A common way of doing so is f = open ( '[file]' , '[mode]' ) Where [file] is the file path and [mode] is one of the following modes: w : For rewritting the file. r : For reading from the file. a : For appending at the end of the file. Then you can use the following methods (depending on the selected mode): f . write ( 'test' ) f . read () ... Nevertheless, it is a good practice to use the with keyword when dealing with file objects, since it will automatically close it after the work is done. It can be used as follows with open ( 'file_path' ) as f : file_data = f . read () Otherwise, f.close() should be called in order to close the file and thus freeing up any system resource used by it.", "title": "Files"}, {"location": "computer_science/programming/python/basics/#string-formatting", "text": "", "title": "String formatting"}, {"location": "computer_science/programming/python/basics/#formatted-string-literals-f-strings", "text": "Formatted string literals (also called f-strings for short) let you include the value of Python expressions inside a string by prefixing the string with f or F and writing expressions as {expression} . For example: name = \"robot\" print ( f \"Hello { name } \" )", "title": "Formatted string literals (f-strings)"}, {"location": "computer_science/programming/python/basics/#scientific-notation-for-numbers", "text": "To print a number using scientific notation with n decimals, do number = 0.000123 print ( \"{:. {n} e}\" . format ( number )) which will return 1.23e-04 with n=2 .", "title": "Scientific notation for numbers"}, {"location": "computer_science/programming/python/basics/#get-the-name-of-the-weekday", "text": "To get the name of the weekday of a datetime object use .strftime(\"%A\") . For example: >>> from datetime import datetime as date >>> date . today () . strftime ( \"%A\" ) 'Monday'", "title": "Get the name of the weekday"}, {"location": "computer_science/programming/python/basics/#internet-protocols-and-support", "text": "", "title": "Internet protocols and support"}, {"location": "computer_science/programming/python/basics/#httpserver", "text": "You can create a basic HTTP server that serves the files in the current directory with mkdir /tmp/www echo \"Hello world!\" > /tmp/index.html cd /tmp/www ; python3 -m http.server if you want to leave it running in the background even if you close the console session, do nohup python3 -m http.server & instead.", "title": "http.server"}, {"location": "computer_science/programming/python/basics/#built-in-exceptions", "text": "Most common: TypeError : Raised when an operation or function is applied to an object of inappropriate type. ValueError : Raised when an operation or function receives an argument that has the right type but an inappropriate value.", "title": "Built-in exceptions"}, {"location": "computer_science/programming/python/basics/#custom-exception", "text": "To provide more insightful error messages related to our code, we can create custom exceptions. For example: class ColorError ( ValueError ): def __init__ ( self , color ): message = f \"Invalid color { color } .\" super () . __init__ ( message )", "title": "Custom exception"}, {"location": "computer_science/programming/python/basics/#functional-programming-modules", "text": "", "title": "Functional programming modules"}, {"location": "computer_science/programming/python/basics/#functools", "text": "The functools module is for higher-order functions: functions that act on or return other functions.", "title": "functools"}, {"location": "computer_science/programming/python/basics/#usage_2", "text": "", "title": "Usage"}, {"location": "computer_science/programming/python/basics/#change-function-default-argument-value", "text": "from functools import partial def f ( num : int = 0 ) -> str : return \"The value of num is: \" + str ( num ) f_p = partial ( f , num = 1 ) f_p () To keep the docstring of the original function, just copy it with: f_p . __doc__ = f . __doc__", "title": "Change function default argument value"}, {"location": "computer_science/programming/python/basics/#python-runtime-services", "text": "", "title": "Python runtime services"}, {"location": "computer_science/programming/python/basics/#abstract-base-classes", "text": "This module provides the infrastructure for defining abstract base classes (ABCs) in Python, as outlined in PEP 3119 . To create an abstract base class, to define and interface and can be inherited but not instantiated, do: from abc import ABC , abstractmethod class Switchable ( ABC ): \"\"\"Switchable interface.\"\"\" is_on : bool = False @abstractmethod def turn_on ( self ): \"\"\"Method to turn on.\"\" @abstractmethod def turn_off(self): \"\"\" Method to turn off . \"\" class LightBulb ( Switchable ): \"\"\"Light bulb class.\"\"\" def turn_on ( self ): self . is_on = True print ( \"Light is on.\" ) def turn_on ( self ): self . is_on = False print ( \"Light is off.\" ) light_bulb_1 = LightBulb () light_bulb_1 . turn_on () This code is an example for an abstract class that doesn't follow the composition over inheritance principle. It would be better to implement separate turn_on and turn_off functions that get a Switchable object as their argument. Note : Use @abstractmethod before classmethod . See Issue 16267 .", "title": "Abstract Base Classes"}, {"location": "computer_science/programming/python/basics/#development-tools", "text": "", "title": "Development tools"}, {"location": "computer_science/programming/python/basics/#typing", "text": "Provides runtime support for type hints.", "title": "typing"}, {"location": "computer_science/programming/python/basics/#types", "text": "", "title": "Types"}, {"location": "computer_science/programming/python/basics/#typeddict", "text": "Special construct to add type hints to a dictionary. At runtime it is a plain dict . Example: class Point2D ( TypedDict ): x : int y : int label : str a : Point2D = { 'x' : 1 , 'y' : 2 , 'label' : 'good' } # OK b : Point2D = { 'z' : 3 , 'label' : 'bad' } # Fails type check By default, all keys must be present in a TypedDict . It is possible to override this by specifying totality. Usage: class point2D ( TypedDict , total = False ): x : int y : int", "title": "TypedDict"}, {"location": "computer_science/programming/python/debugging/", "text": "pdb \u2691 Since Python 3.7, we can just call breakpoint() and this will import pdb (or the debugger defined in the environment variable PYTHONBREAKPOINT ) and set the breakpoint in that part of the code. This will stop the program execution once the breakpoint is reached. Then, an interactive console while appear. Usage \u2691 The main commands are: args : Print the argument list of the current function. break : Creates a breakpoint (requires parameters) in the program execution. continue : Continues program execution. help : Provides list of commands or help for a specified command. jump : Set the next line to be executed list : Print the source code around the current line. next : Continue execution until the next line in the current function is reached or returns. step : Execute the current line, stopping at first possible occasion. pp : Pretty-prints the value of the expression. quit : Aborts the program. return : Continue execution until the current function returns. All of the above commands (except for pp ) can be called by only its first letter (e.g., continue -> c ). References \u2691 Talk: Nina Zakharenko - Goodbye Print, Hello Debugger! - YouTube", "title": "Debugging"}, {"location": "computer_science/programming/python/debugging/#pdb", "text": "Since Python 3.7, we can just call breakpoint() and this will import pdb (or the debugger defined in the environment variable PYTHONBREAKPOINT ) and set the breakpoint in that part of the code. This will stop the program execution once the breakpoint is reached. Then, an interactive console while appear.", "title": "pdb"}, {"location": "computer_science/programming/python/debugging/#usage", "text": "The main commands are: args : Print the argument list of the current function. break : Creates a breakpoint (requires parameters) in the program execution. continue : Continues program execution. help : Provides list of commands or help for a specified command. jump : Set the next line to be executed list : Print the source code around the current line. next : Continue execution until the next line in the current function is reached or returns. step : Execute the current line, stopping at first possible occasion. pp : Pretty-prints the value of the expression. quit : Aborts the program. return : Continue execution until the current function returns. All of the above commands (except for pp ) can be called by only its first letter (e.g., continue -> c ).", "title": "Usage"}, {"location": "computer_science/programming/python/debugging/#references", "text": "Talk: Nina Zakharenko - Goodbye Print, Hello Debugger! - YouTube", "title": "References"}, {"location": "computer_science/programming/python/decorators/", "text": "Overrides \u2691 overrides is a decorator that verifies that a method that should override an inherited method actually does, and that copies the docstring of the inherited method to the overridden method.", "title": "Decorators"}, {"location": "computer_science/programming/python/decorators/#overrides", "text": "overrides is a decorator that verifies that a method that should override an inherited method actually does, and that copies the docstring of the inherited method to the overridden method.", "title": "Overrides"}, {"location": "computer_science/programming/python/docstrings/", "text": "A docstring is a string literal that occurs as the first statement in a module, function, class, or method definition. Such a docstring becomes the __doc__ special attribute of that object. See PEP 257 Example docstring for a function: def connect_to_next_port ( self , minimum : int ) -> int : \"\"\"Connects to the next available port. Args: minimum: A port value greater or equal to 1024. Returns: The new minimum port. Raises: ConnectionError: If no available port is found. \"\"\"", "title": "Docstrings"}, {"location": "computer_science/programming/python/fastapi/", "text": "FastAPI is a modern, fast (high-performance), web framework for building HTTP APIs based on standard Python type hints. Example ( main.py ): from typing import Optional from fastapi import FastAPI app = FastAPI () @app . get ( \"/\" ) def read_root (): return { \"Hello\" : \"World\" } @app . get ( \"/items/ {item_id} \" ) def read_item ( item_id : int , q : Optional [ str ] = None ): return { \"item_id\" : item_id , \"q\" : q } Run it with uvicorn main:app --reload and then open your browser at http://127.0.0.1:8000/items/5?q=somequery . Usage \u2691 There are two main ways of using this module, with the decorator @app.get(\"{{route}}\") or with FastAPI().add_route(\"{{route}}\", {{function}}) . The first alternative is by far the most common, but if you want to separate the functions from the HTTP API entrypoint, you have to use the second option. For example: from fastapi import FastAPI api = FastAPI() def hello(name: str) -> str: return \"Hello \" + name + \"!\" api.add_route('/hello', hello) The advantage of this alternative is that we can import the function from another module. If you need to change the default value of some argument of the original function, you can use functools . This might be necessary if an argument is a list, since you'll need to set its default value to Query() you can change it with functools instead of modifying the original function (which would be pretty ugly). Make sure of copying the original docstring. Nevertheless, this approach has some caveats such as not handling exceptions raised from the imported function. The best solution for this appears to be defining a wrapper function that handles the arguments, calls the imported function or method and handles the exceptions raising the proper HTTPException . Dependency injection \u2691 A FastAPI decorated function can import the necessary arguments for other functions or objects. For example: from typing import Optional from fastapi import Depends , FastAPI app = FastAPI () async def common_parameters ( q : Optional [ str ] = None , skip : int = 0 , limit : int = 100 ): return { \"q\" : q , \"skip\" : skip , \"limit\" : limit } @app . get ( \"/items/\" ) async def read_items ( commons : dict = Depends ( common_parameters )): return commons In this example, the function read_items will get the parameters for the function common_parameters (i.e., q , skip , limit ) allowing the optional ones to be set or not. Then, the passed parameters will be passed as a dictionary as the commons argument value of read_itmes . This is thanks to Depends . Depends can also be used with classes, and we could get an instance of a class directly to our function. For example by setting the argument: car: Car = Depends(Car) or car: Car = Depends() (which assumes that it depends on the class defined in the type hint). JSON encoder \u2691 The default the responses will be serialized to JSON. You can use a different JSON encoder than the default one, for example ijl/orjson which is more efficient and natively support serialization of dataclasses and more. To set the default encoder do: from fastapi import FastAPI from fastapi.responses import ORJSONResponse FastAPI ( default_response_class = ORJSONResponse ) Testing \u2691 Testing startup and shutdown events \u2691 When you need your event handlers ( startup and shutdown ) to run in your tests, you can use the TestClient with a with statement: import pytest from fastapi.testclient import TestClient from api.main import api @pytest . fixture def client (): with TestClient ( api ) as client : yield client def test_endpoint ( client ): response = client . get ( \"/endpoint\" ) assert response . status_code == 200 Performance \u2691 Performance can be hugely improved with some minor changes: Use orjson (faster JSON serialization): from fastapi import FastAPI from fastapi.responses import ORJSONResponse app = FastAPI ( default_response_class = ORJSONResponse ) ... * When using response_model=... , directly return a Response object if you've already done the pydantic model validation (or if you don't want to validate the object at all). Otherwise the validation will happen twice which is computationally expensive. ... from fastapi.encoders import jsonable_encoder class Thing ( BaseModel ): name : str @app . get ( \"/thing', response_model=Thing) def get_thing (): thing : Thing = Thing ( name = \"something\" ) return ORJSONResponse ( content = jsonable_encoder ( result )) * Use long2ice/fastapi-cache to cache responses and set the appropriate ETag and Cache-Control headers. You will need to use the PickleCoder coder if you want to cache responses directly. Otherwise if you directly return a dict or similar (not a Response ) the cache will store that object and then the model validation will be executed unnecessarily every time the endpoint is called.. All together: from fastapi import FastAPI from fastapi.responses import ORJSONResponse from fastapi.encoders import jsonable_encoder from fastapi_cache.backends.inmemory import InMemoryBackend from fastapi_cache.coder import PickleCoder app = FastAPI ( default_response_class = ORJSONResponse ) @app . on_event ( \"startup\" ) async def startup (): FastAPICache . init ( InMemoryBackend ()) class Thing ( BaseModel ): name : str @app . get ( \"/thing', response_model=Thing) @cache ( expire = 7 * 24 * 60 * 60 , coder = PickleCoder ) # 7 days def get_thing (): thing : Thing = Thing ( name = \"something\" ) return ORJSONResponse ( content = jsonable_encoder ( result ))", "title": "FastAPI"}, {"location": "computer_science/programming/python/fastapi/#usage", "text": "There are two main ways of using this module, with the decorator @app.get(\"{{route}}\") or with FastAPI().add_route(\"{{route}}\", {{function}}) . The first alternative is by far the most common, but if you want to separate the functions from the HTTP API entrypoint, you have to use the second option. For example: from fastapi import FastAPI api = FastAPI() def hello(name: str) -> str: return \"Hello \" + name + \"!\" api.add_route('/hello', hello) The advantage of this alternative is that we can import the function from another module. If you need to change the default value of some argument of the original function, you can use functools . This might be necessary if an argument is a list, since you'll need to set its default value to Query() you can change it with functools instead of modifying the original function (which would be pretty ugly). Make sure of copying the original docstring. Nevertheless, this approach has some caveats such as not handling exceptions raised from the imported function. The best solution for this appears to be defining a wrapper function that handles the arguments, calls the imported function or method and handles the exceptions raising the proper HTTPException .", "title": "Usage"}, {"location": "computer_science/programming/python/fastapi/#dependency-injection", "text": "A FastAPI decorated function can import the necessary arguments for other functions or objects. For example: from typing import Optional from fastapi import Depends , FastAPI app = FastAPI () async def common_parameters ( q : Optional [ str ] = None , skip : int = 0 , limit : int = 100 ): return { \"q\" : q , \"skip\" : skip , \"limit\" : limit } @app . get ( \"/items/\" ) async def read_items ( commons : dict = Depends ( common_parameters )): return commons In this example, the function read_items will get the parameters for the function common_parameters (i.e., q , skip , limit ) allowing the optional ones to be set or not. Then, the passed parameters will be passed as a dictionary as the commons argument value of read_itmes . This is thanks to Depends . Depends can also be used with classes, and we could get an instance of a class directly to our function. For example by setting the argument: car: Car = Depends(Car) or car: Car = Depends() (which assumes that it depends on the class defined in the type hint).", "title": "Dependency injection"}, {"location": "computer_science/programming/python/fastapi/#json-encoder", "text": "The default the responses will be serialized to JSON. You can use a different JSON encoder than the default one, for example ijl/orjson which is more efficient and natively support serialization of dataclasses and more. To set the default encoder do: from fastapi import FastAPI from fastapi.responses import ORJSONResponse FastAPI ( default_response_class = ORJSONResponse )", "title": "JSON encoder"}, {"location": "computer_science/programming/python/fastapi/#testing", "text": "", "title": "Testing"}, {"location": "computer_science/programming/python/fastapi/#testing-startup-and-shutdown-events", "text": "When you need your event handlers ( startup and shutdown ) to run in your tests, you can use the TestClient with a with statement: import pytest from fastapi.testclient import TestClient from api.main import api @pytest . fixture def client (): with TestClient ( api ) as client : yield client def test_endpoint ( client ): response = client . get ( \"/endpoint\" ) assert response . status_code == 200", "title": "Testing startup and shutdown events"}, {"location": "computer_science/programming/python/fastapi/#performance", "text": "Performance can be hugely improved with some minor changes: Use orjson (faster JSON serialization): from fastapi import FastAPI from fastapi.responses import ORJSONResponse app = FastAPI ( default_response_class = ORJSONResponse ) ... * When using response_model=... , directly return a Response object if you've already done the pydantic model validation (or if you don't want to validate the object at all). Otherwise the validation will happen twice which is computationally expensive. ... from fastapi.encoders import jsonable_encoder class Thing ( BaseModel ): name : str @app . get ( \"/thing', response_model=Thing) def get_thing (): thing : Thing = Thing ( name = \"something\" ) return ORJSONResponse ( content = jsonable_encoder ( result )) * Use long2ice/fastapi-cache to cache responses and set the appropriate ETag and Cache-Control headers. You will need to use the PickleCoder coder if you want to cache responses directly. Otherwise if you directly return a dict or similar (not a Response ) the cache will store that object and then the model validation will be executed unnecessarily every time the endpoint is called.. All together: from fastapi import FastAPI from fastapi.responses import ORJSONResponse from fastapi.encoders import jsonable_encoder from fastapi_cache.backends.inmemory import InMemoryBackend from fastapi_cache.coder import PickleCoder app = FastAPI ( default_response_class = ORJSONResponse ) @app . on_event ( \"startup\" ) async def startup (): FastAPICache . init ( InMemoryBackend ()) class Thing ( BaseModel ): name : str @app . get ( \"/thing', response_model=Thing) @cache ( expire = 7 * 24 * 60 * 60 , coder = PickleCoder ) # 7 days def get_thing (): thing : Thing = Thing ( name = \"something\" ) return ORJSONResponse ( content = jsonable_encoder ( result ))", "title": "Performance"}, {"location": "computer_science/programming/python/gotchas/", "text": "Two dimensional array initialization \u2691 Imagine we want to initialize an array containing a few empty arrays inside, something like arr = [[], [], []] If we want to save time and/or keystrokes, we might be tempted to do it as follows arr = [[]] * 3 >>> arr [[], [], []] Which looks like what we wanted right? Well it does, but the gotcha is that all of the inner arrays are actually the same object copied so if you modify one of them, \"all of them\" will be equally affected. For example, >>> arr [ 0 ] . append ( 'test' ) >>> arr [[ 'test' ], [ 'test' ], [ 'test' ]] So what you should do instead is: arr = [[] for _ in range ( 3 )]", "title": "Gotchas"}, {"location": "computer_science/programming/python/gotchas/#two-dimensional-array-initialization", "text": "Imagine we want to initialize an array containing a few empty arrays inside, something like arr = [[], [], []] If we want to save time and/or keystrokes, we might be tempted to do it as follows arr = [[]] * 3 >>> arr [[], [], []] Which looks like what we wanted right? Well it does, but the gotcha is that all of the inner arrays are actually the same object copied so if you modify one of them, \"all of them\" will be equally affected. For example, >>> arr [ 0 ] . append ( 'test' ) >>> arr [[ 'test' ], [ 'test' ], [ 'test' ]] So what you should do instead is: arr = [[] for _ in range ( 3 )]", "title": "Two dimensional array initialization"}, {"location": "computer_science/programming/python/json/", "text": "json is a JSON encoder and decoder for Python. Usage \u2691 Load a file \u2691 Use json.load . You can specify the file encoding if necessary. import json with open ( ' {path} ' , encoding = 'utf-8' ) as f : data = json . load ( f ) Load a file with multiple JSON objects \u2691 json.load expects a single JSON object, so if your file has a JSON object per line, load the objects of each line with json.loads that expects an str object instead of a file. import json data = [] with open ( ' {path} ' ) as f : for line in f : data . append ( json . loads ( line ))", "title": "json"}, {"location": "computer_science/programming/python/json/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/programming/python/json/#load-a-file", "text": "Use json.load . You can specify the file encoding if necessary. import json with open ( ' {path} ' , encoding = 'utf-8' ) as f : data = json . load ( f )", "title": "Load a file"}, {"location": "computer_science/programming/python/json/#load-a-file-with-multiple-json-objects", "text": "json.load expects a single JSON object, so if your file has a JSON object per line, load the objects of each line with json.loads that expects an str object instead of a file. import json data = [] with open ( ' {path} ' ) as f : for line in f : data . append ( json . loads ( line ))", "title": "Load a file with multiple JSON objects"}, {"location": "computer_science/programming/python/jupyter/", "text": "Jupyter Notebook/Lab is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. It can be used for R and for Python, among others. Extensions \u2691 jupyter-server-proxy \u2691 Jupyter Server Proxy lets you run arbitrary external processes (such as RStudio, Shiny Server, syncthing, PostgreSQL, etc) alongside your notebook, and provide authenticated web access to them. Once installed, you'll be able to access arbitrary hosts and ports at <notebook-base>/proxy/<host>:<port> . Installation \u2691 First, install the required server extension jupyter serverextension enable --sys-prefix jupyter_server_proxy then, install the Python package pip install jupyter-server-proxy and you're ready to go. Libraries \u2691 jupyter-dash \u2691 plotly/jupyter-dash is a library that makes it easy to develop Plotly Dash apps interactively from within Jupyter environments. Installation \u2691 pip install jupyter-dash Usage \u2691 In a Jupyter Notebook, run this example application import plotly.express as px from jupyter_dash import JupyterDash JupyterDash . infer_jupyter_proxy_config () import dash_core_components as dcc import dash_html_components as html from dash.dependencies import Input , Output # Load Data df = px . data . tips () # Build App app = JupyterDash ( __name__ ) app . layout = html . Div ([ html . H1 ( \"JupyterDash Demo\" ), dcc . Graph ( id = 'graph' ), html . Label ([ \"colorscale\" , dcc . Dropdown ( id = 'colorscale-dropdown' , clearable = False , value = 'plasma' , options = [ { 'label' : c , 'value' : c } for c in px . colors . named_colorscales () ]) ]), ]) # Define callback to update graph @app . callback ( Output ( 'graph' , 'figure' ), [ Input ( \"colorscale-dropdown\" , \"value\" )] ) def update_figure ( colorscale ): return px . scatter ( df , x = \"total_bill\" , y = \"tip\" , color = \"size\" , color_continuous_scale = colorscale , render_mode = \"webgl\" , title = \"Tips\" ) # Run app and display result inline in the notebook app . run_server ( mode = 'inline' ) JupyterDash.infer_jupyter_proxy_config() is needed if the Jupyter server is not accessible directly, and needs the jupyter-server-proxy extension to be installed. ipynb \u2691 ipython/ipynb is a package/module importer for importing code from Jupyter Notebook files (.ipynb). Usage \u2691 To import a Notebook ( notebook1 ) that is in the same directory as the current one: import ipynb.fs # Boilerplate required # Do a full import from .full.notebook1 import foo # Do a definitions-only import from .defs.notebook1 import bar", "title": "Jupyter Notebook/Lab"}, {"location": "computer_science/programming/python/jupyter/#extensions", "text": "", "title": "Extensions"}, {"location": "computer_science/programming/python/jupyter/#jupyter-server-proxy", "text": "Jupyter Server Proxy lets you run arbitrary external processes (such as RStudio, Shiny Server, syncthing, PostgreSQL, etc) alongside your notebook, and provide authenticated web access to them. Once installed, you'll be able to access arbitrary hosts and ports at <notebook-base>/proxy/<host>:<port> .", "title": "jupyter-server-proxy"}, {"location": "computer_science/programming/python/jupyter/#installation", "text": "First, install the required server extension jupyter serverextension enable --sys-prefix jupyter_server_proxy then, install the Python package pip install jupyter-server-proxy and you're ready to go.", "title": "Installation"}, {"location": "computer_science/programming/python/jupyter/#libraries", "text": "", "title": "Libraries"}, {"location": "computer_science/programming/python/jupyter/#jupyter-dash", "text": "plotly/jupyter-dash is a library that makes it easy to develop Plotly Dash apps interactively from within Jupyter environments.", "title": "jupyter-dash"}, {"location": "computer_science/programming/python/jupyter/#installation_1", "text": "pip install jupyter-dash", "title": "Installation"}, {"location": "computer_science/programming/python/jupyter/#usage", "text": "In a Jupyter Notebook, run this example application import plotly.express as px from jupyter_dash import JupyterDash JupyterDash . infer_jupyter_proxy_config () import dash_core_components as dcc import dash_html_components as html from dash.dependencies import Input , Output # Load Data df = px . data . tips () # Build App app = JupyterDash ( __name__ ) app . layout = html . Div ([ html . H1 ( \"JupyterDash Demo\" ), dcc . Graph ( id = 'graph' ), html . Label ([ \"colorscale\" , dcc . Dropdown ( id = 'colorscale-dropdown' , clearable = False , value = 'plasma' , options = [ { 'label' : c , 'value' : c } for c in px . colors . named_colorscales () ]) ]), ]) # Define callback to update graph @app . callback ( Output ( 'graph' , 'figure' ), [ Input ( \"colorscale-dropdown\" , \"value\" )] ) def update_figure ( colorscale ): return px . scatter ( df , x = \"total_bill\" , y = \"tip\" , color = \"size\" , color_continuous_scale = colorscale , render_mode = \"webgl\" , title = \"Tips\" ) # Run app and display result inline in the notebook app . run_server ( mode = 'inline' ) JupyterDash.infer_jupyter_proxy_config() is needed if the Jupyter server is not accessible directly, and needs the jupyter-server-proxy extension to be installed.", "title": "Usage"}, {"location": "computer_science/programming/python/jupyter/#ipynb", "text": "ipython/ipynb is a package/module importer for importing code from Jupyter Notebook files (.ipynb).", "title": "ipynb"}, {"location": "computer_science/programming/python/jupyter/#usage_1", "text": "To import a Notebook ( notebook1 ) that is in the same directory as the current one: import ipynb.fs # Boilerplate required # Do a full import from .full.notebook1 import foo # Do a definitions-only import from .defs.notebook1 import bar", "title": "Usage"}, {"location": "computer_science/programming/python/linters/", "text": "Pydocstyle \u2691 PyCQA/pydocstyle is a static analysis tool for checking compliance with Python docstring conventions. Tips \u2691 Allow missing docstrings when overriding methods \u2691 To allow missing docstrings when overriding methods you can use the @overrides decorator and the command line option --ignore-decorator=overrides or the setting ignore_decorator = \"overrides\" in the configuration file.", "title": "Linters"}, {"location": "computer_science/programming/python/linters/#pydocstyle", "text": "PyCQA/pydocstyle is a static analysis tool for checking compliance with Python docstring conventions.", "title": "Pydocstyle"}, {"location": "computer_science/programming/python/linters/#tips", "text": "", "title": "Tips"}, {"location": "computer_science/programming/python/linters/#allow-missing-docstrings-when-overriding-methods", "text": "To allow missing docstrings when overriding methods you can use the @overrides decorator and the command line option --ignore-decorator=overrides or the setting ignore_decorator = \"overrides\" in the configuration file.", "title": "Allow missing docstrings when overriding methods"}, {"location": "computer_science/programming/python/mypy/", "text": "mypy is a static type checker for Python. Usage \u2691 Pre-commit hook \u2691 To use mypy as a pre-commit hook, add: - repo : 'https://github.com/pre-commit/mirrors-mypy' rev : '' hooks : - id : 'mypy' args : [] additional_dependencies : - 'pydantic' For extended support for pydantic don't forget to add the additional dependency and enable the plugin in pyproject.toml with: # --------- mypy ------------- [tool.mypy] plugins = [ \"pydantic.mypy\" ] Tips \u2691 Ignore type checking in one line \u2691 To ignore type checking in one particular line of the code, add the comment # type: ignore at the end of that line", "title": "mypy"}, {"location": "computer_science/programming/python/mypy/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/programming/python/mypy/#pre-commit-hook", "text": "To use mypy as a pre-commit hook, add: - repo : 'https://github.com/pre-commit/mirrors-mypy' rev : '' hooks : - id : 'mypy' args : [] additional_dependencies : - 'pydantic' For extended support for pydantic don't forget to add the additional dependency and enable the plugin in pyproject.toml with: # --------- mypy ------------- [tool.mypy] plugins = [ \"pydantic.mypy\" ]", "title": "Pre-commit hook"}, {"location": "computer_science/programming/python/mypy/#tips", "text": "", "title": "Tips"}, {"location": "computer_science/programming/python/mypy/#ignore-type-checking-in-one-line", "text": "To ignore type checking in one particular line of the code, add the comment # type: ignore at the end of that line", "title": "Ignore type checking in one line"}, {"location": "computer_science/programming/python/networkx/", "text": "NetworkX is a Python package for the creation, manipulation, and study of the structure, dynamics, and functions of complex networks. Importing \u2691 Import from Pandas \u2691 Import from edgelist \u2691 You need a DataFrame containing at least origin and destination columns. The rest of the columns, or a selection of them, can be imported as edge attributes. An input DataFrame could look like origin destination weight cost A B 2 100 A C 1 20 ... ... ... ... To create an NetworkX.Graph from it, do import networkx as nx import pandas as pd import matplotlib.pyplot as plt df = pd . DataFrame ({ \"origin\" : [ \"A\" , \"A\" ], \"destination\" : [ \"B\" , \"C\" ], \"weight\" : [ 2 , 1 ], \"cost\" : [ 100 , 20 ] }) G = nx . from_pandas_edgelist ( df , source = \"origin\" , target = \"destination\" , edge_attr = [ \"weight\" , \"cost\" ], create_using = nx . DiGraph ()) # Draw it pos = nx . spring_layout ( G , k = 10 ) # For better example looking nx . draw ( G , pos , with_labels = True ) labels = { e : G . edges [ e ][ \"cost\" ] for e in G . edges } nx . draw_networkx_edge_labels ( G , pos , edge_labels = labels ) plt . show () Only add create_using=nx.DiGraph() if you want the result to be a directed graph, otherwise it will be an undirected one by default. Add node attributes from Series \u2691 You can add node attributes to an existing graph from a Pandas Series with_labels nx . set_node_attributes ( G , pd . Series ( nodes . gender , index = nodes . node ) . to_dict (), 'gender' ) Exporting \u2691 Export to Gephi \u2691 NetworkX graphs can be easily exported to GEXF File Format , which is supported by Gephi . To do so, import networkx as nx G = nx . Graph () nx . write_gexf ( G , ' {name} .gexf' ) I had some issues exporting a graph that was created from Pandas. I could only export it correctly when I left only the weight edge attribute. Generators \u2691 Ego graph \u2691 To generate the ego graph of a node from an existing graph, you can use networkx.generators.ego.ego_graph . networkx . generators . ego . ego_graph ( G , n , radius = 1 , center = True , undirected = False , distance = None ) Undirected graph from directed \u2691 Use networkx.DiGraph.to_undirected(reciprocal=False, as_view=False) . Set reciprocal=True if you want to keep only the edges that appear in both directions in the original digraph. Subgraph filtering nodes and edges \u2691 To get a subgraph of another by filtering nodes and or edges, use networkx.classes.graphviews.subgraph_view(G, filter_node=<function no_filter>, filter_edge=<function no_filter>) . The functions will get the node name or the edge name only (without attributes) so keep it in mind while writing the filtering function because you won't be able to access the node or edge attributes directly. Example: import networkx as nx G = nx . path_graph ( 6 ) G [ 3 ][ 4 ][ \"cross_me\" ] = False def filter_edge ( n1 , n2 ): return G [ n1 ][ n2 ] . get ( \"cross_me\" , True ) view = nx . subgraph_view ( G , filter_edge = filter_edge ) view . edges () Which returns EdgeView([(0, 1), (1, 2), (2, 3), (4, 5)]) .", "title": "NetworkX"}, {"location": "computer_science/programming/python/networkx/#importing", "text": "", "title": "Importing"}, {"location": "computer_science/programming/python/networkx/#import-from-pandas", "text": "", "title": "Import from Pandas"}, {"location": "computer_science/programming/python/networkx/#import-from-edgelist", "text": "You need a DataFrame containing at least origin and destination columns. The rest of the columns, or a selection of them, can be imported as edge attributes. An input DataFrame could look like origin destination weight cost A B 2 100 A C 1 20 ... ... ... ... To create an NetworkX.Graph from it, do import networkx as nx import pandas as pd import matplotlib.pyplot as plt df = pd . DataFrame ({ \"origin\" : [ \"A\" , \"A\" ], \"destination\" : [ \"B\" , \"C\" ], \"weight\" : [ 2 , 1 ], \"cost\" : [ 100 , 20 ] }) G = nx . from_pandas_edgelist ( df , source = \"origin\" , target = \"destination\" , edge_attr = [ \"weight\" , \"cost\" ], create_using = nx . DiGraph ()) # Draw it pos = nx . spring_layout ( G , k = 10 ) # For better example looking nx . draw ( G , pos , with_labels = True ) labels = { e : G . edges [ e ][ \"cost\" ] for e in G . edges } nx . draw_networkx_edge_labels ( G , pos , edge_labels = labels ) plt . show () Only add create_using=nx.DiGraph() if you want the result to be a directed graph, otherwise it will be an undirected one by default.", "title": "Import from edgelist"}, {"location": "computer_science/programming/python/networkx/#add-node-attributes-from-series", "text": "You can add node attributes to an existing graph from a Pandas Series with_labels nx . set_node_attributes ( G , pd . Series ( nodes . gender , index = nodes . node ) . to_dict (), 'gender' )", "title": "Add node attributes from Series"}, {"location": "computer_science/programming/python/networkx/#exporting", "text": "", "title": "Exporting"}, {"location": "computer_science/programming/python/networkx/#export-to-gephi", "text": "NetworkX graphs can be easily exported to GEXF File Format , which is supported by Gephi . To do so, import networkx as nx G = nx . Graph () nx . write_gexf ( G , ' {name} .gexf' ) I had some issues exporting a graph that was created from Pandas. I could only export it correctly when I left only the weight edge attribute.", "title": "Export to Gephi"}, {"location": "computer_science/programming/python/networkx/#generators", "text": "", "title": "Generators"}, {"location": "computer_science/programming/python/networkx/#ego-graph", "text": "To generate the ego graph of a node from an existing graph, you can use networkx.generators.ego.ego_graph . networkx . generators . ego . ego_graph ( G , n , radius = 1 , center = True , undirected = False , distance = None )", "title": "Ego graph"}, {"location": "computer_science/programming/python/networkx/#undirected-graph-from-directed", "text": "Use networkx.DiGraph.to_undirected(reciprocal=False, as_view=False) . Set reciprocal=True if you want to keep only the edges that appear in both directions in the original digraph.", "title": "Undirected graph from directed"}, {"location": "computer_science/programming/python/networkx/#subgraph-filtering-nodes-and-edges", "text": "To get a subgraph of another by filtering nodes and or edges, use networkx.classes.graphviews.subgraph_view(G, filter_node=<function no_filter>, filter_edge=<function no_filter>) . The functions will get the node name or the edge name only (without attributes) so keep it in mind while writing the filtering function because you won't be able to access the node or edge attributes directly. Example: import networkx as nx G = nx . path_graph ( 6 ) G [ 3 ][ 4 ][ \"cross_me\" ] = False def filter_edge ( n1 , n2 ): return G [ n1 ][ n2 ] . get ( \"cross_me\" , True ) view = nx . subgraph_view ( G , filter_edge = filter_edge ) view . edges () Which returns EdgeView([(0, 1), (1, 2), (2, 3), (4, 5)]) .", "title": "Subgraph filtering nodes and edges"}, {"location": "computer_science/programming/python/pandas/", "text": "Usage \u2691 Get data \u2691 Read series from file \u2691 You can use series = pd . read_csv ( 'csvfile.csv' , header = None , index_col = 0 , squeeze = True ) squeeze also works with read_table . DataFrame \u2691 Methods \u2691 to_sql \u2691 pandas.DataFrame.to_sql (name, con, schema=None, if_exists='fail', index=True, index_label=None, chunksize=None, dtype=None, method=None) writes records stored in a DataFrame to a SQL database. Example: import pandas as pd from sqlalchemy import create_engine engine = create_engine ( 'sqlite://' , echo = False ) df = pd . DataFrame ({ 'name' : [ 'User 1' , 'User 2' , 'User 3' ]}) df . to_sql ( 'users' , con = engine ) This will create a new table called users and fill it with the DataFrame . If the table already exists, it will fail. Set if_exists='append' or if_exists='replace' for other behaviors. Debug \u2691 pandas.errors.DtypeWarning \u2691 Warning raised when reading different dtypes in a column from a file. pandas.errors.DtypeWarning Reference \u2691 Nullable integer data type", "title": "Pandas"}, {"location": "computer_science/programming/python/pandas/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/programming/python/pandas/#get-data", "text": "", "title": "Get data"}, {"location": "computer_science/programming/python/pandas/#read-series-from-file", "text": "You can use series = pd . read_csv ( 'csvfile.csv' , header = None , index_col = 0 , squeeze = True ) squeeze also works with read_table .", "title": "Read series from file"}, {"location": "computer_science/programming/python/pandas/#dataframe", "text": "", "title": "DataFrame"}, {"location": "computer_science/programming/python/pandas/#methods", "text": "", "title": "Methods"}, {"location": "computer_science/programming/python/pandas/#to_sql", "text": "pandas.DataFrame.to_sql (name, con, schema=None, if_exists='fail', index=True, index_label=None, chunksize=None, dtype=None, method=None) writes records stored in a DataFrame to a SQL database. Example: import pandas as pd from sqlalchemy import create_engine engine = create_engine ( 'sqlite://' , echo = False ) df = pd . DataFrame ({ 'name' : [ 'User 1' , 'User 2' , 'User 3' ]}) df . to_sql ( 'users' , con = engine ) This will create a new table called users and fill it with the DataFrame . If the table already exists, it will fail. Set if_exists='append' or if_exists='replace' for other behaviors.", "title": "to_sql"}, {"location": "computer_science/programming/python/pandas/#debug", "text": "", "title": "Debug"}, {"location": "computer_science/programming/python/pandas/#pandaserrorsdtypewarning", "text": "Warning raised when reading different dtypes in a column from a file. pandas.errors.DtypeWarning", "title": "pandas.errors.DtypeWarning"}, {"location": "computer_science/programming/python/pandas/#reference", "text": "Nullable integer data type", "title": "Reference"}, {"location": "computer_science/programming/python/pip/", "text": "Usage \u2691 Uninstall a package \u2691 pip uninstall [package] pypa-doc Requirements files \u2691 Structure \u2691 Define the user dependencies in setup.py and use pip-compile to generate a requirements.txt file with the latest compatible versions. Then, create a requirements-dev.in file and add: -c requirements.txt -e file:. dep1 dep2 ... -c requirements.txt will consider the user dependencies and its versions but without adding them also to requirements-dev.txt . Add with -c any other requirements files from the project such as docs/requirements.txt . -e file:. will add the local package so that any changes would reflect directly in your environment. file:. instead of just . makes the path in the generated requirements-dev.txt relative instead of absolute. Use pip-compile requirements-dev.in to generate requirements-dev.txt . pip-tools \u2691 jazzband/pip-tools are a set of tools to keep your pinned Python dependencies fresh. pip-compile \u2691 Define dependencies in setup.py or requirements.in (without specifying the version of each package) and then set the version to the latest possible one by running pip-compile , which will generate a requirements.txt file. This is useful for having a saved list with the dependencies and their version that are compatible among them and with your software (you can check it by running your software's tests for example). Development dependencies \u2691 You can build a requirements-dev.txt file containing the development dependencies needed only for development purposes and not for the software user and considering the dependencies and versions from requirements.txt so that only compatible versions are chosen. To do so, create a requirements-dev.in file containing: -c requirements.txt somepackage otherpackage ... And fix the versions with: pip-compile requirements-dev.in Which will generate a requirements-dev.txt file. pip-sync \u2691 To keep the locally installed dependencies synced with these files do: python -m piptools sync requirements.txt requirements-dev.txt Only run inside of a virtual environment.", "title": "pip"}, {"location": "computer_science/programming/python/pip/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/programming/python/pip/#uninstall-a-package", "text": "pip uninstall [package] pypa-doc", "title": "Uninstall a package"}, {"location": "computer_science/programming/python/pip/#requirements-files", "text": "", "title": "Requirements files"}, {"location": "computer_science/programming/python/pip/#structure", "text": "Define the user dependencies in setup.py and use pip-compile to generate a requirements.txt file with the latest compatible versions. Then, create a requirements-dev.in file and add: -c requirements.txt -e file:. dep1 dep2 ... -c requirements.txt will consider the user dependencies and its versions but without adding them also to requirements-dev.txt . Add with -c any other requirements files from the project such as docs/requirements.txt . -e file:. will add the local package so that any changes would reflect directly in your environment. file:. instead of just . makes the path in the generated requirements-dev.txt relative instead of absolute. Use pip-compile requirements-dev.in to generate requirements-dev.txt .", "title": "Structure"}, {"location": "computer_science/programming/python/pip/#pip-tools", "text": "jazzband/pip-tools are a set of tools to keep your pinned Python dependencies fresh.", "title": "pip-tools"}, {"location": "computer_science/programming/python/pip/#pip-compile", "text": "Define dependencies in setup.py or requirements.in (without specifying the version of each package) and then set the version to the latest possible one by running pip-compile , which will generate a requirements.txt file. This is useful for having a saved list with the dependencies and their version that are compatible among them and with your software (you can check it by running your software's tests for example).", "title": "pip-compile"}, {"location": "computer_science/programming/python/pip/#development-dependencies", "text": "You can build a requirements-dev.txt file containing the development dependencies needed only for development purposes and not for the software user and considering the dependencies and versions from requirements.txt so that only compatible versions are chosen. To do so, create a requirements-dev.in file containing: -c requirements.txt somepackage otherpackage ... And fix the versions with: pip-compile requirements-dev.in Which will generate a requirements-dev.txt file.", "title": "Development dependencies"}, {"location": "computer_science/programming/python/pip/#pip-sync", "text": "To keep the locally installed dependencies synced with these files do: python -m piptools sync requirements.txt requirements-dev.txt Only run inside of a virtual environment.", "title": "pip-sync"}, {"location": "computer_science/programming/python/plotly/", "text": "Plotly express \u2691 Usage \u2691 Facet and Trellis Plots \u2691 Facet plots, also known as trellis plots or small multiples, are figures made up of multiple subplots which have the same set of axes, where each subplot shows a subset of the data. Example: import plotly.express as px df = px . data . gapminder () fig = px . scatter ( df , x = 'gdpPercap' , y = 'lifeExp' , color = 'continent' , size = 'pop' , facet_col = 'year' , facet_col_wrap = 4 ) fig . show () Convert Matplotlib figure to Plotly \u2691 For better aesthetics and interactivity, you can convert Matplotlib figures, that often are returned by existing libraries, to Plotly with: import plotly.tools as tls x = np . random . random ( 100 ) # toy data y = np . random . random ( 100 ) # toy data ## matplotlib fig fig , axes = plt . subplots ( 2 , 1 , figsize = ( 10 , 6 )) axes [ 0 ] . plot ( x , label = 'x' ) axes [ 1 ] . scatter ( x , y ) ## convert and plot in plotly tls . mpl_to_plotly ( fig ) Reference: python - Matplotlib to plotly offline - Stack Overflow Dash \u2691 Dash is a productive Python framework for building web analytic applications. Configuration \u2691 Reverse proxy \u2691 There might be issues with the request URLs if the app is served under a non-root directory of a domain (e.g., domain.tld/dashboard/ ). This is because Dash uses some absolute paths by default. Use the following configuration to avoid this issues: app = dash . Dash ( __name__ ) app . config . update ( { \"routes_pathname_prefix\" : \"\" , # default is / \"requests_pathname_prefix\" : \"/ {path} /\" , } ) Then if you use NGINX: location / { path}/ { proxy_pass http://127.0.0.1: { binded_port}/ ; } Interactive visualizations \u2691 The dash_core_components library includes a component called Graph . Graph renders interactive data visualizations using the open source plotly.js JavaScript graphing library. plotly.js supports over 35 chart types and renders charts in both vector-quality SVG and high-performance WebGL. The figure argument in the dash_core_components.Graph component is the same figure argument that is used by plotly.py . Dash components are described declaratively by a set of attributes. All of these attributes can be updated by callback functions, but only a subset of these attributes are updated through user interaction, such as when you click on an option in a dcc.Dropdown component and the value property of tha component changes. The dcc.Graph component has four attributes that can change through user-interaction: hoverData , clickData , selectedData , relayoutData .", "title": "Plotly"}, {"location": "computer_science/programming/python/plotly/#plotly-express", "text": "", "title": "Plotly express"}, {"location": "computer_science/programming/python/plotly/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/programming/python/plotly/#facet-and-trellis-plots", "text": "Facet plots, also known as trellis plots or small multiples, are figures made up of multiple subplots which have the same set of axes, where each subplot shows a subset of the data. Example: import plotly.express as px df = px . data . gapminder () fig = px . scatter ( df , x = 'gdpPercap' , y = 'lifeExp' , color = 'continent' , size = 'pop' , facet_col = 'year' , facet_col_wrap = 4 ) fig . show ()", "title": "Facet and Trellis Plots"}, {"location": "computer_science/programming/python/plotly/#convert-matplotlib-figure-to-plotly", "text": "For better aesthetics and interactivity, you can convert Matplotlib figures, that often are returned by existing libraries, to Plotly with: import plotly.tools as tls x = np . random . random ( 100 ) # toy data y = np . random . random ( 100 ) # toy data ## matplotlib fig fig , axes = plt . subplots ( 2 , 1 , figsize = ( 10 , 6 )) axes [ 0 ] . plot ( x , label = 'x' ) axes [ 1 ] . scatter ( x , y ) ## convert and plot in plotly tls . mpl_to_plotly ( fig ) Reference: python - Matplotlib to plotly offline - Stack Overflow", "title": "Convert Matplotlib figure to Plotly"}, {"location": "computer_science/programming/python/plotly/#dash", "text": "Dash is a productive Python framework for building web analytic applications.", "title": "Dash"}, {"location": "computer_science/programming/python/plotly/#configuration", "text": "", "title": "Configuration"}, {"location": "computer_science/programming/python/plotly/#reverse-proxy", "text": "There might be issues with the request URLs if the app is served under a non-root directory of a domain (e.g., domain.tld/dashboard/ ). This is because Dash uses some absolute paths by default. Use the following configuration to avoid this issues: app = dash . Dash ( __name__ ) app . config . update ( { \"routes_pathname_prefix\" : \"\" , # default is / \"requests_pathname_prefix\" : \"/ {path} /\" , } ) Then if you use NGINX: location / { path}/ { proxy_pass http://127.0.0.1: { binded_port}/ ; }", "title": "Reverse proxy"}, {"location": "computer_science/programming/python/plotly/#interactive-visualizations", "text": "The dash_core_components library includes a component called Graph . Graph renders interactive data visualizations using the open source plotly.js JavaScript graphing library. plotly.js supports over 35 chart types and renders charts in both vector-quality SVG and high-performance WebGL. The figure argument in the dash_core_components.Graph component is the same figure argument that is used by plotly.py . Dash components are described declaratively by a set of attributes. All of these attributes can be updated by callback functions, but only a subset of these attributes are updated through user interaction, such as when you click on an option in a dcc.Dropdown component and the value property of tha component changes. The dcc.Graph component has four attributes that can change through user-interaction: hoverData , clickData , selectedData , relayoutData .", "title": "Interactive visualizations"}, {"location": "computer_science/programming/python/psycopg2/", "text": "Usage \u2691 Dynamic SQL generation \u2691 To replace parts of an SQL query with variables, there are three main ways of doing it: SQL query string formatting (e.g., \"SELECT * FROM table WHERE id = {id}\".format(id=42) ): DON'T . This can potentially lead to SQL injections. cursor.execute vars : Use this option when replacing values that aren't column names or similar. For example: cur . execute ( \"insert into table values ( %s , %s )\" , [ 10 , 20 ]) psycopg2.sql : this module will allow you to generate SQL statements on the fly, separating clearly the changing parts of the statement from the query parameters. Example: from psycopg2 import sql cur . execute ( sql . SQL ( \"insert into {} values ( %s , %s )\" ) . format ( sql . Identifier ( 'table' )), [ 10 , 20 ]) If part of your query is a variable sequence of arguments, such as a comma-separated list of field names, you can use the SQL.join() method to pass them to the query: query = sql . SQL ( \"select {fields} from {table} \" ) . format ( fields = sql . SQL ( ',' ) . join ([ sql . Identifier ( 'field1' ), sql . Identifier ( 'field2' ), sql . Identifier ( 'field3' ), ]), table = sql . Identifier ( 'some_table' ))", "title": "psycopg2"}, {"location": "computer_science/programming/python/psycopg2/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/programming/python/psycopg2/#dynamic-sql-generation", "text": "To replace parts of an SQL query with variables, there are three main ways of doing it: SQL query string formatting (e.g., \"SELECT * FROM table WHERE id = {id}\".format(id=42) ): DON'T . This can potentially lead to SQL injections. cursor.execute vars : Use this option when replacing values that aren't column names or similar. For example: cur . execute ( \"insert into table values ( %s , %s )\" , [ 10 , 20 ]) psycopg2.sql : this module will allow you to generate SQL statements on the fly, separating clearly the changing parts of the statement from the query parameters. Example: from psycopg2 import sql cur . execute ( sql . SQL ( \"insert into {} values ( %s , %s )\" ) . format ( sql . Identifier ( 'table' )), [ 10 , 20 ]) If part of your query is a variable sequence of arguments, such as a comma-separated list of field names, you can use the SQL.join() method to pass them to the query: query = sql . SQL ( \"select {fields} from {table} \" ) . format ( fields = sql . SQL ( ',' ) . join ([ sql . Identifier ( 'field1' ), sql . Identifier ( 'field2' ), sql . Identifier ( 'field3' ), ]), table = sql . Identifier ( 'some_table' ))", "title": "Dynamic SQL generation"}, {"location": "computer_science/programming/python/pydantic/", "text": "pydantic : data validation and settings management using python type annotations. Enforces type hints at runtime, and provides user friendly errors when data is invalid. Usage \u2691 The most basic example is: from datetime import datetime from typing import List , Optional from pydantic import BaseModel class User ( BaseModel ): id : int name = 'John Doe' signup_ts : Optional [ datetime ] = None friends : List [ int ] = [] external_data = { 'id' : '123' , 'signup_ts' : '2019-06-01 12:22' , 'friends' : [ 1 , 2 , '3' ], } user = User ( ** external_data ) print ( user . id ) #> 123 print ( repr ( user . signup_ts )) #> datetime.datetime(2019, 6, 1, 12, 22) print ( user . friends ) #> [1, 2, 3] print ( user . dict ()) \"\"\" { 'id': 123, 'signup_ts': datetime.datetime(2019, 6, 1, 12, 22), 'friends': [1, 2, 3], 'name': 'John Doe', } \"\"\" What's going on here: id is of type int ; the annotation-only declaration tells pydantic that this field is required. Strings, bytes or floats will be coerced to ints if possible; otherwise an exception will be raised. name is inferred as a string from the provided default; because it has a default, it is not required. signup_ts is a datetime field which is not required (and takes the value Nonei if it's not supplied). pydantic will process either a unix timestamp int (e.g. 1496498400) or a string representing the date & time. friends uses python's typing system, and requires a list of integers. As with id , integer-like objects will be converted to integers. If validation fails pydantic will raise an error with a breakdown of what was wrong. Validators \u2691 Custom validation and complex relationships between objects can be achieved using the validator decorator. Example: from pydantic import BaseModel , validator class UserModel ( BaseModel ): name : str username : str password1 : str password2 : str @validator ( 'name' ) def name_must_contain_space ( cls , v ): if ' ' not in v : raise ValueError ( 'must contain a space' ) return v . title () The validation function will get the variable name value and can perform checks or transformations to it. It should finally return the desired value for the variable. You can use validators to set the value of an attribute as a combination of others if undefined: from typing import Optional from pydantic import BaseModel , validator class UserModel ( BaseModel ): name : str password1 : str password2 : str username : Optional [ str ] = None accepted_tos : bool = False @validator ( 'username' , pre = True , always = True ) def default_username ( cls , v , values ): if v is None : v = values [ 'name' ] return v always=True is required in this example since otherwise when username is not passed, the validator won't be executed. pre=True makes it run before any other validator so that username is defined in before other possible validations. Note that values only contains the class attributes defined before the one that is being validated. In the example above, values in the default_username validator won't contain the accepted_tos key. Root validators \u2691 Validation can also be performed on the entire model's data. You can decorate a function with @root_validator and it will get all of the values as an argument. This function should process them and raise an exception or return the desired values dictionary. For example: @root_validator def check_passwords_match ( cls , values ): pw1 , pw2 = values . get ( 'password1' ), values . get ( 'password2' ) if pw1 is not None and pw2 is not None and pw1 != pw2 : raise ValueError ( 'passwords do not match' ) return values root_validator takes pre as argument but not always , since its executed always anyways. Note : there is a bug ( #1895 ) that prevents subclasses to override the root_validator method defined in the parent class. A workaround for BaseModel subclasses is described in the issue comments but not for pydantic dataclasses. In this second case, a solution is to not define the root validator in the parent class and do it only on the child.", "title": "pydantic"}, {"location": "computer_science/programming/python/pydantic/#usage", "text": "The most basic example is: from datetime import datetime from typing import List , Optional from pydantic import BaseModel class User ( BaseModel ): id : int name = 'John Doe' signup_ts : Optional [ datetime ] = None friends : List [ int ] = [] external_data = { 'id' : '123' , 'signup_ts' : '2019-06-01 12:22' , 'friends' : [ 1 , 2 , '3' ], } user = User ( ** external_data ) print ( user . id ) #> 123 print ( repr ( user . signup_ts )) #> datetime.datetime(2019, 6, 1, 12, 22) print ( user . friends ) #> [1, 2, 3] print ( user . dict ()) \"\"\" { 'id': 123, 'signup_ts': datetime.datetime(2019, 6, 1, 12, 22), 'friends': [1, 2, 3], 'name': 'John Doe', } \"\"\" What's going on here: id is of type int ; the annotation-only declaration tells pydantic that this field is required. Strings, bytes or floats will be coerced to ints if possible; otherwise an exception will be raised. name is inferred as a string from the provided default; because it has a default, it is not required. signup_ts is a datetime field which is not required (and takes the value Nonei if it's not supplied). pydantic will process either a unix timestamp int (e.g. 1496498400) or a string representing the date & time. friends uses python's typing system, and requires a list of integers. As with id , integer-like objects will be converted to integers. If validation fails pydantic will raise an error with a breakdown of what was wrong.", "title": "Usage"}, {"location": "computer_science/programming/python/pydantic/#validators", "text": "Custom validation and complex relationships between objects can be achieved using the validator decorator. Example: from pydantic import BaseModel , validator class UserModel ( BaseModel ): name : str username : str password1 : str password2 : str @validator ( 'name' ) def name_must_contain_space ( cls , v ): if ' ' not in v : raise ValueError ( 'must contain a space' ) return v . title () The validation function will get the variable name value and can perform checks or transformations to it. It should finally return the desired value for the variable. You can use validators to set the value of an attribute as a combination of others if undefined: from typing import Optional from pydantic import BaseModel , validator class UserModel ( BaseModel ): name : str password1 : str password2 : str username : Optional [ str ] = None accepted_tos : bool = False @validator ( 'username' , pre = True , always = True ) def default_username ( cls , v , values ): if v is None : v = values [ 'name' ] return v always=True is required in this example since otherwise when username is not passed, the validator won't be executed. pre=True makes it run before any other validator so that username is defined in before other possible validations. Note that values only contains the class attributes defined before the one that is being validated. In the example above, values in the default_username validator won't contain the accepted_tos key.", "title": "Validators"}, {"location": "computer_science/programming/python/pydantic/#root-validators", "text": "Validation can also be performed on the entire model's data. You can decorate a function with @root_validator and it will get all of the values as an argument. This function should process them and raise an exception or return the desired values dictionary. For example: @root_validator def check_passwords_match ( cls , values ): pw1 , pw2 = values . get ( 'password1' ), values . get ( 'password2' ) if pw1 is not None and pw2 is not None and pw1 != pw2 : raise ValueError ( 'passwords do not match' ) return values root_validator takes pre as argument but not always , since its executed always anyways. Note : there is a bug ( #1895 ) that prevents subclasses to override the root_validator method defined in the parent class. A workaround for BaseModel subclasses is described in the issue comments but not for pydantic dataclasses. In this second case, a solution is to not define the root validator in the parent class and do it only on the child.", "title": "Root validators"}, {"location": "computer_science/programming/python/pytelegrambotapi/", "text": "eternnoir/pyTelegramBotAPI is a A simple, but extensible Python implementation for the Telegram Bot API . Tips \u2691 Get chat id \u2691 To get the (group) chat id of the (group) chat that has a conversation with the bot, check https://api.telegram.org/bot[bot_token]/getUpdates .", "title": "pyTelegramBotAPI"}, {"location": "computer_science/programming/python/pytelegrambotapi/#tips", "text": "", "title": "Tips"}, {"location": "computer_science/programming/python/pytelegrambotapi/#get-chat-id", "text": "To get the (group) chat id of the (group) chat that has a conversation with the bot, check https://api.telegram.org/bot[bot_token]/getUpdates .", "title": "Get chat id"}, {"location": "computer_science/programming/python/pytest/", "text": "Usage \u2691 Invoke with python -m pytest so that the current directory is included to the python path. Execute just one test or test class \u2691 pytest test_server . py :: TestClass :: test_method or pytest test_server . py :: TestClass Coverage \u2691 To see which parts of your code are executed when running the tests, you can use Coverage.py . You can install it with pip install coverage . The basic usage is: coverage run --source ={{ path }} -m pytest coverage report -m # view report summary in the command-line coverage html # generate detailed report in htmlcov/index.html 100% coverage doesn't mean that all the code is tested, it means that all the code was executed at least once while running the tests. 100% coverage is necessary but not sufficient for ensuring that all code is tested. Reference \u2691 Parametrization \u2691 To run the same test several times with different variables use @pytest.mark.parametrize() . import pytest @pytest . mark . parametrize ( \"test_input,expected\" , [( \"3+5\" , 8 ), ( \"2+4\" , 6 ), ( \"6*9\" , 42 )]) def test_eval ( test_input , expected ): assert eval ( test_input ) == expected Mocking \u2691 monkeypatch \u2691 Sometimes tests need to invoke functionality which depends on global settings or which invokes code which cannot be easily tested such as network access. The monkeypatch fixture helps you to safely set/delete an attribute, dictionary item or environment variable, or to modify sys.path for importing. You need to add monkeypatch as an argument to the test functions. Environment variables \u2691 monkeypatch . setenv ( name , value , prepend = None ) Fixtures \u2691 To run a custom function for every test in a class do: class TestClass : @pytest . fixture ( autouse = True ) def setup ( self ): self . variable = 42 def test_something ( self ): ... capfd \u2691 Capture stdout/stderr output. Example: def test_foo ( capfd ): foo () # Writes \"Hello World!\" to stdout out , err = capfd . readouterr () assert out == \"Hello World!\"", "title": "pytest"}, {"location": "computer_science/programming/python/pytest/#usage", "text": "Invoke with python -m pytest so that the current directory is included to the python path.", "title": "Usage"}, {"location": "computer_science/programming/python/pytest/#execute-just-one-test-or-test-class", "text": "pytest test_server . py :: TestClass :: test_method or pytest test_server . py :: TestClass", "title": "Execute just one test or test class"}, {"location": "computer_science/programming/python/pytest/#coverage", "text": "To see which parts of your code are executed when running the tests, you can use Coverage.py . You can install it with pip install coverage . The basic usage is: coverage run --source ={{ path }} -m pytest coverage report -m # view report summary in the command-line coverage html # generate detailed report in htmlcov/index.html 100% coverage doesn't mean that all the code is tested, it means that all the code was executed at least once while running the tests. 100% coverage is necessary but not sufficient for ensuring that all code is tested.", "title": "Coverage"}, {"location": "computer_science/programming/python/pytest/#reference", "text": "", "title": "Reference"}, {"location": "computer_science/programming/python/pytest/#parametrization", "text": "To run the same test several times with different variables use @pytest.mark.parametrize() . import pytest @pytest . mark . parametrize ( \"test_input,expected\" , [( \"3+5\" , 8 ), ( \"2+4\" , 6 ), ( \"6*9\" , 42 )]) def test_eval ( test_input , expected ): assert eval ( test_input ) == expected", "title": "Parametrization"}, {"location": "computer_science/programming/python/pytest/#mocking", "text": "", "title": "Mocking"}, {"location": "computer_science/programming/python/pytest/#monkeypatch", "text": "Sometimes tests need to invoke functionality which depends on global settings or which invokes code which cannot be easily tested such as network access. The monkeypatch fixture helps you to safely set/delete an attribute, dictionary item or environment variable, or to modify sys.path for importing. You need to add monkeypatch as an argument to the test functions.", "title": "monkeypatch"}, {"location": "computer_science/programming/python/pytest/#environment-variables", "text": "monkeypatch . setenv ( name , value , prepend = None )", "title": "Environment variables"}, {"location": "computer_science/programming/python/pytest/#fixtures", "text": "To run a custom function for every test in a class do: class TestClass : @pytest . fixture ( autouse = True ) def setup ( self ): self . variable = 42 def test_something ( self ): ...", "title": "Fixtures"}, {"location": "computer_science/programming/python/pytest/#capfd", "text": "Capture stdout/stderr output. Example: def test_foo ( capfd ): foo () # Writes \"Hello World!\" to stdout out , err = capfd . readouterr () assert out == \"Hello World!\"", "title": "capfd"}, {"location": "computer_science/programming/python/re/", "text": "re provides regular expression matching operations similar to those found in Perl. Usage \u2691 Split \u2691 To split a string by multiple delimiters, you can do: import re re . split ( '; |, ' , \"string\" )", "title": "re"}, {"location": "computer_science/programming/python/re/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/programming/python/re/#split", "text": "To split a string by multiple delimiters, you can do: import re re . split ( '; |, ' , \"string\" )", "title": "Split"}, {"location": "computer_science/programming/python/requests/", "text": "Requests is an elegant and simple HTTP library for Python, built for human beings. Usage \u2691 Make a request \u2691 import requests r = requests . get ( 'https://api.github.com/events' ) r . text r . json ()", "title": "requests"}, {"location": "computer_science/programming/python/requests/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/programming/python/requests/#make-a-request", "text": "import requests r = requests . get ( 'https://api.github.com/events' ) r . text r . json ()", "title": "Make a request"}, {"location": "computer_science/programming/python/snippets/", "text": "Header \u2691 This header should go on top of python scripts. #!/usr/bin/env python3 # -*- coding: utf-8 -*- \"\"\"docstring\"\"\" __version__ = \"0.0.1a\" __author__ = \"author\" __copyright__ = \"Copyright\" __credits__ = [ \"author\" ] __license__ = \"GPL3\" __maintainer__ = \"maintainer\" __email__ = \"email\" __status__ = \"Alpha\" Basic operations \u2691 Find first element in dictionary that satisfies a condition \u2691 next ( item for item in { dict } if {{ condition }}) I/O \u2691 Create a directory if it doesn't exist \u2691 import os dir_path = ' {dir_path} ' if not os . path . exists ( dir_path ): os . makedirs ( dir_path ) Network \u2691 Download a file \u2691 To download a file from a URL do: import urllib.request urllib . request . urlretrieve ( ' {url} ' , ' {destination_path} ' ) Useful data \u2691 Weekdays \u2691 Weekdays = IntEnum ( \"Weekdays\" , \"Monday Tuesday Wednesday Thursday Friday Saturday Sunday\" , start = 0 , )", "title": "Snippets"}, {"location": "computer_science/programming/python/snippets/#header", "text": "This header should go on top of python scripts. #!/usr/bin/env python3 # -*- coding: utf-8 -*- \"\"\"docstring\"\"\" __version__ = \"0.0.1a\" __author__ = \"author\" __copyright__ = \"Copyright\" __credits__ = [ \"author\" ] __license__ = \"GPL3\" __maintainer__ = \"maintainer\" __email__ = \"email\" __status__ = \"Alpha\"", "title": "Header"}, {"location": "computer_science/programming/python/snippets/#basic-operations", "text": "", "title": "Basic operations"}, {"location": "computer_science/programming/python/snippets/#find-first-element-in-dictionary-that-satisfies-a-condition", "text": "next ( item for item in { dict } if {{ condition }})", "title": "Find first element  in dictionary that satisfies a condition"}, {"location": "computer_science/programming/python/snippets/#io", "text": "", "title": "I/O"}, {"location": "computer_science/programming/python/snippets/#create-a-directory-if-it-doesnt-exist", "text": "import os dir_path = ' {dir_path} ' if not os . path . exists ( dir_path ): os . makedirs ( dir_path )", "title": "Create a directory if it doesn't exist"}, {"location": "computer_science/programming/python/snippets/#network", "text": "", "title": "Network"}, {"location": "computer_science/programming/python/snippets/#download-a-file", "text": "To download a file from a URL do: import urllib.request urllib . request . urlretrieve ( ' {url} ' , ' {destination_path} ' )", "title": "Download a file"}, {"location": "computer_science/programming/python/snippets/#useful-data", "text": "", "title": "Useful data"}, {"location": "computer_science/programming/python/snippets/#weekdays", "text": "Weekdays = IntEnum ( \"Weekdays\" , \"Monday Tuesday Wednesday Thursday Friday Saturday Sunday\" , start = 0 , )", "title": "Weekdays"}, {"location": "computer_science/programming/python/statsmodels/", "text": "statsmodels is a Python module that provides classes and functions for the estimation of many different statistical models, as well as for conducting statistical tests, and statistical data exploration. Usage \u2691 Linear regression \u2691 Using Ordinary Least Squares. import statsmodels.api as sm Y = [ 1 , 2 ] X = [ 0 , 1 ] X = sm . add_constant ( X ) model = sm . OLS ( Y , X ) results = model . fit () results . summary () As expected the resulting coefficients are 1 for the constant and 1 for \\(X\\) : \\[ Y = 1 + X \\]", "title": "statsmodels"}, {"location": "computer_science/programming/python/statsmodels/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/programming/python/statsmodels/#linear-regression", "text": "Using Ordinary Least Squares. import statsmodels.api as sm Y = [ 1 , 2 ] X = [ 0 , 1 ] X = sm . add_constant ( X ) model = sm . OLS ( Y , X ) results = model . fit () results . summary () As expected the resulting coefficients are 1 for the constant and 1 for \\(X\\) : \\[ Y = 1 + X \\]", "title": "Linear regression"}, {"location": "computer_science/programming/python/style/", "text": "PEP-8 \u2691 PEP-8 is a style guide for Python code. Indentation \u2691 Use 4 spaces as the TAB length as stated by pep-8 - Long strings \u2691 Implicit concatenation might be the cleanest solution: s = \"this is my really, really, really, really, really, really,\" \\ \" really long string that I'd like to shorten.\" Packages \u2691 pprint \u2691 pprint is a Python module provides a capability to \u201cpretty-print\u201d arbitrary Python data structures in a form which can be used as input to the interpreter. import pprint things = [ a , b , c ] pprint . pprint ( things ) The documentation can be found here .", "title": "Style"}, {"location": "computer_science/programming/python/style/#pep-8", "text": "PEP-8 is a style guide for Python code.", "title": "PEP-8"}, {"location": "computer_science/programming/python/style/#indentation", "text": "Use 4 spaces as the TAB length as stated by pep-8 -", "title": "Indentation"}, {"location": "computer_science/programming/python/style/#long-strings", "text": "Implicit concatenation might be the cleanest solution: s = \"this is my really, really, really, really, really, really,\" \\ \" really long string that I'd like to shorten.\"", "title": "Long strings"}, {"location": "computer_science/programming/python/style/#packages", "text": "", "title": "Packages"}, {"location": "computer_science/programming/python/style/#pprint", "text": "pprint is a Python module provides a capability to \u201cpretty-print\u201d arbitrary Python data structures in a form which can be used as input to the interpreter. import pprint things = [ a , b , c ] pprint . pprint ( things ) The documentation can be found here .", "title": "pprint"}, {"location": "computer_science/programming/python/tenacity/", "text": "jd/tenacity is a retrying library for Python. Usage \u2691 Try a maximum of n times with exponential wait time between attempts \u2691 from tenacity import retry , stop_after_attempt , wait_exponential @retry ( stop = stop_after_attempt ( 3 ), wait = wait_exponential ( multiplier = 0.1 )) def somefunction (): raise Exception The function will be retried a maximum of 3 times, waiting 0.1 s, 0.2 s and 0.4 s between each attempt respectively. Catch only some kind of errors \u2691 Use @retry(retry=retry_if_exception_type(IOError)) . Several types of exceptions can be combined as follows: @retry ( retry = ( retry_if_exception_type ( IOError ) | retry_if_exception_type ( TimeoutError )))", "title": "Tenacity"}, {"location": "computer_science/programming/python/tenacity/#usage", "text": "", "title": "Usage"}, {"location": "computer_science/programming/python/tenacity/#try-a-maximum-of-n-times-with-exponential-wait-time-between-attempts", "text": "from tenacity import retry , stop_after_attempt , wait_exponential @retry ( stop = stop_after_attempt ( 3 ), wait = wait_exponential ( multiplier = 0.1 )) def somefunction (): raise Exception The function will be retried a maximum of 3 times, waiting 0.1 s, 0.2 s and 0.4 s between each attempt respectively.", "title": "Try a maximum of n times with exponential wait time between attempts"}, {"location": "computer_science/programming/python/tenacity/#catch-only-some-kind-of-errors", "text": "Use @retry(retry=retry_if_exception_type(IOError)) . Several types of exceptions can be combined as follows: @retry ( retry = ( retry_if_exception_type ( IOError ) | retry_if_exception_type ( TimeoutError )))", "title": "Catch only some kind of errors"}, {"location": "computer_science/programming/python/typing/", "text": "Since Python 3.5, type hints are supported. Note that the Python runtime does not enforce function and variable type annotations but they can be used by third party tools such as type checkers, IDEs, linters, etc. Usage \u2691 When defining a function, the syntax to specify the type of an argument and its default value, which is optional, is {arg_name}: {arg_type} = {arg_default_value} . The return type can also by specified. Let's see an example: def greeting ( name : str ) -> str : return 'Hello ' + name Type aliases \u2691 A type alias is defined by assigning the type to the alias. For example: import pandas as pd import networkx as nx # Type aliases Series = pd . core . series . Series DataFrame = pd . core . frame . DataFrame Graph = nx . classes . graph . Graph Types \u2691 Common types from typing : Type[Class] : Accepts instances of the Class and the Class itself.", "title": "Typing"}, {"location": "computer_science/programming/python/typing/#usage", "text": "When defining a function, the syntax to specify the type of an argument and its default value, which is optional, is {arg_name}: {arg_type} = {arg_default_value} . The return type can also by specified. Let's see an example: def greeting ( name : str ) -> str : return 'Hello ' + name", "title": "Usage"}, {"location": "computer_science/programming/python/typing/#type-aliases", "text": "A type alias is defined by assigning the type to the alias. For example: import pandas as pd import networkx as nx # Type aliases Series = pd . core . series . Series DataFrame = pd . core . frame . DataFrame Graph = nx . classes . graph . Graph", "title": "Type aliases"}, {"location": "computer_science/programming/python/typing/#types", "text": "Common types from typing : Type[Class] : Accepts instances of the Class and the Class itself.", "title": "Types"}, {"location": "computer_science/programming/python/unittest/", "text": "The unittest unit testing framework was originally inspired by JUnit and has a similar flavor as major unit testing frameworks in other languages. It supports test automation, sharing of setup and shutdown code for tests, aggregation of tests into collections, and independence of the tests from the reporting framework. Mock \u2691 unittest.mock is a library for testing in Python. It allows you to replace parts of your system under test with mock objects and make assertions about how they have been used. Usage \u2691 First, from unittest.mock import patch . Then set the appropriate decorator for the function and expect a new argument related to the mock object. This object will have methods such as: assert_called : assert that the mock was called at least once. assert_called_once : assert that the mock was called exactly once. assert_called_with : asserts that the last call has been made in a particular way. assert_called_once_with : assert that the mock was called exactly once and that call was with the specified arguments. And attributes such as: call_args : either None (if the mock hasn't been called), or the arguments that the mock was last called with. Function \u2691 Use @patch(\"{{function}}\", {{return_value}}) . Class Method \u2691 Use @patch.object({{class}}, {{method}}, return_value={{return_value}}) . For example: @patch . object ( SomeClass , 'class_method' ) def test ( mock_method ): SomeClass . class_method ( 3 ) mock_method . assert_called_with ( 3 ) test () Abstract class \u2691 To patch an abstract class to be able to instantiate it, without having to create a fake class that inherits from it, you can patch it as follows: @patch . object ( MyAbcClass , '__abstractmethods__' , set ()) or if you want to patch some attributes and/or methods at the same time: @patch . multiple ( MyAbcClass , __abstractmethods__ = set ())", "title": "unittest"}, {"location": "computer_science/programming/python/unittest/#mock", "text": "unittest.mock is a library for testing in Python. It allows you to replace parts of your system under test with mock objects and make assertions about how they have been used.", "title": "Mock"}, {"location": "computer_science/programming/python/unittest/#usage", "text": "First, from unittest.mock import patch . Then set the appropriate decorator for the function and expect a new argument related to the mock object. This object will have methods such as: assert_called : assert that the mock was called at least once. assert_called_once : assert that the mock was called exactly once. assert_called_with : asserts that the last call has been made in a particular way. assert_called_once_with : assert that the mock was called exactly once and that call was with the specified arguments. And attributes such as: call_args : either None (if the mock hasn't been called), or the arguments that the mock was last called with.", "title": "Usage"}, {"location": "computer_science/programming/python/unittest/#function", "text": "Use @patch(\"{{function}}\", {{return_value}}) .", "title": "Function"}, {"location": "computer_science/programming/python/unittest/#class-method", "text": "Use @patch.object({{class}}, {{method}}, return_value={{return_value}}) . For example: @patch . object ( SomeClass , 'class_method' ) def test ( mock_method ): SomeClass . class_method ( 3 ) mock_method . assert_called_with ( 3 ) test ()", "title": "Class Method"}, {"location": "computer_science/programming/python/unittest/#abstract-class", "text": "To patch an abstract class to be able to instantiate it, without having to create a fake class that inherits from it, you can patch it as follows: @patch . object ( MyAbcClass , '__abstractmethods__' , set ()) or if you want to patch some attributes and/or methods at the same time: @patch . multiple ( MyAbcClass , __abstractmethods__ = set ())", "title": "Abstract class"}, {"location": "computer_science/windows/wintousb/", "text": "WinToUSB is a Windows To Go (WTG) creator. It is not open source, it has a free (of charge) version. It is distributed as a Windows executable. As of now, I couldn't find any open source alternatives to it. Usage \u2691 Download WinToUSB . Install it. Download the W10 ISO . Run it and follow the steps. I generally choose the GPT+UEFI installation option. The installation will take a long time (maybe more than an hour). Fuck winbugs.", "title": "WinToUSB"}, {"location": "computer_science/windows/wintousb/#usage", "text": "Download WinToUSB . Install it. Download the W10 ISO . Run it and follow the steps. I generally choose the GPT+UEFI installation option. The installation will take a long time (maybe more than an hour). Fuck winbugs.", "title": "Usage"}, {"location": "cooking/recipes/cheesecake/", "text": "This is a basic sweet cheesecake with a layer of scrambled cookies on the bottom recipe. Summary \u2691 30 minutes preparation and 30 minutes cooking. Requires an oven. Ingredients \u2691 For 8 portions. For the cake mix: 3 eggs. 180 g of sugar. 400 g of cream cheese. 200 mL of cream. A tablespoon of wheat or corn flour. A bit of sweetened condensed milk. A bit of vanilla extract or pods. A pinch of salt. For the cookie layer: 200 g of cookies. 50 g of butter. Preparation \u2691 Preheat the oven at 200 \u00ba C with the fan on. Smash the cookies and mix them with the melted butter. Cover a baking tin with baking foil. Spread and press the cookies and butter mix on the bottom of the tin. Mix the rest of the ingredients and put them on top of the cookie layer. Bake for 20-30 minutes, as desired. Tips \u2691 Wet the baking paper with water so the cake doesn't stick to it. Pay close attention to the last minutes of the baking process to take it out whenever it reaches your cooking point preference. It gets \"solid\" pretty fast. The cookie layer has a better texture and bite when cold.", "title": "Cheesecake"}, {"location": "cooking/recipes/cheesecake/#summary", "text": "30 minutes preparation and 30 minutes cooking. Requires an oven.", "title": "Summary"}, {"location": "cooking/recipes/cheesecake/#ingredients", "text": "For 8 portions. For the cake mix: 3 eggs. 180 g of sugar. 400 g of cream cheese. 200 mL of cream. A tablespoon of wheat or corn flour. A bit of sweetened condensed milk. A bit of vanilla extract or pods. A pinch of salt. For the cookie layer: 200 g of cookies. 50 g of butter.", "title": "Ingredients"}, {"location": "cooking/recipes/cheesecake/#preparation", "text": "Preheat the oven at 200 \u00ba C with the fan on. Smash the cookies and mix them with the melted butter. Cover a baking tin with baking foil. Spread and press the cookies and butter mix on the bottom of the tin. Mix the rest of the ingredients and put them on top of the cookie layer. Bake for 20-30 minutes, as desired.", "title": "Preparation"}, {"location": "cooking/recipes/cheesecake/#tips", "text": "Wet the baking paper with water so the cake doesn't stick to it. Pay close attention to the last minutes of the baking process to take it out whenever it reaches your cooking point preference. It gets \"solid\" pretty fast. The cookie layer has a better texture and bite when cold.", "title": "Tips"}, {"location": "cooking/recipes/eggplant_kebab/", "text": "Patl\u0131canl\u0131 kebap is a Turkish dish that contains mainly eggplant and meat. It is generally cooked over a fire but it can be also be prepared in the oven. Summary \u2691 1 hour preparation and 1 h cooking. Needs an oven, but could also be done over a fire. Ingredients \u2691 For 4 large servings use: 500 g of minced meat. 2 or 3 eggplants. 3 or 4 potatoes. 1 or 2 tomatoes. 1 or 2 onions. 1 or 2 peppers (green or red). A head of garlic. Vegetable oil. Salt. Ground black pepper. For serving: Yogurt (optional). Pita bread. Cooking steps \u2691 Cut the eggplants perpendicularly in slices of around 2 cm. Put the eggplant slices in cold water with salt for 30 minutes. Cut the potatoes in slices of 0.5 cm. Slightly fry or put the potatoes into the oven for a while. Mix the meat with oil, salt and ground black pepper. Form balls of the size of a walnut (~30 g each) with the meat. Drain the eggplant slices. On a large oven container, cover the bottom with the potatoes and on top of that, alternate eggplant slices and meat balls forming a cylinder. Put the garlic head, the onions and tomatoes in halves and the peppers into the container. Put salt and pepper on top of everything. Cover the container with aluminum foil and start cooking it in the oven at 180\u00ba C for 30 minutes. Uncover the container and keep cooking until the top is roasted. Afiyet olsun! (enjoy your meal!) Tips \u2691 Choose small eggplants that don't have many seeds inside yet. Bake or fry the eggplant slices before putting everything together. You can also put spicy pepper flakes on top. Eat it with bread and yogurt.", "title": "Eggplant kebab"}, {"location": "cooking/recipes/eggplant_kebab/#summary", "text": "1 hour preparation and 1 h cooking. Needs an oven, but could also be done over a fire.", "title": "Summary"}, {"location": "cooking/recipes/eggplant_kebab/#ingredients", "text": "For 4 large servings use: 500 g of minced meat. 2 or 3 eggplants. 3 or 4 potatoes. 1 or 2 tomatoes. 1 or 2 onions. 1 or 2 peppers (green or red). A head of garlic. Vegetable oil. Salt. Ground black pepper. For serving: Yogurt (optional). Pita bread.", "title": "Ingredients"}, {"location": "cooking/recipes/eggplant_kebab/#cooking-steps", "text": "Cut the eggplants perpendicularly in slices of around 2 cm. Put the eggplant slices in cold water with salt for 30 minutes. Cut the potatoes in slices of 0.5 cm. Slightly fry or put the potatoes into the oven for a while. Mix the meat with oil, salt and ground black pepper. Form balls of the size of a walnut (~30 g each) with the meat. Drain the eggplant slices. On a large oven container, cover the bottom with the potatoes and on top of that, alternate eggplant slices and meat balls forming a cylinder. Put the garlic head, the onions and tomatoes in halves and the peppers into the container. Put salt and pepper on top of everything. Cover the container with aluminum foil and start cooking it in the oven at 180\u00ba C for 30 minutes. Uncover the container and keep cooking until the top is roasted. Afiyet olsun! (enjoy your meal!)", "title": "Cooking steps"}, {"location": "cooking/recipes/eggplant_kebab/#tips", "text": "Choose small eggplants that don't have many seeds inside yet. Bake or fry the eggplant slices before putting everything together. You can also put spicy pepper flakes on top. Eat it with bread and yogurt.", "title": "Tips"}, {"location": "cooking/recipes/red_lentil_soup/", "text": "Mercimek \u00e7orbas\u0131 is the most popular Turkish soup, made with red lentils. Summary \u2691 15 minutes preparation 30 minutes cooking. Ingredients \u2691 For 6 servings use: 3 tablespoons of oil (olive, sunflower\u2026). 1 onion. 1 carrot. 1 big potato. 1.5 cups (250 ml) of washed red lentils. 1.5 l of water. Salt and black pepper. For serving: Butter. Oil. Paprika. Lemon. Pepper flakes. Preparation \u2691 Chop and fry the onions in a pot. Chop the carrot and the potato and add them. Add the red lentils, the water, salt and pepper. Boil for 30 minutes. Bled it with a mixer. Before serving, in a pan fry butter, oil and the paprika. Be careful not to burn it. Add a bit on top of the soup. You can also add lemon juice and pepper flakes on top. Tips \u2691 You can use vegetable/chicken/meat stock mixed with water instead of water. E.g. 1 l of water 0.5 l of stock. Some people add flour for a thicker texture.", "title": "Red lentil soup"}, {"location": "cooking/recipes/red_lentil_soup/#summary", "text": "15 minutes preparation 30 minutes cooking.", "title": "Summary"}, {"location": "cooking/recipes/red_lentil_soup/#ingredients", "text": "For 6 servings use: 3 tablespoons of oil (olive, sunflower\u2026). 1 onion. 1 carrot. 1 big potato. 1.5 cups (250 ml) of washed red lentils. 1.5 l of water. Salt and black pepper. For serving: Butter. Oil. Paprika. Lemon. Pepper flakes.", "title": "Ingredients"}, {"location": "cooking/recipes/red_lentil_soup/#preparation", "text": "Chop and fry the onions in a pot. Chop the carrot and the potato and add them. Add the red lentils, the water, salt and pepper. Boil for 30 minutes. Bled it with a mixer. Before serving, in a pan fry butter, oil and the paprika. Be careful not to burn it. Add a bit on top of the soup. You can also add lemon juice and pepper flakes on top.", "title": "Preparation"}, {"location": "cooking/recipes/red_lentil_soup/#tips", "text": "You can use vegetable/chicken/meat stock mixed with water instead of water. E.g. 1 l of water 0.5 l of stock. Some people add flour for a thicker texture.", "title": "Tips"}, {"location": "countries/turkey/legal/touristic_visa/", "text": "To be able to reside in Turkey after the regular 90 day visa expires, you need a short-term residence permit. You can get it with a work permit or with some short-term visas, such as the touristic visa. This short-term visa will be given for a year at most. Note that you are not allowed to work with the touristic visa. Residence permit steps \u2691 This is the procedure to obtain a residence permit through a touristic visa from Turkey (not from abroad). Since a rental contract and other documents are required, it might be hard to arrange everything from abroad, but it's still possible. It is assumed that you are already in Turkey because you entered with the 90 day touristic visa. Get 4 biometric photos. Get a health insurance. You'll need the original stamped/sealed insurance policy. A minimum-coverage local health insurance policy will cost around 600 TL for a year. Fill the form for the immigration services appointment a Directorate General of Migration Management . Notes: Official required documents list . If the income is your savings, it's recommended to divide your saving by the number of months you are staying and fill the result as your monthly income, instead of puting just 0. video showing the form filling process. Get a photocopy of your passport including the personal information page and the page where the passport control stamp is. Get a statement on having sufficient financial means through the stay. Might not be requested. Could be bank statement of a long enough period. You can open an account in a Turkish bank, for that you will need to get your tax number (vergi numaras\u0131) from the local tax office. Get a notarized copy of your rental agreement. Wait for the appointment. A short interview will take place. If everything goes well, they will tell you to pay the residence permit fees (card and single entry fee) which add up to around 568 TL. Then you have to pay them and come back. The residence permit card will be delivered to your address of stay. Experience \u2691 I applied for the residence permit for touristic purposes for a year. I am a European citizen and this was my first application. I entered Turkey with my passport (visa exemption) on the 10/07/2021. Process \u2691 14/07/2021: Submitted the online form ( https://e-ikamet.goc.gov.tr/ ). For which I needed a house rent contract (they don't ask for it directly but they ask for the house address), a Turkish phone number, a portrait picture and a health insurance policy. 16/07/2021: I received an email informing me of the interview appointment date (05/08/2021 at 13:00). 05/08/2021: I went to the Ankara Valili\u011fi il G\u00f6\u00e7 \u0130daresi M\u00fcd\u00fcrl\u00fc\u011f\u00fc (Barbaros, Binnaz Sk. No:2, 06680 \u00c7ankaya/Ankara) and arrived there at 12:30 (half an hour early). I waited in line and told the security guy that I was early and asked if I could go in anyways. The security guy answered laughing that we all had the appointment at the same time (hundreds of people) so it was ok to go early. He then asked for my pink classifier (pembe dosya) which I had never heard of. Apparently you need to bring your documents in one of those but that rule is not written anywhere. I went down the street and bought one for 3 TL and came back, they let me in without having to wait in the line again. In the reception, some workers where checking the passports and the documents and giving some stickers with a line number. Then, we went to a waiting room where there was a screen calling line numbers. At first you shouldn't wait for your number to be called but instead fill the papers with your phone number and name which are on a table in the back. Then, you should go to the cash desk (vezne) and pay the taxes stated in the printout of the online form. The cash desk opens at one and there is no order to pay. You can only pay with cash. After this, I left that room and went upstairs where I waited for an hour to be called. I waited for my turn for the interview, where I was asked for the basic documents and had no questioning or anything like that and took around 2 minutes. I had to give the notarized copy of my rental contract, the signed form printout, 4 biometric pictures, a photocopy of my passport main page and of the page where the entry stamp was and the health insurance signed policy documents. They didn't ask for the bank statement or anything else. The whole process took 2 hours. It was really messy and people did not generally respect the line order, but the workers were generally friendly and nice. 24/08/2021: I check for the status of my application online ( https://e-ikamet.goc.gov.tr/ ) and saw that there were missing documents (didn't specify which). So I went that same day to the G\u00f6\u00e7 \u0130daresi. A worker checked the status on the computer and told me that I had to pay for the single entry visa fee. I did it and then went upstairs to the missing document issues room, where some workers looked for my folder and added the tax receipt. 03/09/2021: I checked the status of my application and it said that it had been concluded positively. 04/09/2021: I received the residence permit card at my house from PTT. I didn't get any notifications via SMS at all so its important to constantly check online for the status. I asked for the residence permit to be from 01/08/2021 to the 01/08/2022 (same as the insurance) but I got it 14/07/2021 to the 09/07/2022. Costs \u2691 Biometric pictures: 35 TL. One year basic health insurance (SOMPO SIGORTA): 85 TL. Notarized copy of the rent contract: 125 TL. Pink classifier: 3 TL. Card and residence permit taxes: 462 TL. Single entry visa: 759 TL. TOTAL : 1,469 TL I'm not including the Sim card costs (600TL for 3 months with internet) and the photocopy prices (few TL). Things to do after obtaining the residence permit \u2691 Notify my Turkish cell phone operator (updated my details from the app). Otherwise your line will be canceled after some months (source: the guy at Turkcell store). Get access to e-devlet to do bureaucracy online. Go to PTT and ask for the code, you will receive it as an SMS to your Turkish phone number. The cost is 2 TL. Go back to the G\u00f6\u00e7 \u0130daresi to register your address (yes, again). You will need to bring some utility bill registered to your name. You can also go with the person you live with if the bills are under their name and they are already registered (n\u00fcfus) at that address. If they are not registered, they can try to do it from e-devlet or go to the population directorate (n\u00fcfus m\u00fcd\u00fcrl\u00fc\u011f\u00fc). References \u2691 Residence and work visas for Turkey, Visas in Turkey", "title": "Touristic visa"}, {"location": "countries/turkey/legal/touristic_visa/#residence-permit-steps", "text": "This is the procedure to obtain a residence permit through a touristic visa from Turkey (not from abroad). Since a rental contract and other documents are required, it might be hard to arrange everything from abroad, but it's still possible. It is assumed that you are already in Turkey because you entered with the 90 day touristic visa. Get 4 biometric photos. Get a health insurance. You'll need the original stamped/sealed insurance policy. A minimum-coverage local health insurance policy will cost around 600 TL for a year. Fill the form for the immigration services appointment a Directorate General of Migration Management . Notes: Official required documents list . If the income is your savings, it's recommended to divide your saving by the number of months you are staying and fill the result as your monthly income, instead of puting just 0. video showing the form filling process. Get a photocopy of your passport including the personal information page and the page where the passport control stamp is. Get a statement on having sufficient financial means through the stay. Might not be requested. Could be bank statement of a long enough period. You can open an account in a Turkish bank, for that you will need to get your tax number (vergi numaras\u0131) from the local tax office. Get a notarized copy of your rental agreement. Wait for the appointment. A short interview will take place. If everything goes well, they will tell you to pay the residence permit fees (card and single entry fee) which add up to around 568 TL. Then you have to pay them and come back. The residence permit card will be delivered to your address of stay.", "title": "Residence permit steps"}, {"location": "countries/turkey/legal/touristic_visa/#experience", "text": "I applied for the residence permit for touristic purposes for a year. I am a European citizen and this was my first application. I entered Turkey with my passport (visa exemption) on the 10/07/2021.", "title": "Experience"}, {"location": "countries/turkey/legal/touristic_visa/#process", "text": "14/07/2021: Submitted the online form ( https://e-ikamet.goc.gov.tr/ ). For which I needed a house rent contract (they don't ask for it directly but they ask for the house address), a Turkish phone number, a portrait picture and a health insurance policy. 16/07/2021: I received an email informing me of the interview appointment date (05/08/2021 at 13:00). 05/08/2021: I went to the Ankara Valili\u011fi il G\u00f6\u00e7 \u0130daresi M\u00fcd\u00fcrl\u00fc\u011f\u00fc (Barbaros, Binnaz Sk. No:2, 06680 \u00c7ankaya/Ankara) and arrived there at 12:30 (half an hour early). I waited in line and told the security guy that I was early and asked if I could go in anyways. The security guy answered laughing that we all had the appointment at the same time (hundreds of people) so it was ok to go early. He then asked for my pink classifier (pembe dosya) which I had never heard of. Apparently you need to bring your documents in one of those but that rule is not written anywhere. I went down the street and bought one for 3 TL and came back, they let me in without having to wait in the line again. In the reception, some workers where checking the passports and the documents and giving some stickers with a line number. Then, we went to a waiting room where there was a screen calling line numbers. At first you shouldn't wait for your number to be called but instead fill the papers with your phone number and name which are on a table in the back. Then, you should go to the cash desk (vezne) and pay the taxes stated in the printout of the online form. The cash desk opens at one and there is no order to pay. You can only pay with cash. After this, I left that room and went upstairs where I waited for an hour to be called. I waited for my turn for the interview, where I was asked for the basic documents and had no questioning or anything like that and took around 2 minutes. I had to give the notarized copy of my rental contract, the signed form printout, 4 biometric pictures, a photocopy of my passport main page and of the page where the entry stamp was and the health insurance signed policy documents. They didn't ask for the bank statement or anything else. The whole process took 2 hours. It was really messy and people did not generally respect the line order, but the workers were generally friendly and nice. 24/08/2021: I check for the status of my application online ( https://e-ikamet.goc.gov.tr/ ) and saw that there were missing documents (didn't specify which). So I went that same day to the G\u00f6\u00e7 \u0130daresi. A worker checked the status on the computer and told me that I had to pay for the single entry visa fee. I did it and then went upstairs to the missing document issues room, where some workers looked for my folder and added the tax receipt. 03/09/2021: I checked the status of my application and it said that it had been concluded positively. 04/09/2021: I received the residence permit card at my house from PTT. I didn't get any notifications via SMS at all so its important to constantly check online for the status. I asked for the residence permit to be from 01/08/2021 to the 01/08/2022 (same as the insurance) but I got it 14/07/2021 to the 09/07/2022.", "title": "Process"}, {"location": "countries/turkey/legal/touristic_visa/#costs", "text": "Biometric pictures: 35 TL. One year basic health insurance (SOMPO SIGORTA): 85 TL. Notarized copy of the rent contract: 125 TL. Pink classifier: 3 TL. Card and residence permit taxes: 462 TL. Single entry visa: 759 TL. TOTAL : 1,469 TL I'm not including the Sim card costs (600TL for 3 months with internet) and the photocopy prices (few TL).", "title": "Costs"}, {"location": "countries/turkey/legal/touristic_visa/#things-to-do-after-obtaining-the-residence-permit", "text": "Notify my Turkish cell phone operator (updated my details from the app). Otherwise your line will be canceled after some months (source: the guy at Turkcell store). Get access to e-devlet to do bureaucracy online. Go to PTT and ask for the code, you will receive it as an SMS to your Turkish phone number. The cost is 2 TL. Go back to the G\u00f6\u00e7 \u0130daresi to register your address (yes, again). You will need to bring some utility bill registered to your name. You can also go with the person you live with if the bills are under their name and they are already registered (n\u00fcfus) at that address. If they are not registered, they can try to do it from e-devlet or go to the population directorate (n\u00fcfus m\u00fcd\u00fcrl\u00fc\u011f\u00fc).", "title": "Things to do after obtaining the residence permit"}, {"location": "countries/turkey/legal/touristic_visa/#references", "text": "Residence and work visas for Turkey, Visas in Turkey", "title": "References"}, {"location": "countries/turkey/legal/work/", "text": "Work permit \u2691 As a foreigner, you will need a Work Permit to work and live in Turkey. Exceptions \u2691 According to Article 8e of Law No. 4817 about work permit for foreigners: \" [...] working permission may be given [...] to citizens of the countries that are a member of the European Union [...] \". Note : apparently this does not apply in practice. Reference: YABANCILARIN \u00c7ALI\u015eMA \u0130Z\u0130NLER\u0130 HAKKINDA KANUN . Evaluation criteria \u2691 Employment of at least five Turkish citizens is compulsory in the workplace for which work permit is requested. The paid-in capital of the workplace must be at least 100,000 TL or the gross sales must be at least 800,000 TL or the last year's export amount must be at least 250,000 USD. The monthly wage declared to be paid to the foreigner by the employer must be: 4 times the minimum wage for engineers . 1.5 times the minimum wage for foreigners who will work in professions other than domestic. In cases requiring advanced technology or in the absence of a Turkish expert with the same qualifications, the criteria determined by the 1 st and 2 nd articles will not be applied upon the approval of the General Directorate. Reference: Uluslararas\u0131 \u0130\u015fg\u00fcc\u00fc Genel M\u00fcd\u00fcrl\u00fc\u011f\u00fc | \u00c7al\u0131\u015fma \u0130zni De\u011ferlendirme Kriterleri Process summary \u2691 Reference: Uluslararas\u0131 \u0130\u015fg\u00fcc\u00fc Genel M\u00fcd\u00fcrl\u00fc\u011f\u00fc The Ministry will take up to 30 days process the request, given that all of the required documents are provided. Reference: YABANCILARIN \u00c7ALI\u015eMA \u0130Z\u0130NLER\u0130 HAKKINDA KANUN . Within a maximum of 180 days after the date the work permit is issued the foreigner must enter into Turkey. Reference: Turkey Work Permit - Turkish Consulates . Grants \u2691 Traineeships \u2691 They cover the travel and subsistence costs. The application must be done through the university and have a Learning Agreement. Traineeships for vocational education, apprenticeships, and recent graduates | Erasmus+ R&D grants \u2691 1501 - T\u00dcB\u0130TAK Sanayi Ar-Ge Projeleri Destekleme Program\u0131 | T\u00dcRK\u0130YE B\u0130L\u0130MSEL VE TEKNOLOJ\u0130K ARA\u015eTIRMA KURUMU . The program aims to support small and medium-sized enterprises (SMEs) in the project-based research-technology development and innovation activities of organizations. 1509 Y\u00f6netmelik ve Esaslar | T\u00dcRK\u0130YE B\u0130L\u0130MSEL VE TEKNOLOJ\u0130K ARA\u015eTIRMA KURUMU . Other T\u00dcB\u0130TAK grants . Horizon 2020 . National & International Research Funding Opportunities | EURAXESS Turkey .", "title": "Work"}, {"location": "countries/turkey/legal/work/#work-permit", "text": "As a foreigner, you will need a Work Permit to work and live in Turkey.", "title": "Work permit"}, {"location": "countries/turkey/legal/work/#exceptions", "text": "According to Article 8e of Law No. 4817 about work permit for foreigners: \" [...] working permission may be given [...] to citizens of the countries that are a member of the European Union [...] \". Note : apparently this does not apply in practice. Reference: YABANCILARIN \u00c7ALI\u015eMA \u0130Z\u0130NLER\u0130 HAKKINDA KANUN .", "title": "Exceptions"}, {"location": "countries/turkey/legal/work/#evaluation-criteria", "text": "Employment of at least five Turkish citizens is compulsory in the workplace for which work permit is requested. The paid-in capital of the workplace must be at least 100,000 TL or the gross sales must be at least 800,000 TL or the last year's export amount must be at least 250,000 USD. The monthly wage declared to be paid to the foreigner by the employer must be: 4 times the minimum wage for engineers . 1.5 times the minimum wage for foreigners who will work in professions other than domestic. In cases requiring advanced technology or in the absence of a Turkish expert with the same qualifications, the criteria determined by the 1 st and 2 nd articles will not be applied upon the approval of the General Directorate. Reference: Uluslararas\u0131 \u0130\u015fg\u00fcc\u00fc Genel M\u00fcd\u00fcrl\u00fc\u011f\u00fc | \u00c7al\u0131\u015fma \u0130zni De\u011ferlendirme Kriterleri", "title": "Evaluation criteria"}, {"location": "countries/turkey/legal/work/#process-summary", "text": "Reference: Uluslararas\u0131 \u0130\u015fg\u00fcc\u00fc Genel M\u00fcd\u00fcrl\u00fc\u011f\u00fc The Ministry will take up to 30 days process the request, given that all of the required documents are provided. Reference: YABANCILARIN \u00c7ALI\u015eMA \u0130Z\u0130NLER\u0130 HAKKINDA KANUN . Within a maximum of 180 days after the date the work permit is issued the foreigner must enter into Turkey. Reference: Turkey Work Permit - Turkish Consulates .", "title": "Process summary"}, {"location": "countries/turkey/legal/work/#grants", "text": "", "title": "Grants"}, {"location": "countries/turkey/legal/work/#traineeships", "text": "They cover the travel and subsistence costs. The application must be done through the university and have a Learning Agreement. Traineeships for vocational education, apprenticeships, and recent graduates | Erasmus+", "title": "Traineeships"}, {"location": "countries/turkey/legal/work/#rd-grants", "text": "1501 - T\u00dcB\u0130TAK Sanayi Ar-Ge Projeleri Destekleme Program\u0131 | T\u00dcRK\u0130YE B\u0130L\u0130MSEL VE TEKNOLOJ\u0130K ARA\u015eTIRMA KURUMU . The program aims to support small and medium-sized enterprises (SMEs) in the project-based research-technology development and innovation activities of organizations. 1509 Y\u00f6netmelik ve Esaslar | T\u00dcRK\u0130YE B\u0130L\u0130MSEL VE TEKNOLOJ\u0130K ARA\u015eTIRMA KURUMU . Other T\u00dcB\u0130TAK grants . Horizon 2020 . National & International Research Funding Opportunities | EURAXESS Turkey .", "title": "R&amp;D grants"}, {"location": "countries/turkey/places/ankara/", "text": "Mogan lake (Mogan G\u00f6l\u00fc) \u2691 This lake is 25 km south of Ankara city and its reachable by public transport. It is located in the G\u00f6lba\u015f\u0131 district. The lake has some parks in its coast, such as Atat\u00fcrk Sahil Park\u0131. This park is relatively big and usually not too crowded.", "title": "Ankara"}, {"location": "countries/turkey/places/ankara/#mogan-lake-mogan-golu", "text": "This lake is 25 km south of Ankara city and its reachable by public transport. It is located in the G\u00f6lba\u015f\u0131 district. The lake has some parks in its coast, such as Atat\u00fcrk Sahil Park\u0131. This park is relatively big and usually not too crowded.", "title": "Mogan lake (Mogan G\u00f6l\u00fc)"}, {"location": "countries/turkey/places/eskisehir/", "text": "Eski\u015fehir is a city in northwestern Turkey and the capital of the Eski\u015fehir Province. In the Byzantine era its name was Dorylaeum. The city is located on the banks of the Porsuk River, 792 m above sea level, where it overlooks the fertile Phrygian Valley. In the nearby hills one can find hot springs. The city is 233 km to the west of Ankara and 330 km to the southeast of Istanbul. The city is known for being a cheap student city and small enough to be able to go anywhere by walking (which is generally true but with few exceptions). It's easy (and cheap) to go to Eski\u015fehir from Ankara or Istanbul with the high-speed train (YHT). Places \u2691 Ulus An\u0131t\u0131 area \u2691 Close to the train station, you can see a monument, Ulus An\u0131t\u0131, in a roundabout. Close to this place, there are a lot of restaurants and bars. Some recommendations are: Ac\u0131kt\u0131m: Go here for their breakfast, it's amazing. De\u011firmencio\u011flu: Buffet restaurant where you get homemade food with a tray. Dublin: Nice bar/restaurant to eat something with a beer. Hangover Sky: Nice bar to eat something with a beer at night. Odunpazar\u0131 Evleri \u2691 Old colorful houses. Nice area to walk around and stop to have tea or coffee. Some recommended caf\u00e9s here are Caf\u00e9 Restaurant Rasta and Cousine Restaurant . The mosque Kur\u015funlu Cami is nearby and has nice gardens that can be visited. Other places to visit around are Alaadin Park\u0131 and the Odunpazar\u0131 Modern M\u00fcze (OMM). Hicri Sezen Park\u0131 \u2691 This is a public park located where the old colorful houses from Odunpazar\u0131 are. It's managed by the municipality and they offer tea and other drinks. Food \u2691 You can try a typical kebap from Eski\u015fehir, Balaban Kebap, at K\u00f6ftes Balaban Kebap . A\u015fk Adas\u0131 \u2691 The island of the lovers is a bit far from the center but is a nice park to visit and spend some time reading a book under the shade of the trees. Sazova \u2691 This is a huge park located apart from the city center.", "title": "Eski\u015fehir"}, {"location": "countries/turkey/places/eskisehir/#places", "text": "", "title": "Places"}, {"location": "countries/turkey/places/eskisehir/#ulus-ant-area", "text": "Close to the train station, you can see a monument, Ulus An\u0131t\u0131, in a roundabout. Close to this place, there are a lot of restaurants and bars. Some recommendations are: Ac\u0131kt\u0131m: Go here for their breakfast, it's amazing. De\u011firmencio\u011flu: Buffet restaurant where you get homemade food with a tray. Dublin: Nice bar/restaurant to eat something with a beer. Hangover Sky: Nice bar to eat something with a beer at night.", "title": "Ulus An\u0131t\u0131 area"}, {"location": "countries/turkey/places/eskisehir/#odunpazar-evleri", "text": "Old colorful houses. Nice area to walk around and stop to have tea or coffee. Some recommended caf\u00e9s here are Caf\u00e9 Restaurant Rasta and Cousine Restaurant . The mosque Kur\u015funlu Cami is nearby and has nice gardens that can be visited. Other places to visit around are Alaadin Park\u0131 and the Odunpazar\u0131 Modern M\u00fcze (OMM).", "title": "Odunpazar\u0131 Evleri"}, {"location": "countries/turkey/places/eskisehir/#hicri-sezen-park", "text": "This is a public park located where the old colorful houses from Odunpazar\u0131 are. It's managed by the municipality and they offer tea and other drinks.", "title": "Hicri Sezen Park\u0131"}, {"location": "countries/turkey/places/eskisehir/#food", "text": "You can try a typical kebap from Eski\u015fehir, Balaban Kebap, at K\u00f6ftes Balaban Kebap .", "title": "Food"}, {"location": "countries/turkey/places/eskisehir/#ask-adas", "text": "The island of the lovers is a bit far from the center but is a nice park to visit and spend some time reading a book under the shade of the trees.", "title": "A\u015fk Adas\u0131"}, {"location": "countries/turkey/places/eskisehir/#sazova", "text": "This is a huge park located apart from the city center.", "title": "Sazova"}, {"location": "economics/development/product_space/", "text": "This entry is a summary of a paper that studies the economic development of countries using network science analysis [^1]. Abstract \u2691 Economies grow by upgrading the products they produce and export. The technology, capital, institutions, and skills needed to make newer products are more easily adapted from some products than from others. Here, we study this network of relatedness between products, or \u201cproduct space,\u201d finding that more-sophisticated products are located in a densely connected core whereas less-sophisticated products occupy a less-connected periphery. Empirically, countries move through the product space by developing goods close to those they currently produce. Most countries can reach the core only by traversing empirically infrequent distances, which may help explain why poor countries have trouble developing more competitive exports and fail to converge to the income levels of rich countries. Summary \u2691 Economic power is usually measured with the aggregate output of a countries capital and labor. The main idea of the article is that diversity of a countries exports matters, and it's useful when predicting a countries development. Countries are more likely to produce products which have similar requirements as the ones they already produce. This video is a great introduction (and even summary) of what's developed in the paper. [^1]: C\u00e9sar A Hidalgo, Bailey Klinger, A-L Barab\u00e1si, and Ricardo Hausmann. The product space conditions the development of nations. Science , 317 \\(5837\\) :482\u2013487, 2007.", "title": "Product Space"}, {"location": "economics/development/product_space/#abstract", "text": "Economies grow by upgrading the products they produce and export. The technology, capital, institutions, and skills needed to make newer products are more easily adapted from some products than from others. Here, we study this network of relatedness between products, or \u201cproduct space,\u201d finding that more-sophisticated products are located in a densely connected core whereas less-sophisticated products occupy a less-connected periphery. Empirically, countries move through the product space by developing goods close to those they currently produce. Most countries can reach the core only by traversing empirically infrequent distances, which may help explain why poor countries have trouble developing more competitive exports and fail to converge to the income levels of rich countries.", "title": "Abstract"}, {"location": "economics/development/product_space/#summary", "text": "Economic power is usually measured with the aggregate output of a countries capital and labor. The main idea of the article is that diversity of a countries exports matters, and it's useful when predicting a countries development. Countries are more likely to produce products which have similar requirements as the ones they already produce. This video is a great introduction (and even summary) of what's developed in the paper. [^1]: C\u00e9sar A Hidalgo, Bailey Klinger, A-L Barab\u00e1si, and Ricardo Hausmann. The product space conditions the development of nations. Science , 317 \\(5837\\) :482\u2013487, 2007.", "title": "Summary"}, {"location": "languages/turkish/grammar/gerunds/", "text": "Gerunds of junction (Ba\u011flama Ulac\u0131) \u2691 -\u0131p [-ip, -\u00fcp, -up; -(y)ip, -(y)\u0131p\u2026] They are used to avoid repetition of the verb tense in sentences with several verbs. Examples \u2691 Sandallara binip gittiler. (... bindiler ve gittiler.) \u00c7ay\u0131 koyup geliyorum. \u015eu adam ni\u00e7in bize bak\u0131p duruyor.", "title": "Gerunds"}, {"location": "languages/turkish/grammar/gerunds/#gerunds-of-junction-baglama-ulac", "text": "-\u0131p [-ip, -\u00fcp, -up; -(y)ip, -(y)\u0131p\u2026] They are used to avoid repetition of the verb tense in sentences with several verbs.", "title": "Gerunds of junction (Ba\u011flama Ulac\u0131)"}, {"location": "languages/turkish/grammar/gerunds/#examples", "text": "Sandallara binip gittiler. (... bindiler ve gittiler.) \u00c7ay\u0131 koyup geliyorum. \u015eu adam ni\u00e7in bize bak\u0131p duruyor.", "title": "Examples"}, {"location": "languages/turkish/grammar/noun_cases/", "text": "Turkish generally uses noun cases ( ismin hal ekleri ) instead of prepositions. Reference \u2691 Turkish/Cases - Wikibooks YEE A1 - Y\u00f6nelme H\u00e2li - YouTube YEE A1 - Belirtme \u2013 Ayr\u0131lma H\u00e2li - YouTube Yal\u0131n hali: -i , -e , -de , -den - YouTube", "title": "Noun cases"}, {"location": "languages/turkish/grammar/noun_cases/#reference", "text": "Turkish/Cases - Wikibooks YEE A1 - Y\u00f6nelme H\u00e2li - YouTube YEE A1 - Belirtme \u2013 Ayr\u0131lma H\u00e2li - YouTube Yal\u0131n hali: -i , -e , -de , -den - YouTube", "title": "Reference"}, {"location": "projects/projects/", "text": "Finished projects \u2691 m0wer/fuzzy_showers : Modeling of a dynamic system using fuzzy logic. There are several showers in a locker room that share the same water heater. User actions over their shower temperature control affect others.", "title": "Projects"}, {"location": "projects/projects/#finished-projects", "text": "m0wer/fuzzy_showers : Modeling of a dynamic system using fuzzy logic. There are several showers in a locker room that share the same water heater. User actions over their shower temperature control affect others.", "title": "Finished projects"}]}